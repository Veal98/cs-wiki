# ğŸ‘“ å¼ é‡ Tensor

---

## 1. ä»€ä¹ˆæ˜¯å¼ é‡

**å¼ é‡æ˜¯å…·æœ‰ç»Ÿä¸€ç±»å‹ï¼ˆç§°ä¸º `dtype`ï¼‰çš„å¤šç»´æ•°ç»„ã€‚**

å¼ é‡ä¸ `np.arrays` æœ‰ä¸€å®šçš„ç›¸ä¼¼æ€§ã€‚

å°±åƒ Python æ•°å€¼å’Œå­—ç¬¦ä¸²ä¸€æ ·ï¼Œ**æ‰€æœ‰å¼ é‡éƒ½æ˜¯ä¸å¯å˜çš„ï¼šæ°¸è¿œæ— æ³•æ›´æ–°å¼ é‡çš„å†…å®¹ï¼Œåªèƒ½åˆ›å»ºæ–°çš„å¼ é‡**ã€‚

## 2. å¼ é‡ç±»å‹

æ ¹æ®ä¸åŒçš„ç”¨é€”ï¼ŒTensorFlow ä¸­ä¸»è¦æœ‰ 2 ç§å¼ é‡ç±»å‹ï¼Œåˆ†åˆ«æ˜¯ï¼š

- `tf.Variable` ï¼šå˜é‡ Tensorï¼Œéœ€è¦æŒ‡å®šåˆå§‹å€¼ï¼Œå¸¸ç”¨äºå®šä¹‰å¯å˜å‚æ•°ï¼Œä¾‹å¦‚ç¥ç»ç½‘ç»œçš„æƒé‡ã€‚

  > ğŸ’¡ å˜é‡æ˜¯ä¸€ç§ç‰¹æ®Šçš„å¼ é‡ï¼Œæ˜¯ç”¨äºè¡¨ç¤ºç¨‹åºå¤„ç†çš„å…±äº«æŒä¹…çŠ¶æ€çš„æ¨èæ–¹æ³•

- `tf.constant` ï¼šå¸¸é‡ Tensorï¼Œéœ€è¦æŒ‡å®šåˆå§‹å€¼ï¼Œå®šä¹‰ä¸å˜åŒ–çš„å¼ é‡ã€‚

æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¼ å…¥åˆ—è¡¨æˆ– NumPy æ•°ç»„æ¥æ–°å»ºå˜é‡å’Œå¸¸é‡ç±»å‹çš„å¼ é‡ï¼š

ğŸ’¬ å˜é‡ç¤ºä¾‹ï¼š

```python
v = tf.Variable([[1, 2], [3, 4]])  # å½¢çŠ¶ä¸º (2, 2) çš„äºŒç»´å˜é‡
v
```

è¾“å‡º

```python
<tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=
array([[1, 2],
       [3, 4]], dtype=int32)>
```

ğŸš¨ **ä»ç°æœ‰ã€å˜é‡ã€‘åˆ›å»ºæ–°å˜é‡ä¼šå¤åˆ¶æ”¯æŒå¼ é‡ã€‚ä¸¤ä¸ªå˜é‡ä¸èƒ½å…±äº«åŒä¸€å†…å­˜ç©ºé—´ã€‚**

```python
a = tf.Variable([2.0, 3.0])
# Create b based on the value of a
b = tf.Variable(a)
a.assign([5, 6])

# a and b are different
print(a.numpy()) # [5. 6.]
print(b.numpy()) # [2. 3.]

# There are other versions of assign
print(a.assign_add([2,3]).numpy())  # [7. 9.]
print(a.assign_sub([7,9]).numpy())  # [0. 0.]
```

ğŸ’¬ å¸¸é‡ç¤ºä¾‹ï¼š

```python
c = tf.constant([[1, 2], [3, 4]])  # å½¢çŠ¶ä¸º (2, 2) çš„äºŒç»´å¸¸é‡
c
```

è¾“å‡º

```python
<tf.Tensor: id=9, shape=(2, 2), dtype=int32, numpy=
array([[1, 2],
       [3, 4]], dtype=int32)>
```

> ğŸ’¡ ä»”ç»†è§‚å¯Ÿï¼Œä½ ä¼šå‘ç°è¾“å‡ºåŒ…å«äº†å¼ é‡çš„ 3 éƒ¨åˆ†å±æ€§ï¼Œåˆ†åˆ«æ˜¯å½¢çŠ¶ `shape`ï¼Œæ•°æ®ç±»å‹ `dtype`ï¼Œä»¥åŠå¯¹åº”çš„ NumPy æ•°ç»„ã€‚

å¼ é‡çš„è½´å¯èƒ½æ›´å¤šï¼Œä¸‹é¢æ˜¯ä¸€ä¸ªåŒ…å« 3 ä¸ªè½´çš„å¼ é‡ï¼š

```python
# There can be an arbitrary number of
# axes (sometimes called "dimensions")
rank_3_tensor = tf.constant([
  [[0, 1, 2, 3, 4],
   [5, 6, 7, 8, 9]],
  [[10, 11, 12, 13, 14],
   [15, 16, 17, 18, 19]],
  [[20, 21, 22, 23, 24],
   [25, 26, 27, 28, 29]],])

print(rank_3_tensor)

tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
```

<img src="https://gitee.com/veal98/images/raw/master/img/20201114104133.png" style="zoom:67%;" />

## 3. å¼ é‡çš„åŸºæœ¬è¿ç®—

é€šè¿‡ä½¿ç”¨ `np.array` æˆ– `tensor.numpy` æ–¹æ³•ï¼Œæ‚¨å¯ä»¥å°†å¼ é‡è½¬æ¢ä¸º NumPy æ•°ç»„ï¼š

```python
np.array(rank_3_tensor)

rank_3_tensor.numpy()
```

å¼ é‡é€šå¸¸åŒ…å«æµ®ç‚¹å‹å’Œæ•´å‹æ•°æ®ï¼Œä½†æ˜¯è¿˜æœ‰è®¸å¤šå…¶ä»–æ•°æ®ç±»å‹ï¼ŒåŒ…æ‹¬ï¼š

- å¤æ‚çš„æ•°å€¼
- å­—ç¬¦ä¸²

<u>[`tf.Tensor`](https://tensorflow.google.cn/api_docs/python/tf/Tensor?hl=zh_cn) åŸºç±»è¦æ±‚å¼ é‡æ˜¯â€œçŸ©å½¢â€â€”â€”ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¯ä¸ªè½´ä¸Šçš„æ¯ä¸€ä¸ªå…ƒç´ å¤§å°ç›¸åŒã€‚ä½†æ˜¯ï¼Œå¼ é‡æœ‰å¯ä»¥å¤„ç†ä¸åŒå½¢çŠ¶çš„ç‰¹æ®Šç±»å‹ã€‚</u>

- **ä¸è§„åˆ™å¼ é‡**ï¼ˆå‚é˜…ä¸‹æ–‡ä¸­çš„ `RaggedTensor`ï¼‰
- **ç¨€ç–å¼ é‡**ï¼ˆå‚é˜…ä¸‹æ–‡ä¸­çš„ `SparseTensor`ï¼‰

æˆ‘ä»¬å¯ä»¥å¯¹å¼ é‡æ‰§è¡ŒåŸºæœ¬æ•°å­¦è¿ç®—ï¼ŒåŒ…æ‹¬åŠ æ³•ã€é€å…ƒç´ ä¹˜æ³•å’ŒçŸ©é˜µä¹˜æ³•è¿ç®—ã€‚

```python
a = tf.constant([[1, 2],
                 [3, 4]])
b = tf.constant([[1, 1],
                 [1, 1]]) # Could have also said `tf.ones([2,2])`

print(tf.add(a, b), "\n")
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) 

print(tf.multiply(a, b), "\n")
tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) 

print(tf.matmul(a, b), "\n")
tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32) 

print(a + b, "\n") # element-wise addition
tf.Tensor(
[[2 3]
 [4 5]], shape=(2, 2), dtype=int32) 

print(a * b, "\n") # element-wise multiplication
tf.Tensor(
[[1 2]
 [3 4]], shape=(2, 2), dtype=int32) 

print(a @ b, "\n") # matrix multiplication
tf.Tensor(
[[3 3]
 [7 7]], shape=(2, 2), dtype=int32) 
```

å„ç§è¿ç®— (op) éƒ½å¯ä»¥ä½¿ç”¨å¼ é‡ã€‚

```python
c = tf.constant([[4.0, 5.0], [10.0, 1.0]])

# Find the largest value
print(tf.reduce_max(c))
tf.Tensor(10.0, shape=(), dtype=float32)

# Find the index of the largest value
print(tf.argmax(c))
tf.Tensor([1 0], shape=(2,), dtype=int64)

# Compute the softmax
print(tf.nn.softmax(c))
tf.Tensor( [[2.6894143e-01 7.3105860e-01] [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)
```

## 4.å¼ é‡çš„å½¢çŠ¶

å¼ é‡æœ‰å½¢çŠ¶ã€‚ä¸‹é¢æ˜¯å‡ ä¸ªç›¸å…³æœ¯è¯­ï¼š

- **å½¢çŠ¶ Shape**ï¼šå¼ é‡çš„æ¯ä¸ªç»´åº¦çš„é•¿åº¦ï¼ˆå…ƒç´ æ•°é‡ï¼‰ã€‚
- **ç§© Rank**ï¼šå¼ é‡çš„ç»´åº¦æ•°é‡ã€‚æ ‡é‡çš„ç§©ä¸º 0ï¼Œå‘é‡çš„ç§©ä¸º 1ï¼ŒçŸ©é˜µçš„ç§©ä¸º 2ã€‚
- **è½´ Axis** æˆ– **ç»´åº¦ Dimension**ï¼šå¼ é‡çš„ä¸€ä¸ªç‰¹æ®Šç»´åº¦ã€‚
- **å¤§å° Size**ï¼šå¼ é‡çš„æ€»é¡¹æ•°ï¼Œå³ä¹˜ç§¯å½¢çŠ¶å‘é‡

> æ³¨ï¼šè™½ç„¶æ‚¨å¯èƒ½ä¼šçœ‹åˆ°â€œäºŒç»´å¼ é‡â€ä¹‹ç±»çš„è¡¨è¿°ï¼Œä½† 2 ç§©å¼ é‡é€šå¸¸å¹¶ä¸æ˜¯ç”¨æ¥æè¿°äºŒç»´ç©ºé—´ã€‚

å¼ é‡å’Œ [`tf.TensorShape`](https://tensorflow.google.cn/api_docs/python/tf/TensorShape?hl=zh_cn) å¯¹è±¡æä¾›äº†æ–¹ä¾¿çš„å±æ€§æ¥è®¿é—®ï¼š

```
rank_4_tensor = tf.zeros([3, 2, 4, 5]) # 4 ç§©å¼ é‡ï¼Œå½¢çŠ¶ï¼š[3, 2, 4, 5]
```

<img src="https://gitee.com/veal98/images/raw/master/img/20201114105211.png" style="zoom:50%;" />

```python
print("Type of every element:", rank_4_tensor.dtype)
Type of every element: <dtype: 'float32'>
        
print("Number of dimensions:", rank_4_tensor.ndim)
Number of dimensions: 4
    
print("Shape of tensor:", rank_4_tensor.shape)
Shape of tensor: (3, 2, 4, 5)
    
print("Elements along axis 0 of tensor:", rank_4_tensor.shape[0])
Elements along axis 0 of tensor: 3
    
print("Elements along the last axis of tensor:", rank_4_tensor.shape[-1])
Elements along the last axis of tensor: 5
    
print("Total number of elements (3*2*4*5): ", tf.size(rank_4_tensor).numpy())
Total number of elements (3*2*4*5):  120
```

è™½ç„¶é€šå¸¸ç”¨ç´¢å¼•æ¥æŒ‡ä»£è½´ï¼Œä½†æ˜¯æ‚¨å§‹ç»ˆè¦è®°ä½æ¯ä¸ªè½´çš„å«ä¹‰ã€‚è½´ä¸€èˆ¬æŒ‰ç…§ä»å…¨å±€åˆ°å±€éƒ¨çš„é¡ºåºè¿›è¡Œæ’åºï¼šé¦–å…ˆæ˜¯æ‰¹æ¬¡è½´ï¼Œéšåæ˜¯ç©ºé—´ç»´åº¦ï¼Œæœ€åæ˜¯æ¯ä¸ªä½ç½®çš„ç‰¹å¾ã€‚è¿™æ ·ï¼Œåœ¨å†…å­˜ä¸­ï¼Œç‰¹å¾å‘é‡å°±ä¼šä½äºè¿ç»­çš„åŒºåŸŸã€‚

<img src="https://gitee.com/veal98/images/raw/master/img/20201114105415.png" style="zoom:67%;" />

## 5. ç´¢å¼•

### â‘  å•è½´ç´¢å¼•

TensorFlow éµå¾ªæ ‡å‡† Python ç´¢å¼•è§„åˆ™ï¼ˆç±»ä¼¼äº[åœ¨ Python ä¸­ä¸ºåˆ—è¡¨æˆ–å­—ç¬¦ä¸²ç¼–åˆ¶ç´¢å¼•](https://docs.python.org/3/tutorial/introduction.html#strings)ï¼‰ä»¥åŠ NumPy ç´¢å¼•çš„åŸºæœ¬è§„åˆ™ã€‚

- ç´¢å¼•ä» `0` å¼€å§‹ç¼–åˆ¶
- **è´Ÿç´¢å¼•è¡¨ç¤ºæŒ‰å€’åºç¼–åˆ¶ç´¢å¼•**
- å†’å· `:` ç”¨äºåˆ‡ç‰‡ `start:stop:step`

```python
rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])
print(rank_1_tensor.numpy())
[ 0  1  1  2  3  5  8 13 21 34]
```

ä½¿ç”¨æ ‡é‡ç¼–åˆ¶ç´¢å¼•ä¼šç§»é™¤ç»´åº¦ï¼š

```python
print("First:", rank_1_tensor[0].numpy()) # batch
First: 0
    
print("Second:", rank_1_tensor[1].numpy()) # width
Second: 1

print("Last:", rank_1_tensor[-1].numpy()) # features
Last: 34
```

ä½¿ç”¨ `:` åˆ‡ç‰‡ç¼–åˆ¶ç´¢å¼•ä¼šä¿ç•™ç»´åº¦ï¼š

```python
print("Everything:", rank_1_tensor[:].numpy())
Everything: [ 0  1  1  2  3  5  8 13 21 34]
    
print("Before 4:", rank_1_tensor[:4].numpy())
Before 4: [0 1 1 2]
    
print("From 4 to the end:", rank_1_tensor[4:].numpy())
From 4 to the end: [ 3  5  8 13 21 34]
    
print("From 2, before 7:", rank_1_tensor[2:7].numpy())
From 2, before 7: [1 2 3 5 8]
    
print("Every other item:", rank_1_tensor[::2].numpy()) # æ¯éš”2ä¸ªå–ä¸€ä¸ª
Every other item: [ 0  1  3  8  21]
    
print("Reversed:", rank_1_tensor[::-1].numpy())
Reversed: [34 21 13  8  5  3  2  1  1  0] 
```

### â‘¡ å¤šè½´ç´¢å¼•

æ›´é«˜ç§©çš„å¼ é‡é€šè¿‡ä¼ é€’å¤šä¸ªç´¢å¼•æ¥ç¼–åˆ¶ç´¢å¼•ã€‚

å¯¹äºé«˜ç§©å¼ é‡çš„æ¯ä¸ªå•ç‹¬çš„è½´ï¼Œéµå¾ªä¸å•è½´æƒ…å½¢å®Œå…¨ç›¸åŒçš„ç´¢å¼•è§„åˆ™ã€‚

```python
rank_2_tensor = tf.constant([[1, 2],
                             [3, 4],
                             [5, 6]], dtype=tf.float16)
```

ä¸ºæ¯ä¸ªç´¢å¼•ä¼ é€’ä¸€ä¸ªæ•´æ•°ï¼Œç»“æœæ˜¯ä¸€ä¸ªæ ‡é‡ã€‚

```python
# Pull out a single value from a 2-rank tensor
print(rank_2_tensor[1, 1].numpy())
4.0
```

æ‚¨å¯ä»¥ä½¿ç”¨æ•´æ•°ä¸åˆ‡ç‰‡çš„ä»»æ„ç»„åˆç¼–åˆ¶ç´¢å¼•ï¼š

```python
# Get row and column tensors
print("Second row:", rank_2_tensor[1, :].numpy())
Second row: [3. 4.]
    
print("Second column:", rank_2_tensor[:, 1].numpy())
Second column: [2. 4. 6.]
    
print("Last row:", rank_2_tensor[-1, :].numpy())
Last row: [5. 6.]
    
print("First item in last column:", rank_2_tensor[0, -1].numpy())
First item in last column: 2.0
    
print("Skip the first row:")
print(rank_2_tensor[1:, :].numpy(), "\n")
Skip the first row:
[[3. 4.]
 [5. 6.]] 
```

ä¸‹é¢æ˜¯ä¸€ä¸ª 3 è½´å¼ é‡çš„ç¤ºä¾‹ï¼š

```python
rank_3_tensor = tf.constant([
  [[0, 1, 2, 3, 4],
   [5, 6, 7, 8, 9]],
  [[10, 11, 12, 13, 14],
   [15, 16, 17, 18, 19]],
  [[20, 21, 22, 23, 24],
   [25, 26, 27, 28, 29]],])

print(rank_3_tensor[:, :, 4]) # é€‰æ‹©æ‰¹æ¬¡ä¸­æ¯ä¸ªç¤ºä¾‹çš„æ‰€æœ‰ä½ç½®çš„ç¬¬ 4 ä¸ªç‰¹å¾
tf.Tensor( [[ 4  9] [14 19] [24 29]], shape=(3, 2), dtype=int32)
```

<img src="https://gitee.com/veal98/images/raw/master/img/20201114110315.png" style="zoom: 60%;" />

## 6. å¼ é‡å½¢çŠ¶é‡æ„ `tf.reshape`

```python
# Shape returns a `TensorShape` object that shows the size on each dimension
var_x = tf.Variable(tf.constant([[1], [2], [3]]))
print(var_x.shape)
(3, 1)
# You can convert this object into a Python list, too
print(var_x.shape.as_list())
[3, 1]
```

**é€šè¿‡é‡æ„ `reshape` å¯ä»¥æ”¹å˜å¼ é‡çš„å½¢çŠ¶ã€‚é‡æ„çš„é€Ÿåº¦å¾ˆå¿«ï¼Œèµ„æºæ¶ˆè€—å¾ˆä½ï¼Œå› ä¸ºä¸éœ€è¦å¤åˆ¶åº•å±‚æ•°æ®**ã€‚

> ğŸš¨ **æ³¨æ„ï¼šå˜é‡ `Variable` æ˜¯æ— æ³•è¿›è¡Œé‡æ„å½¢çŠ¶çš„ï¼**
>
> å˜é‡ç”±å¼ é‡æä¾›æ”¯æŒã€‚æ‚¨å¯ä»¥ä½¿ç”¨ [`tf.Variable.assign`](https://tensorflow.google.cn/api_docs/python/tf/Variable?hl=zh_cn#assign) é‡æ–°åˆ†é…å¼ é‡ã€‚è°ƒç”¨ `assign`ï¼ˆé€šå¸¸ï¼‰ä¸ä¼šåˆ†é…æ–°å¼ é‡ï¼Œè€Œä¼šé‡ç”¨ç°æœ‰å¼ é‡çš„å†…å­˜ã€‚
>
> ```python
> a = tf.Variable([2.0, 3.0])
> # This will keep the same dtype, float32
> a.assign([1, 2]) 
> 
> # Not allowed as it resizes the variable: 
> try:
>   a.assign([1.0, 2.0, 3.0])
> except Exception as e:
>   print(f"{type(e).__name__}: {e}")
> 
> ValueError: Shapes (2,) and (3,) are incompatible
> ```

```python
# We can reshape a tensor to a new shape.
# Note that we're passing in a list
reshaped = tf.reshape(var_x, [1, 3])
print(var_x.shape)
(3, 1)

print(reshaped.shape)
(1, 3)
```

**æ•°æ®åœ¨å†…å­˜ä¸­çš„å¸ƒå±€ä¿æŒä¸å˜ï¼ŒåŒæ—¶ä½¿ç”¨è¯·æ±‚çš„å½¢çŠ¶åˆ›å»ºä¸€ä¸ªæŒ‡å‘åŒä¸€æ•°æ®çš„æ–°å¼ é‡ã€‚TensorFlow é‡‡ç”¨ C æ ·å¼çš„â€œè¡Œä¼˜å…ˆâ€å†…å­˜è®¿é—®é¡ºåºï¼Œå³æœ€å³ä¾§çš„ç´¢å¼•å€¼é€’å¢å¯¹åº”äºå†…å­˜ä¸­çš„å•æ­¥ä½ç§»**ã€‚

```python
print(rank_3_tensor)
tf.Tensor(
[[[ 0  1  2  3  4]
  [ 5  6  7  8  9]]

 [[10 11 12 13 14]
  [15 16 17 18 19]]

 [[20 21 22 23 24]
  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)
```

å¦‚æœæ‚¨**å±•å¹³å¼ é‡ `[-1]`**ï¼Œåˆ™å¯ä»¥çœ‹åˆ°å®ƒåœ¨å†…å­˜ä¸­çš„æ’åˆ—é¡ºåºï¼š

```python
# A `-1` passed in the `shape` argument says "Whatever fits".
print(tf.reshape(rank_3_tensor, [-1]))
tf.Tensor(
[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29], shape=(30,), dtype=int32)
```

ä¸€èˆ¬æ¥è¯´ï¼Œ[`tf.reshape`](https://tensorflow.google.cn/api_docs/python/tf/reshape?hl=zh_cn) å”¯ä¸€åˆç†çš„ç”¨é€”æ˜¯ç”¨äºåˆå¹¶æˆ–æ‹†åˆ†ç›¸é‚»è½´ï¼ˆæˆ–æ·»åŠ /ç§»é™¤ `1`ï¼‰ã€‚

å¯¹äº 3x2x5 å¼ é‡ï¼Œé‡æ„ä¸º (3x2)x5 æˆ– 3x(2x5) éƒ½åˆç†ï¼Œå› ä¸ºåˆ‡ç‰‡ä¸ä¼šæ··æ·†ï¼š

```python
print(tf.reshape(rank_3_tensor, [3*2, 5]), "\n")
tf.Tensor(
[[ 0  1  2  3  4]
 [ 5  6  7  8  9]
 [10 11 12 13 14]
 [15 16 17 18 19]
 [20 21 22 23 24]
 [25 26 27 28 29]], shape=(6, 5), dtype=int32) 

print(tf.reshape(rank_3_tensor, [3, -1]))
tf.Tensor(
[[ 0  1  2  3  4  5  6  7  8  9]
 [10 11 12 13 14 15 16 17 18 19]
 [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)

```

<img src="https://gitee.com/veal98/images/raw/master/img/20201114110959.png" style="zoom: 67%;" />

**é‡æ„å¯ä»¥å¤„ç†æ€»å…ƒç´ ä¸ªæ•°ç›¸åŒçš„ä»»ä½•æ–°å½¢çŠ¶ï¼Œä½†æ˜¯å¦‚æœä¸éµä»è½´çš„é¡ºåºï¼Œåˆ™ä¸ä¼šå‘æŒ¥ä»»ä½•ä½œç”¨**ã€‚

<img src="https://gitee.com/veal98/images/raw/master/img/20201114111100.png" style="zoom:67%;" />

## 7. `DTypes` è¯¦è§£

ä½¿ç”¨ [`Tensor.dtype`](https://tensorflow.google.cn/api_docs/python/tf/Tensor?hl=zh_cn#dtype) å±æ€§å¯ä»¥æ£€æŸ¥ [`tf.Tensor`](https://tensorflow.google.cn/api_docs/python/tf/Tensor?hl=zh_cn) çš„æ•°æ®ç±»å‹ã€‚

ä» Python å¯¹è±¡åˆ›å»º [`tf.Tensor`](https://tensorflow.google.cn/api_docs/python/tf/Tensor?hl=zh_cn) æ—¶ï¼Œæ‚¨å¯ä»¥é€‰æ‹©æŒ‡å®šæ•°æ®ç±»å‹ã€‚

å¦‚æœä¸æŒ‡å®šï¼ŒTensorFlow ä¼šé€‰æ‹©ä¸€ä¸ªå¯ä»¥è¡¨ç¤ºæ‚¨çš„æ•°æ®çš„æ•°æ®ç±»å‹ã€‚TensorFlow å°† Python æ•´æ•°è½¬æ¢ä¸º [`tf.int32`](https://tensorflow.google.cn/api_docs/python/tf?hl=zh_cn#int32)ï¼Œå°† Python æµ®ç‚¹æ•°è½¬æ¢ä¸º [`tf.float32`](https://tensorflow.google.cn/api_docs/python/tf?hl=zh_cn#float32)ã€‚å¦å¤–ï¼Œå½“è½¬æ¢ä¸ºæ•°ç»„æ—¶ï¼ŒTensorFlow ä¼šé‡‡ç”¨ä¸ NumPy ç›¸åŒçš„è§„åˆ™ã€‚

æ•°æ®ç±»å‹å¯ä»¥ç›¸äº’è½¬æ¢ `tf.cast`ï¼š

```python
the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)
the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)

# Now, let's cast to an uint8 and lose the decimal precision
the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)
print(the_u8_tensor)
tf.Tensor([2 3 4], shape=(3,), dtype=uint8) 
```

## 8. å¹¿æ’­

å¹¿æ’­æ˜¯ä» [NumPy ä¸­çš„ç­‰æ•ˆåŠŸèƒ½](https://numpy.org/doc/stable/user/basics.html)å€Ÿç”¨çš„ä¸€ä¸ªæ¦‚å¿µã€‚**ç®€è€Œè¨€ä¹‹ï¼Œåœ¨ä¸€å®šæ¡ä»¶ä¸‹ï¼Œå¯¹ä¸€ç»„å¼ é‡æ‰§è¡Œç»„åˆè¿ç®—æ—¶ï¼Œä¸ºäº†é€‚åº”å¤§å¼ é‡ï¼Œä¼šå¯¹å°å¼ é‡è¿›è¡Œâ€œæ‰©å±•â€ã€‚**

**æœ€ç®€å•å’Œæœ€å¸¸è§çš„ä¾‹å­æ˜¯å°è¯•å°†å¼ é‡ä¸æ ‡é‡ç›¸ä¹˜æˆ–ç›¸åŠ ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ä¼šå¯¹æ ‡é‡è¿›è¡Œå¹¿æ’­ï¼Œä½¿å…¶å˜æˆä¸å…¶ä»–å‚æ•°ç›¸åŒçš„å½¢çŠ¶**ã€‚

```python
x = tf.constant([1, 2, 3])

y = tf.constant(2)
z = tf.constant([2, 2, 2])
# All of these are the same computation
print(tf.multiply(x, 2))
print(x * y)
print(x * z)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
tf.Tensor([2 4 6], shape=(3,), dtype=int32)
```

åŒæ ·ï¼Œå¯ä»¥æ‰©å±•å¤§å°ä¸º 1 çš„ç»´åº¦ï¼Œä½¿å…¶ç¬¦åˆå…¶ä»–å‚æ•°ã€‚åœ¨åŒä¸€ä¸ªè®¡ç®—ä¸­å¯ä»¥åŒæ—¶æ‰©å±•ä¸¤ä¸ªå‚æ•°ã€‚

åœ¨æœ¬ä¾‹ä¸­ï¼Œä¸€ä¸ª 3x1 çš„çŸ©é˜µä¸ä¸€ä¸ª 1x4 è¿›è¡Œå…ƒç´ çº§ä¹˜æ³•è¿ç®—ï¼Œä»è€Œäº§ç”Ÿä¸€ä¸ª 3x4 çš„çŸ©é˜µã€‚æ³¨æ„å‰å¯¼ 1 æ˜¯å¯é€‰çš„ï¼šy çš„å½¢çŠ¶æ˜¯ `[4]`ã€‚

```python
# These are the same computations
x = tf.reshape(x,[3,1])
y = tf.range(1, 5)
print(x, "\n")
print(y, "\n")
print(tf.multiply(x, y))

tf.Tensor( [[1] [2] [3]], shape=(3, 1), dtype=int32)  
tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)  
tf.Tensor( [[ 1  2  3  4] [ 2  4  6  8] [ 3  6  9 12]], shape=(3, 4), dtype=int32)
```

> ğŸ’¡ å¹¿æ’­ç›¸åŠ ï¼š`[3, 1]` ä¹˜ä»¥ `[1, 4]` çš„ç»“æœæ˜¯ `[3,4]`
>
> <img src="https://gitee.com/veal98/images/raw/master/img/20201115110528.png" style="zoom:67%;" />

ä¸‹é¢æ˜¯ä¸ä½¿ç”¨å¹¿æ’­çš„åŒä¸€è¿ç®—ï¼š

```python
x_stretch = tf.constant([[1, 1, 1, 1],
                         [2, 2, 2, 2],
                         [3, 3, 3, 3]])

y_stretch = tf.constant([[1, 2, 3, 4],
                         [1, 2, 3, 4],
                         [1, 2, 3, 4]])

print(x_stretch * y_stretch)  # Again, operator overloading
tf.Tensor(
[[ 1  2  3  4]
 [ 2  4  6  8]
 [ 3  6  9 12]], shape=(3, 4), dtype=int32)
```

**åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå¹¿æ’­çš„æ—¶é—´å’Œç©ºé—´æ•ˆç‡æ›´é«˜ï¼Œå› ä¸ºå¹¿æ’­è¿ç®—ä¸ä¼šåœ¨å†…å­˜ä¸­å…·ä½“åŒ–æ‰©å±•çš„å¼ é‡**ã€‚

## 9. å­—ç¬¦ä¸²å¼ é‡

### â‘  æ¦‚å¿µ

**[`tf.string`](https://tensorflow.google.cn/api_docs/python/tf?hl=zh_cn#string) æ˜¯ä¸€ç§ `dtype`ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œåœ¨å¼ é‡ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å­—ç¬¦ä¸²ï¼ˆå¯å˜é•¿åº¦å­—èŠ‚æ•°ç»„ï¼‰æ¥è¡¨ç¤ºæ•°æ®**ã€‚

**å­—ç¬¦ä¸²æ˜¯åŸå­ç±»å‹ï¼Œæ— æ³•åƒ Python å­—ç¬¦ä¸²ä¸€æ ·ç¼–åˆ¶ç´¢å¼•ã€‚å­—ç¬¦ä¸²çš„é•¿åº¦å¹¶ä¸æ˜¯å¼ é‡çš„ä¸€ä¸ªç»´åº¦**ã€‚æœ‰å…³æ“ä½œå­—ç¬¦ä¸²çš„å‡½æ•°ï¼Œè¯·å‚é˜… [`tf.strings`](https://tensorflow.google.cn/api_docs/python/tf/strings?hl=zh_cn)ã€‚

ä¸‹é¢æ˜¯ä¸€ä¸ªæ ‡é‡å­—ç¬¦ä¸²å¼ é‡ï¼š

```python
# Tensors can be strings, too here is a scalar string.
scalar_string_tensor = tf.constant("Gray wolf")
print(scalar_string_tensor)

tf.Tensor(b'Gray wolf', shape=(), dtype=string)
```

ä¸‹é¢æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²å‘é‡ï¼š

```python
# If we have three string tensors of different lengths, this is OK.
tensor_of_strings = tf.constant(["Gray wolf",
                                 "Quick brown fox",
                                 "Lazy dog"])
# Note that the shape is (3,). The string length is not included.
print(tensor_of_strings)

tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)
```

å­—ç¬¦ä¸²å‘é‡ï¼Œå½¢çŠ¶ï¼š`[3,]`:

<img src="https://gitee.com/veal98/images/raw/master/img/20201115111748.png" style="zoom:67%;" />

åœ¨ä¸Šé¢çš„æ‰“å°è¾“å‡ºä¸­ï¼Œ<u>`b` å‰ç¼€è¡¨ç¤º [`tf.string`](https://tensorflow.google.cn/api_docs/python/tf?hl=zh_cn#string) dtype ä¸æ˜¯ Unicode å­—ç¬¦ä¸²ï¼Œè€Œæ˜¯å­—èŠ‚å­—ç¬¦ä¸²</u>ã€‚

å¦‚æœä¼ é€’ Unicode å­—ç¬¦ï¼Œåˆ™ä¼šä½¿ç”¨ utf-8 ç¼–ç ã€‚

```python
tf.constant("ğŸ¥³ğŸ‘")
<tf.Tensor: shape=(), dtype=string, numpy=b'\xf0\x9f\xa5\xb3\xf0\x9f\x91\x8d'>
```

### â‘¡ æ“ä½œå­—ç¬¦ä¸²çš„åŸºæœ¬å‡½æ•°

åœ¨ [`tf.strings`](https://tensorflow.google.cn/api_docs/python/tf/strings?hl=zh_cn) ä¸­å¯ä»¥æ‰¾åˆ°ç”¨äºæ“ä½œå­—ç¬¦ä¸²çš„ä¸€äº›åŸºæœ¬å‡½æ•°ï¼Œæ¯”å¦‚ [`tf.strings.split`](https://tensorflow.google.cn/api_docs/python/tf/strings/split?hl=zh_cn)ï¼š

```python
# We can use split to split a string into a set of tensors
print(tf.strings.split(scalar_string_tensor, sep=" "))

tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)

# ...but it turns into a `RaggedTensor` if we split up a tensor of strings,
# as each string might be split into a different number of parts.
print(tf.strings.split(tensor_of_strings))

<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>
```

<img src="https://gitee.com/veal98/images/raw/master/img/20201115112219.png" style="zoom: 50%;" />

`tf.string.to_number`ï¼š

```python
text = tf.constant("1 10 100")
print(tf.strings.to_number(tf.strings.split(text, " ")))
tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)
```

è™½ç„¶ä¸èƒ½ä½¿ç”¨ [`tf.cast`](https://tensorflow.google.cn/api_docs/python/tf/cast?hl=zh_cn) å°†å­—ç¬¦ä¸²å¼ é‡è½¬æ¢ä¸ºæ•°å€¼ï¼Œä½†æ˜¯å¯ä»¥å…ˆå°†å…¶è½¬æ¢ä¸ºå­—èŠ‚ï¼Œç„¶åè½¬æ¢ä¸ºæ•°å€¼ã€‚

```python
byte_strings = tf.strings.bytes_split(tf.constant("Duck"))
byte_ints = tf.io.decode_raw(tf.constant("Duck"), tf.uint8)
print("Byte strings:", byte_strings)
print("Bytes:", byte_ints)
Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)
Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)
# Or split it up as unicode and then decode it
unicode_bytes = tf.constant("ã‚¢ãƒ’ãƒ« ğŸ¦†")
unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, "UTF-8")
unicode_values = tf.strings.unicode_decode(unicode_bytes, "UTF-8")

print("\nUnicode bytes:", unicode_bytes)
print("\nUnicode chars:", unicode_char_bytes)
print("\nUnicode values:", unicode_values)
Unicode bytes: tf.Tensor(b'\xe3\x82\xa2\xe3\x83\x92\xe3\x83\xab \xf0\x9f\xa6\x86', shape=(), dtype=string)

Unicode chars: tf.Tensor([b'\xe3\x82\xa2' b'\xe3\x83\x92' b'\xe3\x83\xab' b' ' b'\xf0\x9f\xa6\x86'], shape=(5,), dtype=string)

Unicode values: tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)
```

[`tf.string`](https://tensorflow.google.cn/api_docs/python/tf?hl=zh_cn#string) dtype å¯ç”¨äº TensorFlow ä¸­çš„æ‰€æœ‰åŸå§‹å­—èŠ‚æ•°æ®ã€‚[`tf.io`](https://tensorflow.google.cn/api_docs/python/tf/io?hl=zh_cn) æ¨¡å—åŒ…å«åœ¨æ•°æ®ä¸å­—èŠ‚ç±»å‹ä¹‹é—´è¿›è¡Œç›¸äº’è½¬æ¢çš„å‡½æ•°ï¼ŒåŒ…æ‹¬è§£ç å›¾åƒå’Œè§£æ csv çš„å‡½æ•°ã€‚

## 10. ä¸è§„åˆ™å¼ é‡ RaggedTensor

**å¦‚æœå¼ é‡çš„æŸä¸ªè½´ä¸Šçš„å…ƒç´ ä¸ªæ•°å¯å˜ï¼Œåˆ™ç§°ä¸ºâ€œä¸è§„åˆ™â€å¼ é‡ã€‚å¯¹äºä¸è§„åˆ™æ•°æ®ï¼Œè¯·ä½¿ç”¨ `tf.ragged.RaggedTensor`ã€‚**

ä¾‹å¦‚ï¼Œä¸‹é¢çš„ä¾‹å­æ— æ³•ç”¨è§„åˆ™å¼ é‡è¡¨ç¤ºï¼š

<img src="https://gitee.com/veal98/images/raw/master/img/20201115112952.png" style="zoom:60%;" />

```python
ragged_list = [
    [0, 1, 2, 3],
    [4, 5],
    [6, 7, 8],
    [9]]
try:
  tensor = tf.constant(ragged_list)
except Exception as e:
  print(f"{type(e).__name__}: {e}")

ValueError: Can't convert non-rectangular Python sequence to Tensor.
```

**åº”ä½¿ç”¨ [`tf.ragged.constant`](https://tensorflow.google.cn/api_docs/python/tf/ragged/constant?hl=zh_cn) æ¥åˆ›å»º [`tf.RaggedTensor`](https://tensorflow.google.cn/api_docs/python/tf/RaggedTensor?hl=zh_cn)**ï¼š

```python
ragged_tensor = tf.ragged.constant(ragged_list)
print(ragged_tensor)
<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>
```

[`tf.RaggedTensor`](https://tensorflow.google.cn/api_docs/python/tf/RaggedTensor?hl=zh_cn) çš„å½¢çŠ¶åŒ…å«æœªçŸ¥ç»´åº¦ï¼š

```python
print(ragged_tensor.shape)
(4, None) 
```

## 11. ç¨€ç–å¼ é‡ SparseTensor

åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæ•°æ®å¾ˆç¨€ç–ï¼Œæ¯”å¦‚è¯´åœ¨ä¸€ä¸ªéå¸¸å®½çš„åµŒå…¥ç©ºé—´ä¸­ã€‚ä¸ºäº†é«˜æ•ˆå­˜å‚¨ç¨€ç–æ•°æ®ï¼ŒTensorFlow æ”¯æŒ [`tf.sparse.SparseTensor`](https://tensorflow.google.cn/api_docs/python/tf/sparse/SparseTensor?hl=zh_cn) å’Œç›¸å…³è¿ç®—ã€‚

<img src="https://gitee.com/veal98/images/raw/master/img/20201115113232.png" style="zoom:67%;" />

```python
# Sparse tensors store values by index in a memory-efficient manner
sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],
                                       values=[1, 2],
                                       dense_shape=[3, 4])
print(sparse_tensor, "\n")

# We can convert sparse tensors to dense
print(tf.sparse.to_dense(sparse_tensor))

SparseTensor(indices=tf.Tensor(
[[0 0]
 [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) 

tf.Tensor(
[[1 0 0 0]
 [0 0 2 0]
 [0 0 0 0]], shape=(3, 4), dtype=int32)
```

## ğŸ“š References

- [TensorFlow 2 å®˜æ–¹æ–‡æ¡£](https://tensorflow.google.cn/tutorials/keras/classification?hl=zh_cn)
- [TensorFlow 2 å®˜æ–¹æŒ‡å—](https://tensorflow.google.cn/guide/tensor?hl=zh_cn#%E6%93%8D%E4%BD%9C%E5%BD%A2%E7%8A%B6)
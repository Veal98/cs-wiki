# 🍛 分布式相关概念

---

## 1. 什么是分布式

设计网站可扩展架构的核心思想是模块化，并在此基础之上，降低模块间的耦合性，提高模块的复用性。

所谓分布式业务系统，就是**把原来一个大块系统，拆分成多个独立的子系统，独立的子系统/模块部署在独立的服务器（集群）上**，从物理上分离模块之间的耦合关系，进一步降低耦合性提高复用性。**这些子系统/模块以消息传递及依赖调用的方式聚合成一个完整的系统**。

假设原来你做了一个 OA 系统，里面包含了权限模块、员工模块、请假模块、财务模块，一个工程，里面包含了一堆模块，模块与模块之间会互相去调用，1 台机器部署。现在如果你把这个系统给拆开，权限系统、员工系统、请假系统、财务系统 4 个系统，4 个工程，分别在 4 台机器上部署。一个请求过来，完成这个请求，这个员工系统，调用权限系统，调用请假系统，调用财务系统，4 个系统分别完成了一部分的事情，最后 4 个系统都干完了以后，才认为是这个请求已经完成了。

<img src="https://gitee.com/veal98/images/raw/master/img/20201122165939.png" style="zoom:67%;" />

> 💡 **什么是集群 ？**
>
> <u>`集群（cluster）`就是一组计算机/服务器，它们作为一个整体向用户提供一组网络资源</u>，这些单个的计算机系统就是集群的`节点（node）`。
>
> 💡 **分布式与集群的区别是什么 ？**
>
> 集群是个物理形态，分布式是个工作方式。
>
> - **分布式：** 一个业务分拆多个子业务，部署在不同的服务器上
> - **集群：** 将几台服务器集中在一起，实现同一业务

## 2. 为什么要分布式

从开发角度来讲单体应用的代码都集中在一起，而分布式系统的代码根据业务被拆分。所以，每个团队可以负责一个服务的开发，这样提升了开发效率。另外，代码根据业务拆分之后更加**便于维护和扩展**。

另外，将系统拆分成分布式之后不仅便于系统扩展和维护，更能**提高整个系统的性能**。（把整个系统拆分成不同的服务/系统，然后每个服务/系统 单独部署在一台服务器上，很大程度上提高了系统性能）

## 3. 分布式理论

当我们的单个数据库的性能产生瓶颈的时候，我们可能会对数据库进行分区，这里所说的分区指的是物理分区，分区之后可能不同的库就处于不同的服务器上了，这个时候单个数据库的 ACID 已经不能适应这种情况了，而在这种 ACID 的集群环境下，再想保证集群的 ACID 几乎是很难达到，或者即使能达到那么效率和性能会大幅下降，最为关键的是再很难扩展新的分区了，**这个时候如果再追求集群的 ACID 会导致我们的系统变得很差，此时我们就需要引入一个新的理论原则来适应这种集群的情况，就是 CAP 原理** 👇 

### ① CAP 原理

<img src="https://gitee.com/veal98/images/raw/master/img/20201122170231.png" style="zoom:50%;" />

在理论计算机科学中，`CAP定理（CAP theorem）`，又被称作`布鲁尔定理（Brewer’s theorem）`，它指出**对于一个分布式计算系统来说，不可能同时满足以下三点**：

- **一致性（Consistence）** 

  一致性指的是多个数据副本是否能保持一致的特性，在一致性的条件下，系统在执行数据更新操作之后能够从一致性状态转移到另一个一致性状态。

  <u>对系统的一个数据更新成功之后，如果所有用户都能够读取到最新的值，该系统就被认为具有强一致性。</u>

- **可用性（Availability）**

  <u>可用性指分布式系统在面对各种异常时可以提供正常服务的能力</u>，可以用系统可用时间占总时间的比值来衡量，4 个 9 的可用性表示系统 99.99% 的时间是可用的。

  在可用性条件下，要求系统提供的服务一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时间内返回结果。

- **分区容错性（Partition tolerance）** 

  网络分区指分布式系统中的节点被划分为多个区域，每个区域内部可以通信，但是区域之间无法通信。

  <u>在分区容忍性条件下，分布式系统在遇到任何网络分区故障的时候，仍然需要能对外提供一致性和可用性的服务，除非是整个网络环境都发生了故障。</u>

CAP 仅适用于原子读写的 NOSQL 场景中，并不适合数据库系统。现在的分布式系统具有更多特性比如扩展性、可用性等等，在进行系统设计和开发时，我们不应该仅仅局限在CAP问题上。

**当发生网络分区的时候，如果我们要继续服务，那么一致性和可用性只能 2 选 1。也就是说当网络分区之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必须要实现的。**

> 🚨 **注意：不是所谓的 3 选 2（不要被网上大多数文章误导了）:**
>
> 大部分人解释这一定律时，常常简单的表述为：“一致性、可用性、分区容忍性三者你只能同时达到其中两个，不可能同时达到”。实际上这是一个非常具有误导性质的说法，而且在CAP理论诞生12年之后，CAP之父也在2012年重写了之前的论文。

### ② BASE 理论

<u>在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，那么如何实现高可用性呢</u>？ 就是BASE理论，它是用来对CAP定理进行进一步扩充的。**BASE** 是 **Basically Available（基本可用）** 、**Soft-state（软状态）** 和 **Eventually Consistent（最终一致性）** 三个短语的缩写。

#### BASE 理论的核心思想

即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致性。也就是**牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要保持系统整体 “主要可用” **。

针对数据库领域，BASE 思想的主要实现是对业务数据进行拆分，让不同的数据分布在不同的机器上，以提升系统的可用性，当前主要有以下两种做法：

- 按功能划分数据库
- 分片（如开源的 Mycat、Amoeba等）。

#### BASE 理论三要素

<img src="https://gitee.com/veal98/images/raw/master/img/20201122170911.png" style="zoom:67%;" />

- **基本可用**

  <u>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统不可用。</u>

  比如：

  - **响应时间上的损失**:正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结果，但由于出现故障，查询结果的响应时间增加了1~2秒
  - **系统功能上的损失**：正常情况下，在一个电子商务网站上进行购物的时候，消费者几乎能够顺利完成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物系统的稳定性，部分消费者可能会被引导到一个降级页面

- **软状态**

  软状态指允许系统中的数据存在<u>中间状态</u>，并认为该中间状态的存在不会影响系统的整体可用性，即<u>允许系统在不同节点的数据副本之间进行数据同步的过程存在延时</u>

- **最终一致性**

  最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，<u>最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性</u>。

## 4. Paxos 一致性协议/算法

### ① 什么是 Paxos

Paxos算法是基于**消息传递**且具有**高度容错特性**的**一致性算法**，是目前公认的解决**分布式一致性**问题**最有效**的算法之一。

> 💡 早在1900年就诞生了著名的 **Paxos 经典算法** （**Zookeeper就采用了Paxos算法的近亲兄弟Zab算法**），但由于Paxos算法非常难以理解、实现、排错。所以不断有人尝试简化这一算法，直到2013年才有了重大突破：斯坦福的Diego Ongaro、John Ousterhout以易懂性为目标设计了新的一致性算法—— **Raft 算法** ，并发布了对应的论文《In Search of an Understandable Consensus Algorithm》，到现在有十多种语言实现的 Raft 算法框架，较为出名的有以Go语言实现的Etcd，它的功能类似于Zookeeper，但采用了更为主流的Rest接口。

### ② 问题产生的背景

在常见的分布式系统中，总会发生诸如**机器宕机**或**网络异常**（包括消息的延迟、丢失、重复、乱序，还有网络分区）等情况。<u>Paxos 算法需要解决的问题就是如何在一个可能发生上述异常的分布式系统中，快速且正确地在集群内部对**某个数据的值**达成**一致**，并且保证不论发生以上任何异常，都不会破坏整个系统的一致性。</u>

注：这里**某个数据的值**并不只是狭义上的某个数，它可以是一条日志，也可以是一条命令（command）。。。根据应用场景不同，**某个数据的值**有不同的含义。

### ③ 相关概念

在Paxos算法中，有三种角色：

- **提议者 Proposer**：提议一个值
- **接受者 Acceptor**：对每个提议进行投票
- **告知者 Learners**：被告知投票的结果，不参与投票过程

![](https://gitee.com/veal98/images/raw/master/img/20201122203634.png)

在具体的实现中，一个进程可能**同时充当多种角色**。比如一个进程可能**既是Proposer又是Acceptor又是Learner**。

那么，Proposer、Acceptor、Learner分别在什么情况下才能认为某个提议被选定呢？

- Proposer：只要 Proposer 发的提案被半数以上的 Acceptor 接受，Proposer 就认为该提议被选定了。
- Acceptor：只要 Acceptor 接受了某个提案，Acceptor 就认为该提议被选定了。
- Learner：Acceptor 告诉 Learner 哪个提议被选定，Learner 就认为哪个提议被选定。

### ④ 执行过程

规定一个提议包含两个字段：`[n, v]`，其中 `n` 为序号（具有唯一性），`v` 为提议值。

#### Prepare 阶段

下图演示了两个 Proposer 和三个 Acceptor 的系统中运行该算法的初始过程，每个 Proposer 都会向所有 Acceptor 发送 Prepare 请求。

![](https://gitee.com/veal98/images/raw/master/img/20201122204117.png)

当 Acceptor 接收到一个 Prepare 请求，包含的提议为 `[n1, v1]`，**并且之前还未接收过 Prepare 请求**，那么发送一个 **Prepare 响应**，设置当前接收到的提议为 `[n1, v1]`，并且保证以后不会再接受序号小于 n1 的提议。

如下图，Acceptor X 在收到 `[n=2, v=8]` 的 Prepare 请求时，由于之前没有接收过提议，因此就发送一个 `[no previous]` 的 Prepare 响应，设置当前接收到的提议为 `[n=2, v=8]`，**并且保证以后不会再接受序号小于 2 的提议**。其它的 Acceptor 类似。

![](https://gitee.com/veal98/images/raw/master/img/20201122204220.png)

如果 Acceptor 接收到一个 Prepare 请求，包含的提议为 `[n2, v2]`，**并且之前已经接收过提议** `[n1, v1]`：

- 如果 n1 > n2，那么就丢弃该提议请求；
- 否则，发送 Prepare 响应，该 Prepare 响应包含之前已经接收过的提议 `[n1, v1]`，设置当前接收到的提议为 `[n2, v2]`，并且保证以后不会再接受序号小于 n2 的提议。

如下图，Acceptor Z 收到 Proposer A 发来的 `[n=2, v=8]` 的 Prepare 请求，由于之前已经接收过 `[n=4, v=5]` 的提议，并且 n > 2，因此就抛弃该提议请求；Acceptor X 收到 Proposer B 发来的 `[n=4, v=5]` 的 Prepare 请求，因为之前接收到的提议为 `[n=2, v=8]`，并且 2 <= 4，因此就发送 `[n=2, v=8]` 的 Prepare 响应，设置当前接收到的提议为 `[n=4, v=5]`，并且保证以后不会再接受序号小于 4 的提议。Acceptor Y 类似。

![](https://gitee.com/veal98/images/raw/master/img/20201122204435.png)

#### Accept 阶段

当一个 Proposer 接收到**超过一半 Acceptor 的 Prepare 响应**时，就可以发送 Accept 请求。

Proposer A 接收到两个 Prepare 响应之后，就发送 `[n=2, v=8]` Accept 请求。该 Accept 请求会被所有 Acceptor 丢弃，因为此时所有 Acceptor 都保证不接受序号小于 4 的提议。

Proposer B 过后也收到了两个 Prepare 响应，因此也开始发送 Accept 请求。需要注意的是，**Accept 请求的 v 需要取它收到的最大提议编号对应的 v 值**，也就是 8。因此它发送 `[n=4, v=8]` 的 Accept 请求。

![](https://gitee.com/veal98/images/raw/master/img/20201122204558.png)

#### Learn 阶段

Acceptor 接收到 Accept 请求时，如果序号大于等于该 Acceptor 承诺的最小序号，那么就发送 Learn 提议给所有的 Learner。当 Learner 发现有大多数的 Acceptor 接收了某个提议，那么该提议的提议值就被 Paxos 选择出来。

### ⑤ 约束条件

- **正确性**：指只有一个提议值会生效。

  因为 Paxos 协议要求每个生效的提议被多数 Acceptor 接收，并且 Acceptor 不会接受两个不同的提议，因此可以保证正确性。

- **可终止性**：指最后总会有一个提议生效

  Paxos 协议能够让 Proposer 发送的提议朝着能被大多数 Acceptor 接受的那个提议靠拢，因此能够保证可终止性。

## 5. Raft 一致性协议/算法

Raft 也是分布式一致性协议，是对 Paxos 的简化，主要是用来竞选主节点。

### ① 单个 Candidate 的竞选

有三种节点：Follower、Candidate 和 Leader。Leader 会周期性的发送心跳包给 Follower。每个 Follower 都设置了一个随机的竞选超时时间，一般为 150ms~300ms，如果在这个时间内没有收到 Leader 的心跳包，就会变成 Candidate，进入竞选阶段。

- 下图展示一个分布式系统的最初阶段，此时只有 Follower 没有 Leader。Node A 等待一个随机的竞选超时时间之后，没收到 Leader 发来的心跳包，因此进入竞选阶段。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/111521118015898.gif)

- 此时 Node A 发送投票请求给其它所有节点。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/111521118445538.gif)

- 其它节点会对请求进行回复，如果超过一半的节点回复了，那么该 Candidate 就会变成 Leader。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/111521118483039.gif)

- 之后 Leader 会周期性地发送心跳包给 Follower，Follower 接收到心跳包，会重新开始计时。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/111521118640738.gif)

### ② 多个 Candidate 竞选

- 如果有多个 Follower 成为 Candidate，并且所获得票数相同，那么就需要重新开始投票。例如下图中 Node B 和 Node D 都获得两票，需要重新开始投票。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/111521119203347.gif)

- 由于每个节点设置的随机竞选超时时间不同，因此下一次再次出现多个 Candidate 并获得同样票数的概率很低。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/111521119368714.gif)

### ③ 数据同步

- 来自客户端的修改都会被传入 Leader。注意该修改还未被提交，只是写入日志中。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/71550414107576.gif)

- Leader 会把修改复制到所有 Follower。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/91550414131331.gif)

- Leader 会等待大多数的 Follower 也进行了修改，然后才将修改提交。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/101550414151983.gif)

- 此时 Leader 会通知的所有 Follower 让它们也提交修改，此时所有节点的值达成一致。

  ![img](https://cs-notes-1256109796.cos.ap-guangzhou.myqcloud.com/111550414182638.gif)

## 📚 References

- [CSDN - 分布式系统的经典基础理论](https://blog.csdn.net/qq_34337272/article/details/80444032)
- [Github - Advanced Java](https://doocs.gitee.io/advanced-java/#/./docs/distributed-system/distributed-system-interview)
- [博客园 - 聊聊分布式事务，再说说解决方案](https://www.cnblogs.com/savorboard/p/distributed-system-transaction-consistency.html)
- [Github - CS-Notes](http://cyc2018.gitee.io/cs-notes/#/notes/分布式?id=一、分布式锁)
- [Github - JavaGuide](https://snailclimb.gitee.io/javaguide/#/docs/system-design/distributed-system/分布式?id=二-分布式事务)
- [分布式系列文章——Paxos 算法原理与推导（图文完整版）](https://mp.weixin.qq.com/s?__biz=MzI0NDI0MTgyOA==&mid=2652037784&idx=1&sn=d8c4f31a9cfb49ee91d05bb374e5cdd5&chksm=f2868653c5f10f45fc4a64d15a5f4163c3e66c00ed2ad334fa93edb46671f42db6752001f6c0#rd)
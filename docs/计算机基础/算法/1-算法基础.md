# 🍠 算法基础

---

## 1. 什么是算法

**算法 alogorithm** 就是用来解决问题来定义的计算过程，该过程去某个值或值的集合作为**输入 Input**，并产生某个值或值的集合作为**输出 Output**。这样算法就是把输入转换成输出的计算步骤的一个序列。

⭐ **算法 + 数据结构 = 程序**。

算法只有在合适的数据结构中才能发挥作用，数据结构的不同，会影响算法的选择和效率。

l<u>一般认为，算法是由若干条指令组成的有穷序列，具有下列五个特性</u>：

- 确定性：每条指令都是明确的、无二义的

- 可行性：每条指令都必须是能够执行的

- 输入：允许有0个或多个输入量，取自特定的集合

- 输出：产生一个或多个输出，它（们）与输入量之间存在着某种特定的关系

- 有穷性：每一条指令执行的次数都是有穷的

## 2. 分析算法

我们可以从以下几个方面去分析算法：

### ① 问题的规模

**问题的规模**也即**输入规模**：将一个或多个整数，作为输入数据量的测度

比如，在一个数组中寻找 X，那么这个问题的规模就是这个数组的长度

### ② 占支配地位的运算

一般来说，我们分析算法的时候，关心的是该算法中占支配地位的运算。

比如说，在一个表中寻找数据元素 X，那么这个问题中占支配地位的运算就是 X 与表中的每一个项进行比较

再比如，对一个数组进行排序，那么这个问题中占支配地位的运算就是表中的两个数据项进行比较。

### ③ 时间复杂度

<u>用问题规模 n 的某个函数来表示算法的基本执行次数, 这个表示基本执行次数的函数称为算法的时间复杂性（度）</u>，时间复杂度用 `T(n)` (或 `T(n,m)` 等) 来表示

👇 根据定义，可以归纳出基本的计算步骤：

- 计算出基本操作的执行次数 `T(n)`

  基本操作即算法中的每条语句（以 `;` 号作为分割），语句的执行次数也叫做语句的频度。在做算法分析时，一般默认为考虑最坏的情况。

-  计算出 T(n) 的数量级：即忽略常量、低次幂和最高次幂的系数。令 `f(n)=T(n)` 的数量级

💬 举个最简单的例子：

```java
sum=0；                 
for(i=0;i<n;i++)       
	sum++；
```

上面代码中第一行频度 1，第二行频度为 n，第三行频度为 n，所以 T(n) = n+n+1 = 2n+1。忽略常量、低次幂和最高次幂的系数，则 f(n)  = n

#### 渐进时间复杂度

所谓渐进时间复杂度就是**当问题的规模趋于极限情形时（相当大）的时间复杂度**

对于算法进行特别具体的细致分析虽然很好，但在实践中的实际价值有限。对于算法的时间性质和空间性质，最重要的是其数量级和趋势，这些是分析算法效率的主要部分。而计量算法基本操作数量的规模函数中那些常量因子可以忽略不计。例如，可以认为 $3n^2$ 和 $100n^2$ 属于同一个量级，如果两个算法处理同样规模实例的代价分别为这两个函数，就认为它们的效率“差不多”，都为 $n^2$ 级。

<u>即当 n 趋近于无穷大时，如果 $lim \frac{T(n)}{f(n)}$ 的值为不等于 0 的常数，则称 `f(n)` 是 `T(n)` 的同数量级函数。记作 `T(n) = O/Ω/Θ(f(n))`</u> 

表示渐近时间复杂度的三个记号：

- `T(n) = O(f(n))`

  对于给定的函数 f(n)，若存在 $c > 0$，和正整数 $n_0 ≥ 1$，使得当 $n≥n_0$ 时，总有 $T(n)≤c * f(n)$

  该记法给出了算法时间复杂度的**上界**，复杂度不可能比 $c*f(n)$ 更大

  比如 $T(n)=O(n^2)$ 表示该算法运行时间不会超过 $cn^2$

- `T(n) = Ω(f(n))`

  若存在 $c > 0$，和正整数 $n_0≥1$，使得当 $n≥n_0$ 时，存在无穷多个 n ，使得 $T(n)≥c*f(n)$ 成立

  该记法给出了算法时间复杂度的**下界**，复杂度不可能比 $c*f(n)$ 更小

  比如 $T(n)=Ω(n^2)$ 表示该算法运行时间不会低于 $cn^2$

- `T(n) = Θ(f(n))`

  若存在 $c1,c2>0$，和正整数 $n_0≥1$，使得当 $n≥n_0$ 时，总有 $T(n)≤c1*f(n)$，且有无穷多个 n，使得$T(n)≥c2*f(n)$成立, 即：`T(n) = O(f(n))`与`T(n) = Ω(f(n))`都成立

  该记法既给出了算法时间复杂度的**上界**，也给出了**下界**

  比如：$T(n)=Θ(n^2)$ 表示该算法的运行时间不会超过 $c_1n^2$ ，不会低于 $c_2n^2 $

三种记法的图示图下：

<img src="https://gitee.com/veal98/images/raw/master/img/20200915203916.png" style="zoom: 50%;" />

👇 归纳出基本的渐进时间复杂度的计算步骤：

- 计算出基本操作的执行次数 `T(n)`

  基本操作即算法中的每条语句（以 `;` 号作为分割），语句的执行次数也叫做语句的频度。在做算法分析时，一般默认为考虑最坏的情况。

-  计算出 T(n) 的数量级：即忽略常量、低次幂和最高次幂的系数。令 `f(n)=T(n)` 的数量级
- 用 `O/Ω/Θ` 来表示渐进时间复杂度

举个例子：

```java
int num1, num2; 
for(int i=0; i<n; i++){ 
    num1 += 1;  
    for(int j=1; j<=n; j*=2){  
        num2 += num1; 
    }
}
```

- 首先计算基本操作的执行次数：

  `int num1, num2;` 频度 = 1

  `for(int i=0; i<n; i++)` 中 `int i = 0` 频度 = 1；`i<n; i++` 两条语句的频度都为 n

  同样的，循环体内的语句 `num1 += 1;` 频度 = n

  嵌套循环 `for(int j=1; j<=n; j*=2)` 中 `int j = 1` 频度 = n；`j<=n; j*=2` 两条语句的频度都为 n*log2n

  同样的，循环体内的语句 `num2 += num1;` 频度 = n*log2n

  => $T(n) = 1 + 1 + n + n + n + n + 3n*log2n = 2 + 4n + 3n*log2n$

- 然后忽略掉T(n)中的常量、低次幂和最高次幂的系数：$f(n) = n*log2n$

- 最后，取渐进时间复杂度：

  $lim(T(n)/f(n)) = 2*(1/n)*(1/log2n) + 4*(1/log2n) + 3$

  当 n 趋向于无穷大，1/n 趋向于0，1/log2n 趋向于0，所以极限等于 3 不等于 0，则称 `f(n)` 是 `T(n)` 的同数量级函数 => $T(n) = O(n*log2n)$

#### 常见的渐进时间复杂度

大 O 记法的运算规则：

<img src="https://gitee.com/veal98/images/raw/master/img/20201003154506.png" style="zoom:50%;" />

<img src="https://gitee.com/veal98/images/raw/master/img/20200915211639.png" style="zoom: 67%;" />

运行效率（越小越好）：

⭐ $O(1)<O(logn)<O(n)<O(nlogn)<O(n^2)<O(n^3)<O(2^n)<<O(n!)<O(n^n)$

![](https://gitee.com/veal98/images/raw/master/img/20200915211134.png)

👇 下面对不同的量级给出一个具体的例子：

🔴 **常数阶 O(1)**

无论代码执行了多少行，<u>只要是没有循环等复杂结构，那这个代码的时间复杂度就都是 O(1)</u>，如：

```java
int i = 1;
int j = 2;
++i;
j++;
int m = i + j;
```

上述代码在执行的时候，它消耗的时候并不随着某个变量的增长而增长，那么无论这类代码有多长，即使有几万几十万行，都可以用 O(1) 来表示它的时间复杂度。

🔴 **线性阶 O(n)**

```java
for(i=1; i<=n; ++i){
   j = i;
   j++;
}
```

这段代码，`for `循环里面的代码会执行 n 遍，因此它消耗的时间是随着 n 的变化而变化的，因此这类代码都可以用 O(n) 来表示它的时间复杂度。

🔴 **对数阶 O(logN)**

还是先来看代码：

```java
int i = 1;
while(i < n){
    i = i * 2;
}
```

从上面代码可以看到，在 `while `循环里面，<u>每次都将 i 乘以 2，乘完之后，i 距离 n 就越来越近了</u>。我们试着求解一下，假设循环 x 次之后，i 就大于 2 了，此时这个循环就退出了，也就是说 2 的 x 次方等于 n，那么 $x = log2^n$,也就是说当循环 $log2^n$ 次以后，这个代码就结束了。因此这个代码的时间复杂度为：O(logn)

🔴 **线性对数阶 O(nlogN)**

线性对数阶 O(nlogN) 其实非常容易理解，将时间复杂度为 O(logn) 的代码循环 N 遍的话，那么它的时间复杂度就是 n * O(logN)，也就是 O(nlogN)。

就拿上面的代码加一点修改来举例：

```java
for(m=1; m<n; m++){
    i = 1;
    while(i<n){
        i = i * 2;
    }
}
```

🔴 **平方阶 O(n²)**

平方阶 O(n²) 就更容易理解了，如果把 O(n) 的代码再嵌套循环一遍，它的时间复杂度就是 O(n²) 了：

```java
for(x=1; i<=n; x++)
{
   for(i=1; i<=n; i++)
    {
       j = i;
       j++;
    }
}
```

这段代码其实就是嵌套了 2 层 n 循环，它的时间复杂度就是 O(n*n)，即 O (n²)

如果将其中一层循环的 n 改成 m，即：

```java
for(x=1; i<=m; x++){
   for(i=1; i<=n; i++){
       j = i;
       j++;
    }
}
```

那它的时间复杂度就变成了 O(m*n)

#### 最坏/最好/平均时间复杂度

**最坏时间复杂度**：在规模为 n 的所有输入中，基本运算执行次数为最多的时间复杂度

**最好时间复杂度**：在规模为 n 的所有输入中，基本运算执行次数为最少的时间复杂度

**平均时间复杂度**：在规模为 n 的所有输入中，算法时间复杂度的平均值。一般假设每种输入情况以等概率出现。（其实我们上面讨论的渐进时间复杂度就是平均时间复杂度）

以顺序查找为例：

```java
public int find(int[] arr, int target) {
    int n = arr.length;
    for (int i = 0; i < n; i++) {
        // 依次遍历数组，如果找到和目标元素相同的值，在返回该值所在下标
        if (arr[i] == target) {
            return i;
        }
    }
    return -1;
}
```

- 最好情况时间复杂度：目标元素刚好在数组**第一个位置**，那么只需要一次就能找到，时间复杂度很明显是常量阶 O(1)

- 最坏情况时间复杂度：目标元素在数组**最后一个位置**或者**不在数组中**，那么得需要遍历完整个数组才能得出结果，时间复杂度为 O(n)

- 平均时间复杂度：根据大 O 记法，T(n) = O(n)

### ④ 空间复杂度

**一个程序的空间复杂度是指运行完一个程序所需内存的大小**。利用程序的空间复杂度，可以对程序的运行所需要的内存多少有个预先估计。一个程序执行时除了需要存储空间和存储本身所使用的指令、常数、变量和输入数据外，还需要一些对数据进行操作的工作单元和存储一些为现实计算所需信息的辅助空间。程序执行时所需存储空间包括以下两部分。

- 固定部分。这部分空间的大小与输入/输出的数据的个数多少、数值无关。主要包括指令空间（即代码空间）、数据空间（常量、简单变量）等所占的空间。这部分属于静态空间。

- 可变空间，这部分空间的主要包括动态分配的空间，以及递归栈所需的空间等。这部分的空间大小与算法有关。

<u>目前来说，除了在一些特殊情况下，我们都是更加注重时间复杂度，而不是空间复杂度。</u>

## 3. NP 完全性理论

### ① 基本概念

**多项式（Polynomial）时间**：对规模为 n 的输入，算法在最坏情况下的计算时间为 $O(n^k)$。将可由多项式时间算法求解的问题看作为易解的问题，将需要超多项式时间时间才能求解的问题看作难解的问题。

**判定问题**：判断是否有一种能够解决某一类问题的能行算法的研究课题。

**非确定性多项式时间**：非确定性算法将问题分解为猜测和验证两个阶段。算法的猜测阶段是非确定性的，给出问题解的一个猜测。算法的验证阶段是确定性的，验证猜测阶段给出的解的正确性。<u>设算法 A 是解一个判定问题 Q 的非确定性算法，如果 A 的验证阶段能在多项式时间内完成，则称 A 是一个多项式时间非确定性算法，也称问题 Q 是非确定性多项式时间可解的。</u>

比如，找大质数的问题。有没有一个公式，你一套公式，就可以一步步推算出来，下一个质数应该是多少呢？这样的公式是没有的。再比如，大的合数分解质因数的问题，有没有一个公式，把合数代进去，就直接可以算出，它的因子各自是多少？也没有这样的公式。这种问题的答案，是无法直接计算得到的，只能通过间接的“猜算”来得到结果。这也就是非确定性问题。而这些问题的通常有个算法，它不能直接告诉你答案是什么，但可以告诉你，某个可能的结果是正确的答案还是错误的。这个可以告诉你“猜算”的答案正确与否的算法，假如可以在多项式时间内算出来，就叫做多项式非确定性问题。

### ② P 类问题

🔸 **P 类问题（Polynomial Problem）**：所有可以在 多项式时间 内求解的 判定问题 构成 P 类问题。

### ③ NP 类问题

🔸 **NP 类问题（Non-deterministic Polynomial Problem）**：所有的 非确定性多项式时间 可解的 判定问题 构成 NP 类问题。

对于一个问题，如果我们能够在多项式时间内解决，那么我们肯定也能在多项式时间内验证某个猜测是否为这个问题的一个解，因此 **P 问题也属于 NP 问题**，或者说 P 问题是NP问题的一个子集。

### ④ NP 完全问题

#### Ⅰ 规约 Reducibility

在学习 NP 完全问题 之前，我们先了解**规约 Reducibility**的概念：

定义一个问题P可以归约到另一个问题Q，即解决 Q 的方法也可以用来解决P。这也就是说，如果我找到了解决问题Q的算法，那么这个算法也可以解决问题P。因此我们可以知道问题P一定不比问题Q要难，至少它们两个是同样难度的。

看下面两组问题。

> **1.a** 已知北京，上海，深圳，昆明，长沙，武汉，西安，台湾这八座城市中任意两座城市之间的机票价格。现在隔壁老王从北京出发，飞到其他七座城市（每个城市都要去一趟），最后回到北京。求是否存在机票总开销小于10000块的旅行方案？
>
> **1.b** 已知北京，上海，深圳，昆明，长沙，武汉，西安，台湾这八座城市中任意两座城市之间的机票价格。现在隔壁老王从北京出发，飞到其他七座城市（每个城市都要去一趟），最后回到北京。求所有旅行方案中机票总开销最少为多少钱？

> **2.a** 现有N个人要乘坐电梯到楼上，他们的体重分别为a1,a2, … ,an，电梯足够宽敞，不过最大的载重为M，试问是否存在一种方案使得电梯往返次数不多于t次，并且将这N个人全部送上楼？
>
> **2.b** 现有N个人要乘坐电梯到楼上，他们的体重分别为a1,a2, … ,an，电梯足够宽敞，不过最大的载重为M，要求设计一种方案将这N个人全部送上楼，并且电梯往返次数最少？
>
> **2.c** 在某港口放有N个集装箱，它们需要通过海运送到另一港口。已知其中第i个集装箱的长宽高和重量分别为Li,Wi,Hi,Mi。负责运载的轮船其货仓的长宽高和载重分别为L,W,H,M。要求设计一种方案将这些集装箱全部海运到另一港口，并且使用的轮船数目最少。

在第一组问题中，如果我们知道了问题1.b的解，那我们也就知道了问题1.a的解。并且用来求解问题1.b的方法也可用在求解问题1.a上。因此这组问题中，1.a可以归约到1.b

同样，在第二组问题中，如果我们知道了问题2.b的解，那我们也就知道了问题2.a的解。如果我们能解出2.c，那么我们也一定能解出2.b，然后解出2.a。这里主要是想强调一下归约的可传递性：**如果P可归约到Q，Q可归约到R，那么P可以归约到R**。

#### Ⅱ NP 完全问题

🔸 **NPC 类问题（NP 完全问题）**：<u>有没有这样一种 NP 问题，所有的 NP 问题都可以归约到它。也就是说，解决了这个问题，也就同时解决了所有的 NP 问题。即 `P = NP`</u>。不过，**目前还没有一个 NPC 类问题有多项式时间算法**。

> 在 1971 年，斯蒂芬·库克找到了第一个这样的问题：**可满足性问题**。简要来说，就是对于N个布尔类型的变量，它们之间采用“与”，“或”，“非”这样的逻辑运算符连接，那么这些变量能否找到一组合适的取值，使得最终的运算结果为真。与之相同的是逻辑电路问题，它其实就是可满足性问题的数字电路实现，用高电平和低电平表示真和假，用与门，或门和非门表示逻辑运算符。
>
> 伯克利的教授理查德·卡普在读过库克的论文之后，发现有一种方法可以**把可满足性问题归约到团问题**。团问题大致是这样一类问题：对于任意两个人，要么是微信好友，要么不是微信好友。那么能否找到一个人数为50个人的团体，使得他们两两之间彼此都是微信好友？因为库克证明了可满足性问题是NP问题中最难的问题，而卡普得到的则是，团问题不比可满足性问题要简单，至少它们一样难。卡普不仅证明了团问题是NP问题中最难的一个，而且他还找到了19个同样难度的重要问题，比如哈密顿回路，旅行商问题，最大割问题等等。1972年，他在他的论文《Reducibility Among Combinatorial Problems》中，提出了这 21 个 NP 中最难的问题，后来被称为 NP 完全问题。

现在的很多设计都是基于 `P ≠ NP` 之上的，那么假如某一天某一位大牛证明了 `P = NP`，那将对我们的生活产生怎样的改变呢？

举几个栗子：在生物学方面，我们能够很快地完成基因测序工作；对于一个机器学习系统，能够很快的得到令人满意的特征选择；如果从犯罪现场提取到罪犯的DNA，我们能在第一时间确定他是谁。不过，这也同样会带来问题：比如当前信息在网络传输中使用MD5来校验，以检查是否在中途被篡改，在 P=NP 之后，这种校验方式就不再可靠了。同样，对于RSA加密算法，也可以很快地计算出密钥。因为RSA是基于计算大数的乘法和除法很容易，而对大数进行因式分解非常难而设计的，因式分解被认为是NP问题。

### ⑤ NP 难问题

前面说过 NPC 问题是 NP 问题中最难的一类问题，那么比 NPC 问题还要难的问题是什么样子呢？**首先可以由NPC 问题归约到它，其次它不一定是 NP 问题。这一类问题称为 NP 难问题（NP-Hard）。**

前面说过如果 P=NP，那么所有的NP问题都存在有效的解决方案，而**对于 NP 难问题来说，即使 P=NP，也不一定存在有效的解决方案**。

<img src="https://gitee.com/veal98/images/raw/master/img/20201003172050.png" style="zoom: 50%;" />



## 💯 课后习题

> 🔈 题目来源 《计算机算法与分析 王晓东 - 第5版》

### ① 求下列函数的渐进表达式

- $3n^2 + 10n$

  $< 3n^2 + 10n^2 = 13n^2 = O(n^2)$

- $n^2 / 10 + 2^n$

  $< 2^n + 2^n = 2*2^n = O(2^n)$

- $21 + 1/n$

  $< 21 + 1 = 22 = O(1)$

- $log(n^3)$

  $=3log(n)=O(log(n))$

- $10log(3^n)$

  $= (10log3)n = O(n) $

### ② O(1) 和 O(2) 的区别

O(1) = O(2)，用 O(1) 、O(2) 表示同一个函数时，差别仅在于其中的常数因子。

### ③ 求函数渐进阶

<img src="https://gitee.com/veal98/images/raw/master/img/20201003161240.png" style="zoom: 45%;" />

- （1）由于 $logn^2$ 和 $logn + 5$ 并无直接的大小关系， $logn^2$ 可能小于某个常数乘以 $logn + 5$，也可能大于某个常数乘以 $logn + 5$。所以 $f(n) =θ(g(n))$

- （2）$log(n) < √n$，$f(n) = 2log(n) < 2 * √n = 2 * g(n)$。所以 $f(n) = O(g(n))$

- （3）$log(n) < n$， $f(n) = n > 2 * log(n) = 1 * g(n)$。所以 $f(n) =  Ω(g(n))$

- （4）$f(n) =  Ω(g(n))$

- （5）常数级别的比较： $f(n) =θ(g(n))$

- （6）$f(n) =  Ω(g(n))$

- （7）$2^n > n^2$，$f(n) > 1/100 * g(n)$。所以 $f(n) =  Ω(g(n))$

- （8）$2^n < 3^n$。所以 $f(n) =  O(g(n))$

## 📚 References

- 《算法导论 — 第 3 版 机械工业出版社》
- 《计算机算法与分析 王晓东 - 第5版》
- [NP 完全性理论简介](https://blog.csdn.net/liusiqian0209/article/details/49837447)
- [算法时间复杂度的计算 [整理]](https://www.iteye.com/blog/univasity-1164707)
- [算法—时间复杂度](https://blog.csdn.net/user11223344abc/article/details/81485842)
- [最好、最坏、平均、均摊时间复杂度分析](https://blog.csdn.net/weixin_38483589/article/details/84262167)
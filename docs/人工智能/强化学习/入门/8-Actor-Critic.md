# ğŸ­ æ¼”å‘˜-è¯„è®ºå‘˜ç®—æ³• Actor-Critic

---

â­ ä»Šå¤©æˆ‘ä»¬æ¥è¯´è¯´å¼ºåŒ–å­¦ä¹ ä¸­çš„ä¸€ç§ç»“åˆä½“ Actor Critic (æ¼”å‘˜è¯„åˆ¤å®¶), **å®ƒåˆå¹¶äº† ä»¥å€¼ä¸ºåŸºç¡€ (æ¯”å¦‚ Q learning) å’Œ ä»¥åŠ¨ä½œæ¦‚ç‡ä¸ºåŸºç¡€ (æ¯”å¦‚ Policy Gradients) ä¸¤ç±»å¼ºåŒ–å­¦ä¹ ç®—æ³•**.

## 1. Actor-Critic æ–¹æ³•ï¼ˆACï¼‰

<img src="https://gitee.com/veal98/images/raw/master/img/20201113160456.png" style="zoom:50%;" />

- ğŸ’› **ç­–ç•¥ç½‘ç»œ** - Actor-Critic ä¸­çš„ **ã€Actorã€‘** ï¼šå‰èº«æ˜¯ Policy Gradients, è¿™èƒ½è®©å®ƒæ¯«ä¸è´¹åŠ›åœ°åœ¨è¿ç»­åŠ¨ä½œä¸­é€‰å–åˆé€‚çš„åŠ¨ä½œ.

  å¯¹äº Actor ç½‘ç»œ $ğœ‹_ğœƒ$ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–å›æŠ¥æœŸæœ›ï¼Œé€šè¿‡ $ğœ•ğ½(ğœƒ) / ğœ•ğœƒ$ åå¯¼æ•°æ¥æ›´æ–°ç­–ç•¥ç½‘ç»œçš„å‚æ•° ğœƒï¼š

  <img src="https://gitee.com/veal98/images/raw/master/img/20201113160646.png" style="zoom: 50%;" />

- ğŸ’› **ä»·å€¼ç½‘ç»œ** - Actor Critic ä¸­çš„ **ã€Criticã€‘** ï¼šå‰èº«æ˜¯ Q-learning æˆ–è€…å…¶ä»–çš„ Value-Based çš„å­¦ä¹ æ³• , ç”¨äºè¯„ä¼°å½“å‰çŠ¶æ€çš„å¥½åã€‚èƒ½è¿›è¡Œå•æ­¥æ›´æ–°, è€Œä¼ ç»Ÿçš„ Policy Gradients åˆ™æ˜¯å›åˆæ›´æ–°, è¿™é™ä½äº†å­¦ä¹ æ•ˆç‡.

  å¯¹äº Critic ç½‘ç»œ $ğ‘‰_ğœ™^ğœ‹$ï¼Œç›®æ ‡æ˜¯åœ¨é€šè¿‡ MC æ–¹æ³•æˆ–è€… TD æ–¹æ³•è·å¾—å‡†ç¡®çš„ $ğ‘‰_ğœ™^ğœ‹(ğ‘ ğ‘¡)$ å€¼å‡½æ•°ä¼°è®¡ï¼š

  <img src="https://gitee.com/veal98/images/raw/master/img/20201113160851.png" style="zoom:50%;" />

ğŸ”¸ **ä¸€å¥è¯æ¦‚æ‹¬ Actor Critic æ–¹æ³•**:

ç»“åˆäº† Policy Gradient (Actor) å’Œ å€¼å‡½æ•°è¿‘ä¼¼ Function Approximation (Critic) çš„æ–¹æ³•. â­ **`Actor` åŸºäºæ¦‚ç‡é€‰è¡Œä¸º, `Critic` åŸºäº `Actor` çš„è¡Œä¸ºè¯„åˆ¤è¡Œä¸ºçš„å¾—åˆ†, `Actor` æ ¹æ® `Critic` çš„è¯„åˆ†ä¿®æ”¹é€‰è¡Œä¸ºçš„æ¦‚ç‡**.

> ğŸ’¡ **`Actor` ä¿®æ”¹è¡Œä¸ºæ—¶å°±åƒè’™ç€çœ¼ç›ä¸€ç›´å‘å‰å¼€è½¦, `Critic` å°±æ˜¯é‚£ä¸ªæ‰¶æ–¹å‘ç›˜æ”¹å˜ `Actor` å¼€è½¦æ–¹å‘çš„.**
>
> æˆ–è€…è¯´è¯¦ç»†ç‚¹, å°±æ˜¯ `Actor` åœ¨è¿ç”¨ Policy Gradient çš„æ–¹æ³•è¿›è¡Œ Gradient ascent çš„æ—¶å€™, ç”± `Critic` æ¥å‘Šè¯‰ä»–, è¿™æ¬¡çš„ Gradient ascent æ˜¯ä¸æ˜¯ä¸€æ¬¡æ­£ç¡®çš„ ascent, å¦‚æœè¿™æ¬¡çš„å¾—åˆ†ä¸å¥½, é‚£ä¹ˆå°±ä¸è¦ ascent é‚£ä¹ˆå¤š.

ğŸ”¸ **Actor Critic æ–¹æ³•çš„ä¼˜åŠ¿**: å¯ä»¥è¿›è¡Œå•æ­¥æ›´æ–°, æ¯”ä¼ ç»Ÿçš„ Policy Gradient è¦å¿«.

ğŸ”¸ **Actor Critic æ–¹æ³•çš„åŠ£åŠ¿**: å–å†³äº Critic çš„ä»·å€¼åˆ¤æ–­, ä½†æ˜¯ Critic éš¾æ”¶æ•›, å†åŠ ä¸Š Actor çš„æ›´æ–°, å°±æ›´éš¾æ”¶æ•›. ä¸ºäº†è§£å†³æ”¶æ•›é—®é¢˜, Google Deepmind æå‡ºäº† `Actor Critic` å‡çº§ç‰ˆ `Deep Deterministic Policy Gradient`. åè€…èåˆäº† DQN çš„ä¼˜åŠ¿, è§£å†³äº†æ”¶æ•›éš¾çš„é—®é¢˜. æˆ‘ä»¬ä¹‹åä¹Ÿä¼šè¦è®²åˆ° Deep Deterministic Policy Gradient. 

## 2. Advantage AC ç®—æ³•ï¼ˆA2Cï¼‰

ä¸Šé¢ä»‹ç»çš„é€šè¿‡è®¡ç®—ä¼˜åŠ¿å€¼å‡½æ•° $ğ´^ğœ‹(ğ‘ , ğ‘)$ çš„ Actor Critic ç®—æ³•ç§°ä¸º `Advantage Actor-Critic ç®—æ³•`ï¼Œå®ƒæ˜¯ç›®å‰ä½¿ç”¨ Actor Critic æ€æƒ³çš„ä¸»æµç®—æ³•ä¹‹ä¸€

<img src="https://gitee.com/veal98/images/raw/master/img/20201113161620.png" style="zoom:50%;" />

> ğŸ“œ å…¶å® Actor Critic ç³»åˆ—ç®—æ³•ä¸ä¸€å®šè¦ä½¿ç”¨ä¼˜åŠ¿å€¼å‡½æ•° $ğ´^ğœ‹(ğ‘ , ğ‘)$ï¼Œè¿˜å¯ä»¥æœ‰å…¶å®ƒå˜ç§

## 3. Asynchronous Advantage AC ç®—æ³•ï¼ˆA3Cï¼‰

Reinforcement learning æœ‰ä¸€ä¸ªé—®é¢˜å°±æ˜¯å®ƒå¾ˆæ…¢ã€‚é‚£æ€ä¹ˆå¢åŠ è®­ç»ƒçš„é€Ÿåº¦å‘¢ï¼Ÿå°±æ˜¯ `Asynchronous(å¼‚æ­¥çš„) Advantage Actor-Critic` 

A3C æ˜¯ DeepMind åŸºäº Advantage Actor-Criticï¼ŒA2C ç®—æ³•æå‡ºæ¥çš„å¼‚æ­¥ç‰ˆæœ¬ï¼Œ**å°† Actor-Critic ç½‘ç»œéƒ¨ç½²åœ¨å¤šä¸ªçº¿ç¨‹ä¸­åŒæ—¶è¿›è¡Œè®­ç»ƒï¼Œå¹¶é€šè¿‡å…¨å±€ç½‘ç»œæ¥åŒæ­¥å‚æ•°ã€‚è¿™ç§å¼‚æ­¥è®­ç»ƒçš„æ¨¡å¼å¤§å¤§æå‡äº†è®­ç»ƒæ•ˆç‡ï¼Œè®­ç»ƒé€Ÿåº¦æ›´å¿«ï¼Œå¹¶ä¸”ç®—æ³•æ€§èƒ½ä¹Ÿæ›´å¥½**ã€‚

<img src="https://gitee.com/veal98/images/raw/master/img/20201113162317.png" style="zoom: 62%;" />

æ–¹æ³•æ­¥éª¤ï¼š

- **æ¯ä¸ª worker éƒ½ä¼š copy å…¨å±€å‚æ•°**
- æ¯ä¸ª worker éƒ½ä¸ç¯å¢ƒè¿›è¡Œäº’åŠ¨ï¼Œå¹¶å¾—åˆ° sample data
- è®¡ç®—æ¢¯åº¦
- æ›´æ–°å…¨å±€å‚æ•°





## ğŸ“š References

- [Bilibili - æå®æ¯…ã€Šæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‹](https://www.bilibili.com/video/BV1MW411w79n)
- [Github - LeeDeepRL - Notes](https://datawhalechina.github.io/leedeeprl-notes/)
- [CSDN - æå®æ¯…æ·±åº¦å¼ºåŒ–å­¦ä¹ ç¬”è®° - jessie](https://blog.csdn.net/cindy_1102/article/details/87904928)
- ğŸ‘ [Github - Deep-Learning-with-TensorFlow-book](https://github.com/dragen1860/Deep-Learning-with-TensorFlow-book)
- [Github - DeepRL-TensorFlow2](https://github.com/marload/DeepRL-TensorFlow2) - ğŸ‹ Simple implementations of various popular Deep Reinforcement Learning algorithms using TensorFlow2
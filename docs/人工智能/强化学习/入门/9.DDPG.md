# ğŸ¨ Deep Deterministic Policy Gradientï¼ˆDDPGï¼‰

---

**Actor-Critic æ¶‰åŠåˆ°äº†ä¸¤ä¸ªç¥ç»ç½‘ç»œ, è€Œä¸”æ¯æ¬¡éƒ½æ˜¯åœ¨è¿ç»­çŠ¶æ€ä¸­æ›´æ–°å‚æ•°, æ¯æ¬¡å‚æ•°æ›´æ–°å‰åéƒ½å­˜åœ¨ç›¸å…³æ€§, å¯¼è‡´ç¥ç»ç½‘ç»œåªèƒ½ç‰‡é¢çš„çœ‹å¾…é—®é¢˜, ç”šè‡³å¯¼è‡´ç¥ç»ç½‘ç»œå­¦ä¸åˆ°ä¸œè¥¿**. æƒ³æƒ³æˆ‘ä»¬ä¹‹å‰ä»‹ç»çš„DQNæ˜¯å¦‚ä½•è§£å†³çš„è¿™ä¸ªé—®é¢˜çš„ï¼Ÿå°±æ˜¯å»ºç«‹äº†ä¸¤ä¸ªç½‘ç»œï¼Œä¸€ä¸ªQç›®æ ‡ç½‘ç»œï¼Œä¸€ä¸ªQç°å®ç½‘ç»œï¼ŒåŒæ—¶ä½¿ç”¨äº†ç»éªŒå›æ”¾æœºåˆ¶ã€‚é‚£ä¹ˆå¦‚æœåœ¨ `Actor-Critic` ç½‘ç»œç»“æ„ä¸­åŠ å…¥è¿™ä¸¤ä¸ªæœºåˆ¶ï¼Œå°±å¾—åˆ°äº†ä¸€ç§æ–°çš„å¼ºåŒ–å­¦ä¹ æ¨¡å‹ï¼š`Deep Deterministic Policy Gradient`ï¼Œç®€ç§°`DDPG`ã€‚å¯ä»¥è¯´ **Actor-Critic + DQN = DDPG**ã€‚

![](https://gitee.com/veal98/images/raw/master/img/20201102102711.png)

## 1. Deep å’Œ DQN

Deep é¡¾åæ€ä¹‰, å°±æ˜¯èµ°å‘æ›´æ·±å±‚æ¬¡, æˆ‘ä»¬åœ¨ DQN ä¸­æåˆ°è¿‡, ä½¿ç”¨ä¸€ä¸ªè®°å¿†åº“å’Œä¸¤å¥—ç»“æ„ç›¸åŒä½†å‚æ•°æ›´æ–°é¢‘ç‡ä¸åŒçš„ç¥ç»ç½‘ç»œèƒ½æœ‰æ•ˆä¿ƒè¿›å­¦ä¹ . é‚£æˆ‘ä»¬ä¹ŸæŠŠè¿™ç§æ€æƒ³è¿ç”¨åˆ° DDPG å½“ä¸­, ä½¿ DDPG ä¹Ÿå…·å¤‡è¿™ç§ä¼˜è‰¯å½¢å¼. ä½†æ˜¯ DDPG çš„ç¥ç»ç½‘ç»œå½¢å¼å´æ¯” DQN çš„è¦å¤æ‚ä¸€ç‚¹ç‚¹.

![](https://gitee.com/veal98/images/raw/master/img/20201102102811.png)

## 2. Deterministic Policy Gradient

Policy gradient ç›¸æ¯”å…¶ä»–çš„å¼ºåŒ–å­¦ä¹ æ–¹æ³•, å®ƒèƒ½è¢«ç”¨æ¥åœ¨è¿ç»­åŠ¨ä½œä¸Šè¿›è¡ŒåŠ¨ä½œçš„ç­›é€‰ . è€Œä¸”ç­›é€‰çš„æ—¶å€™æ˜¯æ ¹æ®æ‰€å­¦ä¹ åˆ°çš„åŠ¨ä½œåˆ†å¸ƒéšæœºè¿›è¡Œç­›é€‰, è€Œ Deterministic æ”¹å˜äº†è¾“å‡ºåŠ¨ä½œçš„è¿‡ç¨‹, æ–©é’‰æˆªé“çš„åªåœ¨è¿ç»­åŠ¨ä½œä¸Šè¾“å‡ºä¸€ä¸ªåŠ¨ä½œå€¼.

![](https://gitee.com/veal98/images/raw/master/img/20201102105726.png)

æˆ‘ä»¬çœ‹ä¸€ä¸‹ DDPG å…³äºæ­¤çš„æ¦‚å¿µå®šä¹‰ï¼š

ğŸ”¸ **ç¡®å®šæ€§è¡Œä¸ºç­–ç•¥ `Î¼`** : å®šä¹‰ä¸ºä¸€ä¸ªå‡½æ•°ï¼Œæ¯ä¸€æ­¥çš„è¡Œä¸ºå¯ä»¥é€šè¿‡ $a_{t} = \mu(s_{t}) $ è®¡ç®—è·å¾—ã€‚

ğŸ”¸ **ç­–ç•¥ç½‘ç»œ**ï¼šç”¨ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œå¯¹ Î¼ å‡½æ•°è¿›è¡Œæ¨¡æ‹Ÿï¼Œè¿™ä¸ªç½‘ç»œæˆ‘ä»¬å°±å«åšç­–ç•¥ç½‘ç»œï¼Œå…¶å‚æ•°ä¸º $\theta^{\mu}$

ğŸ”¸ **behavior policy `Î²`** : åœ¨ RL è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬è¦å…¼é¡¾ 2 ä¸ª e : exploration å’Œ exploitï¼š

<u>exploration çš„ç›®çš„æ˜¯æ¢ç´¢æ½œåœ¨çš„æ›´ä¼˜ç­–ç•¥</u>ï¼Œæ‰€ä»¥è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œ**æˆ‘ä»¬ä¸º action çš„å†³ç­–æœºåˆ¶å¼•å…¥éšæœºå™ªå£°ï¼Œå°†action çš„å†³ç­–ä»ç¡®å®šæ€§è¿‡ç¨‹å˜ä¸ºä¸€ä¸ªéšæœºè¿‡ç¨‹ï¼Œ å†ä»è¿™ä¸ªéšæœºè¿‡ç¨‹ä¸­é‡‡æ ·å¾—åˆ°ç¡®å®šçš„ actionï¼Œä¸‹è¾¾ç»™ç¯å¢ƒæ‰§è¡Œ**ã€‚è¿‡ç¨‹å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![](https://gitee.com/veal98/images/raw/master/img/20201113165016.png)

ä¸Šè¿°è¿™ä¸ªç­–ç•¥å«åš behavior ç­–ç•¥ï¼Œç”¨ Î² æ¥è¡¨ç¤º, è¿™æ—¶ RL çš„è®­ç»ƒæ–¹å¼å«åš off-policy.

è¿™é‡Œä¸ $\epsilon-greedy$ çš„æ€è·¯æ˜¯ç±»ä¼¼çš„ã€‚

DDPGä¸­ï¼Œä½¿ç”¨ [Uhlenbeck-Ornsteinéšæœºè¿‡ç¨‹](https://en.wikipedia.org/wiki/Ornsteinâ€“Uhlenbeck_process)ï¼ˆä¸‹é¢ç®€ç§° `UO` è¿‡ç¨‹ï¼‰ï¼Œä½œä¸ºå¼•å…¥çš„éšæœºå™ªå£°ã€‚UOè¿‡ç¨‹åœ¨æ—¶åºä¸Šå…·å¤‡å¾ˆå¥½çš„ç›¸å…³æ€§ï¼Œå¯ä»¥ä½¿ agent å¾ˆå¥½çš„æ¢ç´¢å…·å¤‡åŠ¨é‡å±æ€§çš„ç¯å¢ƒã€‚

ğŸš¨ **æ³¨æ„**ï¼š<u>è¿™ä¸ª `Î²` ä¸æ˜¯æˆ‘ä»¬æƒ³è¦å¾—åˆ°çš„æœ€ä¼˜ç­–ç•¥ï¼Œä»…ä»…åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œç”Ÿæˆä¸‹è¾¾ç»™ç¯å¢ƒçš„ actionï¼Œ ä»è€Œè·å¾—æˆ‘ä»¬æƒ³è¦çš„æ•°æ®é›†ï¼Œæ¯”å¦‚çŠ¶æ€è½¬æ¢ (transitions)ã€æˆ–è€… agent çš„è¡Œèµ°è·¯å¾„ç­‰ï¼Œç„¶ååˆ©ç”¨è¿™ä¸ªæ•°æ®é›†å»è®­ç»ƒç­–ç•¥ `Î¼` ï¼Œä»¥è·å¾—æœ€ä¼˜ç­–ç•¥ã€‚åœ¨æµ‹è¯• test å’Œè¯„ä¼° evaluation æ—¶ï¼Œä½¿ç”¨ `Î¼`ï¼Œä¸ä¼šå†ä½¿ç”¨ `Î²`ã€‚</u>

## 3. DDPG ç¥ç»ç½‘ç»œ

ç°åœ¨æˆ‘ä»¬æ¥è¯´è¯´ DDPG ä¸­æ‰€ç”¨åˆ°çš„ç¥ç»ç½‘ç»œ. å®ƒå…¶å®å’Œæˆ‘ä»¬ä¹‹å‰æåˆ°çš„ Actor-Critic å½¢å¼å·®ä¸å¤š, ä¹Ÿéœ€è¦æœ‰åŸºäº ç­–ç•¥ Policy çš„ç¥ç»ç½‘ç»œï¼ˆ`ç­–ç•¥ç½‘ç»œ`ï¼‰ å’ŒåŸºäº ä»·å€¼ Value çš„ç¥ç»ç½‘ç»œï¼ˆ`ä»·å€¼ç½‘ç»œ / Q ç½‘ç»œ`ï¼‰, ä½†æ˜¯ä¸ºäº†ä½“ç° DQN çš„æ€æƒ³, æ¯ç§ç¥ç»ç½‘ç»œæˆ‘ä»¬éƒ½éœ€è¦å†ç»†åˆ†ä¸ºä¸¤ä¸ªï¼ˆ`online ç½‘ç»œ`å’Œ `target ç½‘ç»œ`ï¼‰ï¼š

- **ã€ç­–ç•¥ç½‘ç»œã€‘**Policy Gradient è¿™è¾¹, æˆ‘ä»¬æœ‰**ä¼°è®¡ç½‘ç»œ online**å’Œ**ç°å®ç½‘ç»œ target**, <u>ä¼°è®¡ç½‘ç»œç”¨æ¥è¾“å‡ºå®æ—¶çš„åŠ¨ä½œ, ä¾› actor åœ¨ç°å®ä¸­å®è¡Œ. è€Œç°å®ç½‘ç»œåˆ™æ˜¯ç”¨æ¥æ›´æ–°ä»·å€¼ç½‘ç»œç³»ç»Ÿçš„</u>. 
- **ã€Q ç½‘ç»œã€‘**æˆ‘ä»¬å†æ¥çœ‹çœ‹ä»·å€¼ç³»ç»Ÿè¿™è¾¹, æˆ‘ä»¬ä¹Ÿæœ‰ç°å®ç½‘ç»œå’Œä¼°è®¡ç½‘ç»œ, ä»–ä»¬éƒ½åœ¨è¾“å‡ºè¿™ä¸ªçŠ¶æ€çš„ä»·å€¼, è€Œè¾“å…¥ç«¯å´æœ‰ä¸åŒ, çŠ¶æ€ç°å®ç½‘ç»œè¿™è¾¹ä¼šæ‹¿ç€ä»åŠ¨ä½œç°å®ç½‘ç»œæ¥çš„åŠ¨ä½œåŠ ä¸ŠçŠ¶æ€çš„è§‚æµ‹å€¼åŠ ä»¥åˆ†æ, è€ŒçŠ¶æ€ä¼°è®¡ç½‘ç»œåˆ™æ˜¯æ‹¿ç€å½“æ—¶ Actor æ–½åŠ çš„åŠ¨ä½œå½“åšè¾“å…¥.åœ¨å®é™…è¿ç”¨ä¸­, DDPG çš„è¿™ç§åšæ³•çš„ç¡®å¸¦æ¥äº†æ›´æœ‰æ•ˆçš„å­¦ä¹ è¿‡ç¨‹.

![](https://gitee.com/veal98/images/raw/master/img/20201102110538.png)

â­ æˆ‘ä»¬é‡‡ç”¨äº†ç±»ä¼¼ DQN çš„åŒç½‘ç»œç»“æ„ï¼ŒåŒæ ·çš„æˆ‘ä»¬**åªéœ€è¦è®­ç»ƒ online ç½‘ç»œçš„å‚æ•°ï¼Œè€Œ target ç½‘ç»œçš„å‚æ•°æ˜¯ç”±å‰é¢ä¸¤ä¸ªç½‘ç»œæ¯éš”ä¸€å®šçš„æ—¶é—´å¤åˆ¶è¿‡å»çš„**ã€‚

<img src="https://gitee.com/veal98/images/raw/master/img/20201113165957.png" style="zoom: 80%;" />

åœ¨è®­ç»ƒå®Œä¸€ä¸ª mini-batch çš„æ•°æ®ä¹‹åï¼Œé€šè¿‡æ¢¯åº¦ä¸‹é™ç®—æ³•æ›´æ–° online ç½‘ç»œçš„å‚æ•°ï¼Œç„¶åå†é€šè¿‡ **soft update ç®—æ³•**æ›´æ–° target ç½‘ç»œçš„å‚æ•°ï¼š

<img src="https://gitee.com/veal98/images/raw/master/img/20201113170145.png" style="zoom: 80%;" />

## 4. DDPG æ•´ä½“ç®—æ³•è¯¦è§£

![](https://gitee.com/veal98/images/raw/master/img/20201113170644.png)

ğŸš• åˆå§‹åŒ– actor / critic çš„ online ç¥ç»ç½‘ç»œå‚æ•°: $\theta^{Q}$ å’Œ $\theta^{\mu}$ ï¼› 

ğŸš• å°† online  ç½‘ ç»œçš„å‚æ•°æ‹·è´ç»™å¯¹åº”çš„ target ç½‘ç»œå‚æ•° ï¼š $\theta^{Q{\prime}} \leftarrow \theta^{Q}$, $\theta^{\mu{\prime}} \leftarrow \theta^{\mu} $ ï¼›

ğŸš• åˆå§‹åŒ– replay memory buffer R ;

ğŸš• for each episode:

- åˆå§‹åŒ– UO éšæœºè¿‡ç¨‹ï¼›

- for t = 1, T:

  - actor æ ¹æ® behavior ç­–ç•¥é€‰æ‹©ä¸€ä¸ª $a_t$ , ä¸‹è¾¾ç»™ç¯å¢ƒæ‰§è¡Œè¯¥åŠ¨ä½œ

    <img src="https://gitee.com/veal98/images/raw/master/img/20201113171214.png" style="zoom:80%;" />

    behaviorç­–ç•¥æ˜¯ä¸€ä¸ªæ ¹æ®å½“å‰ online ç­–ç•¥ Î¼ å’Œéšæœº UO å™ªå£°ç”Ÿæˆçš„éšæœºè¿‡ç¨‹, ä»è¿™ä¸ªéšæœºè¿‡ç¨‹é‡‡æ ·è·å¾— $a_{t}$ çš„å€¼ã€‚

  - ç¯å¢ƒæ‰§è¡ŒåŠ¨ä½œ $a_t$ å¹¶äº§ç”Ÿæ–°çš„çŠ¶æ€ $s_{t+1}$

  - actor å°†è¿™ä¸ªçŠ¶æ€è½¬æ¢è¿‡ç¨‹(transition): $(s_{t}, a_{t}, r_{t}ï¼Œs_{t+1}) $ å­˜å…¥replay memory buffer R ä¸­ï¼Œä½œä¸ºè®­ç»ƒ online ç½‘ç»œçš„æ•°æ®é›†

  - ä» replay memory buffer Rä¸­ï¼Œéšæœºé‡‡æ · N ä¸ª transition æ•°æ®ï¼Œä½œä¸º online ç­–ç•¥ç½‘ç»œã€ online Q ç½‘ç»œçš„ä¸€ä¸ª mini-batch è®­ç»ƒæ•°æ®ã€‚æˆ‘ä»¬ç”¨$(s_{i}, a_{i}, r_{i}ï¼Œs_{i+1}) $è¡¨ç¤º mini-batch ä¸­çš„å•ä¸ª transition æ•°æ®

  - è®¡ç®— online Qç½‘ç»œçš„æ¢¯åº¦ gradientï¼š
    Q ç½‘ç»œçš„ loss å®šä¹‰ï¼šä½¿ç”¨ç±»ä¼¼äºç›‘ç£å¼å­¦ä¹ çš„æ–¹æ³•ï¼Œå®šä¹‰ lossä¸º MSE: mean squared errorï¼š

    <img src="https://gitee.com/veal98/images/raw/master/img/20201113171548.png" style="zoom:80%;" />

    å…¶ä¸­ï¼Œ $y_{i}$  å¯ä»¥çœ‹åš"æ ‡ç­¾"ï¼š

    <img src="https://gitee.com/veal98/images/raw/master/img/20201113171622.png" style="zoom:80%;" />

    åŸºäºæ ‡å‡†çš„åå‘ä¼ æ’­æ–¹æ³• back-propagationï¼Œå°±å¯ä»¥æ±‚å¾— L é’ˆå¯¹  $\theta^{Q}$ çš„æ¢¯åº¦ gradientï¼š$ \triangledown_{\theta^{Q}} L $ ã€‚

    æœ‰ä¸¤ç‚¹å€¼å¾—æ³¨æ„ï¼š

    â‘  $y_{i}$  çš„è®¡ç®—ï¼Œä½¿ç”¨çš„æ˜¯ target ç­–ç•¥ç½‘ç»œ Î¼ â€²   å’Œ target Q ç½‘ç»œ Q â€²  ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†Qç½‘ç»œå‚æ•°çš„å­¦ä¹ è¿‡ç¨‹æ›´åŠ ç¨³å®šï¼Œæ˜“äºæ”¶æ•›ã€‚

    â‘¡ è¿™ä¸ªæ ‡ç­¾æœ¬èº«ä¾èµ–äºæˆ‘ä»¬æ­£åœ¨å­¦ä¹ çš„ target ç½‘ç»œï¼Œè¿™æ˜¯åŒºåˆ«äºç›‘ç£å¼å­¦ä¹ çš„åœ°æ–¹ã€‚
    
  - update online Qï¼š é‡‡ç”¨ Adam optimizer æ›´æ–°  $\theta^{Q}$ 

  - è®¡ç®—ç­–ç•¥ç½‘ç»œçš„ç­–ç•¥æ¢¯åº¦ policy gradientï¼š
    

  policy gradientçš„å®šä¹‰ï¼šè¡¨ç¤º performance objective çš„å‡½æ•°J  é’ˆå¯¹ $\theta^{\mu}$ çš„ gradientã€‚ æ ¹æ® 2015 D.Silver çš„[DPG è®ºæ–‡](http://xueshu.baidu.com/s?wd=paperuri:(43a8642b81092513eb6bad1f3f5231e2)&filter=sc_long_sign&sc_ks_para=q=Deterministic policy gradient algorithms&sc_us=6855198342873463498&tn=SE_baiduxueshu_c1gjeupa&ie=utf-8)ä¸­çš„æ•°å­¦æ¨å¯¼ï¼Œåœ¨é‡‡ç”¨off-policyçš„è®­ç»ƒæ–¹æ³•æ—¶ï¼Œpolicy gradientç®—æ³•å¦‚ä¸‹ï¼š

  ![](https://gitee.com/veal98/images/raw/master/img/20201113172144.png)

  æ ¹æ® Monte-carlo æ–¹æ³•ï¼Œä½¿ç”¨ mini-batch æ•°æ®ä»£å…¥ä¸Šè¿° policy gradient å…¬å¼ï¼Œå¯ä»¥ä½œä¸ºå¯¹ä¸Šè¿°æœŸæœ›å€¼çš„ä¸€ä¸ªæ— åå·®ä¼°è®¡ (un-biased estimate), æ‰€ä»¥ policy gradient å¯ä»¥æ”¹å†™ä¸º

    <img src="https://gitee.com/veal98/images/raw/master/img/20201113172035.png" style="zoom: 67%;" />

  - 	update online ç­–ç•¥ç½‘ç»œï¼šé‡‡ç”¨ Adam optimizeræ›´æ–° $\theta^{\mu}$ 
      
  - 	soft update target ç½‘ç»œ Î¼ â€² å’Œ Q â€² ï¼š
      <img src="https://gitee.com/veal98/images/raw/master/img/20201113170145.png" style="zoom: 80%;" />
      
  - end for time step

- ğŸš• end for episode

![](https://gitee.com/veal98/images/raw/master/img/20201113172444.png)

## 5. ä»£ç å®ç°

> âœ… TODO

## ğŸ“š References

- [è«çƒ¦ Python â€” å¼ºåŒ–å­¦ä¹ ](https://mofanpy.com/tutorials/machine-learning/reinforcement-learning/intro-RL-methods/)
- [Github - DeepRL-TensorFlow2](https://github.com/marload/DeepRL-TensorFlow2) - ğŸ‹ Simple implementations of various popular Deep Reinforcement Learning algorithms using TensorFlow2
- [Deep Reinforcement Learning - 1. DDPGåŸç†å’Œç®—æ³•](https://blog.csdn.net/kenneth_yu/article/details/78478356)
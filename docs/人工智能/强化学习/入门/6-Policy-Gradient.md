# ğŸ’« ç­–ç•¥æ¢¯åº¦ Policy Gradient

---

> ğŸ’¡ **Policy Gradient** å±äº Value-Freeã€Policy-Based

å¯¹æ¯”èµ·ä»¥å€¼ä¸ºåŸºç¡€çš„æ–¹æ³•, Policy Gradients æ ¹æ®æ¦‚ç‡ç›´æ¥è¾“å‡ºåŠ¨ä½œçš„æœ€å¤§å¥½å¤„å°±æ˜¯, **å®ƒèƒ½åœ¨ä¸€ä¸ªè¿ç»­åŒºé—´å†…æŒ‘é€‰åŠ¨ä½œ**, è€Œ Value-Based çš„æ¯”å¦‚ Q-learning æ— æ³•å¾ˆå¥½çš„å¤„ç†è¿ç»­åŠ¨ä½œ

## 1. Policy Gradient æ ¸å¿ƒæ€æƒ³

å¦‚å›¾æ‰€ç¤º, è§‚æµ‹çš„ä¿¡æ¯é€šè¿‡ç¥ç»ç½‘ç»œåˆ†æ, é€‰å‡ºäº†å·¦è¾¹çš„è¡Œä¸º, æˆ‘ä»¬ç›´æ¥è¿›è¡Œåå‘ä¼ é€’, ä½¿ä¹‹ä¸‹æ¬¡è¢«é€‰çš„å¯èƒ½æ€§å¢åŠ , ä½†æ˜¯å¥–æƒ©ä¿¡æ¯å´å‘Šè¯‰æˆ‘ä»¬, è¿™æ¬¡çš„è¡Œä¸ºæ˜¯ä¸å¥½çš„, é‚£æˆ‘ä»¬çš„åŠ¨ä½œå¯èƒ½æ€§å¢åŠ çš„å¹…åº¦ éšä¹‹è¢«å‡ä½. è¿™æ ·å°±èƒ½**é å¥–åŠ±æ¥å·¦å³æˆ‘ä»¬çš„ç¥ç»ç½‘ç»œåå‘ä¼ é€’**. 

![](https://gitee.com/veal98/images/raw/master/img/20201102094845.png)

å‡å¦‚è¿™æ¬¡çš„è§‚æµ‹ä¿¡æ¯è®©ç¥ç»ç½‘ç»œé€‰æ‹©äº†å³è¾¹çš„è¡Œä¸º, å³è¾¹çš„è¡Œä¸ºéšä¹‹æƒ³è¦è¿›è¡Œåå‘ä¼ é€’, ä½¿å³è¾¹çš„è¡Œä¸ºä¸‹æ¬¡è¢«å¤šé€‰ä¸€ç‚¹, è¿™æ—¶, å¥–æƒ©ä¿¡æ¯ä¹Ÿæ¥äº†, å‘Šè¯‰æˆ‘ä»¬è¿™æ˜¯å¥½è¡Œä¸º, é‚£æˆ‘ä»¬å°±åœ¨è¿™æ¬¡åå‘ä¼ é€’çš„æ—¶å€™åŠ å¤§åŠ›åº¦, è®©å®ƒä¸‹æ¬¡è¢«å¤šé€‰çš„å¹…åº¦æ›´çŒ›çƒˆã€‚è¿™å°±æ˜¯ Policy Gradients çš„æ ¸å¿ƒæ€æƒ³.

Policy gradient åŒæ ·ä¹Ÿè¦æ¥å—ç¯å¢ƒä¿¡æ¯ (observation), **ä¸åŒçš„æ˜¯ä»–è¦è¾“å‡ºä¸æ˜¯ action çš„ value, è€Œæ˜¯å…·ä½“çš„é‚£ä¸€ä¸ª action**, è¿™æ · policy gradient å°±è·³è¿‡äº† value è¿™ä¸ªé˜¶æ®µ

ä¹Ÿå°±æ˜¯è¯´ Policy Gradient ç½‘ç»œçš„è¾“å…¥ä¹Ÿæ˜¯çŠ¶æ€(State)ï¼Œè¾“å‡ºæ˜¯æ¯ä¸ªåŠ¨ä½œçš„æ¦‚ç‡ï¼Œä¾‹å¦‚ `[0.7, 0.3]` ï¼Œè¿™æ„å‘³ç€æœ‰70% çš„å‡ ç‡ä¼šé€‰æ‹©åŠ¨ä½œ 0ï¼Œ30% çš„å‡ ç‡é€‰æ‹©åŠ¨ä½œ 1

## 2. Policy Gradient æ•´ä½“ç®—æ³•

æˆ‘ä»¬ä»‹ç»çš„ policy gradient çš„åŸºç¡€ç®—æ³•æ˜¯ä¸€ç§åŸºäº **æ•´æ¡å›åˆæ•°æ®** çš„æ›´æ–°, ä¹Ÿå« **REINFORCE** æ–¹æ³•. è¿™ç§æ–¹æ³•æ˜¯ policy gradient çš„æœ€åŸºæœ¬æ–¹æ³•

Î¸ å°±æ˜¯æˆ‘ä»¬éœ€è¦ä¸æ–­æ›´æ–°çš„ç¥ç»ç½‘ç»œå‚æ•°

![](https://gitee.com/veal98/images/raw/master/img/20201102095848.png)

> ğŸ’¡ $\pi$ è¡¨ç¤º Policyï¼Œ$\pi(s,a)$ è¡¨ç¤ºåœ¨çŠ¶æ€ s ä¸‹é€‰æ‹©åŠ¨ä½œ a çš„æ¦‚ç‡ 
>
> **`Policy` è¾“å‡ºæŸä¸ªçŠ¶æ€ä¸‹æ‰€æœ‰å¯èƒ½åŠ¨ä½œçš„æ‰§è¡Œæ¦‚ç‡ï¼Œå®ƒå…¶å®æ˜¯ä¸€ä¸ªå‡½æ•°ï¼ŒæŠŠè¾“å…¥çš„çŠ¶æ€å˜æˆè¡Œä¸º**ã€‚å‡è®¾ä½ æ˜¯ç”¨ deep learning çš„æŠ€æœ¯æ¥åš reinforcement learning çš„è¯ï¼Œ**`policy` å°±æ˜¯ä¸€ä¸ªç¥ç»ç½‘ç»œ**ï¼Œç¥ç»ç½‘ç»œé‡Œé¢æœ‰ä¸€å †å‚æ•°ï¼Œ <u>æˆ‘ä»¬ç”¨ Î¸ æ¥ä»£è¡¨ Ï€ çš„å‚æ•°</u>ï¼š
>
> <img src="https://gitee.com/veal98/images/raw/master/img/20201026173154.png" style="zoom:40%;" />

<img src="https://gitee.com/veal98/images/raw/master/img/20201102095924.png" style="zoom:67%;" /> è¡¨ç¤ºåœ¨ çŠ¶æ€ `s` å¯¹æ‰€é€‰åŠ¨ä½œ `a` çš„åƒæƒŠåº¦, å¦‚æœ $\pi(s,a)$ æ¦‚ç‡è¶Šå°, åå‘çš„ $log\pi(s,a)$ åè€Œè¶Šå¤§. å¦‚æœåœ¨ $\pi(s,a)$ å¾ˆå°çš„æƒ…å†µä¸‹, æ‹¿åˆ°äº†ä¸€ä¸ªå¤§çš„ `R`, ä¹Ÿå°±æ˜¯ å¤§çš„ `V`, é‚£ $log\pi(s,a)V$ å°±æ›´å¤§, è¡¨ç¤ºæ›´åƒæƒŠ

ğŸ‘ **é€šä¿—æ¥è¯´ï¼Œæˆ‘é€‰äº†ä¸€ä¸ªä¸å¸¸é€‰çš„åŠ¨ä½œï¼ˆæ¦‚ç‡å°ï¼‰, å´å‘ç°åŸæ¥å®ƒèƒ½å¾—åˆ°äº†ä¸€ä¸ªå¥½çš„ reward, é‚£æˆ‘å°±å¾—å¯¹è¿™æ¬¡çš„å‚æ•°è¿›è¡Œä¸€ä¸ªå¤§å¹…ä¿®æ”¹. è¿™å°±æ˜¯åƒæƒŠåº¦çš„ç‰©ç†æ„ä¹‰**

## 3. ä»£ç å®ç°

> âœ… TODO

## ğŸ“š References

- [Bilibili - æå®æ¯…ã€Šæ·±åº¦å¼ºåŒ–å­¦ä¹ ã€‹](https://www.bilibili.com/video/BV1MW411w79n)
- [Github - LeeDeepRL - Notes](https://datawhalechina.github.io/leedeeprl-notes/)
- [CSDN - æå®æ¯…æ·±åº¦å¼ºåŒ–å­¦ä¹ ç¬”è®° - jessie](https://blog.csdn.net/cindy_1102/article/details/87904928)
- [å¼ºåŒ–å­¦ä¹ çº²è¦](https://github.com/zhoubolei/introRL)
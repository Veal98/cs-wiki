# ğŸ’»  å´æ©è¾¾ Coursera æœºå™¨å­¦ä¹  â€” ç¼–ç¨‹ä½œä¸š 

## ğŸš€ Ex1ï¼šçº¿æ€§å›å½’

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
```

### 1. ç®€å•ç»ƒä¹ 

è¾“å‡ºä¸€ä¸ª `5*5` çš„å•ä½çŸ©é˜µ

```python
np.eye(5)
```

![](https://gitee.com/veal98/images/raw/master/img/20200615153229.png)

### 2. å•å˜é‡çº¿æ€§å›å½’

åœ¨æœ¬éƒ¨åˆ†çš„ç»ƒä¹ ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨ä¸€ä¸ªå˜é‡å®ç°çº¿æ€§å›å½’ï¼Œä»¥é¢„æµ‹é£Ÿå“å¡è½¦çš„åˆ©æ¶¦ã€‚å‡è®¾ä½ æ˜¯ä¸€å®¶é¤é¦†çš„é¦–å¸­æ‰§è¡Œå®˜ï¼Œæ­£åœ¨**è€ƒè™‘ä¸åŒçš„åŸå¸‚å¼€è®¾ä¸€ä¸ªæ–°çš„åˆ†åº—**ã€‚è¯¥è¿é”åº—å·²ç»åœ¨å„ä¸ªåŸå¸‚æ‹¥æœ‰å¡è½¦ï¼Œè€Œä¸”ä½ æœ‰æ¥è‡ªåŸå¸‚çš„åˆ©æ¶¦å’Œäººå£æ•°æ®ã€‚
æ‚¨å¸Œæœ›**ä½¿ç”¨è¿™äº›æ•°æ®æ¥å¸®åŠ©æ‚¨é€‰æ‹©å°†å“ªä¸ªåŸå¸‚æ‰©å±•åˆ°ä¸‹ä¸€ä¸ªåŸå¸‚**ã€‚

> æ•´ä¸ª 2 çš„éƒ¨åˆ†éœ€è¦æ ¹æ®åŸå¸‚äººå£æ•°é‡ï¼Œé¢„æµ‹å¼€å°åƒåº—çš„åˆ©æ¶¦ æ•°æ®åœ¨ ex1 / ex1data1.txt é‡Œï¼Œç¬¬ä¸€åˆ—æ˜¯åŸå¸‚äººå£æ•°é‡ï¼Œç¬¬äºŒåˆ—æ˜¯è¯¥åŸå¸‚å°åƒåº—åˆ©æ¶¦ã€‚
>
> ğŸ’¡ **ex1data1.txt**ï¼š
>
> 6.1101,17.592
>
> 5.5277,9.1302
>
> 8.5186,13.662
>
> 7.0032,11.854
>
> 5.8598,6.8233
>
> 8.3829,11.886
>
> 7.4764,4.3483
>
> 8.5781,12

#### 2.1 å±•ç¤ºæ•°æ®

è¯»å…¥æ•°æ®ï¼Œç„¶åå±•ç¤ºæ•°æ®

```python
path = 'ex1/ex1data1.txt'
data = pd.read_csv(path,names = ['Population','Profit']) # è¯»å–æ•°æ®å¹¶èµ‹äºˆåˆ—å
data.plot(kind='scatter', x='Population', y='Profit'ï¼Œfigsize=(8,5)) # scatter è¡¨ç¤ºæ•£ç‚¹å›¾
```

![](https://gitee.com/veal98/images/raw/master/img/20200615155158.png)

#### 2.2 æ¢¯åº¦ä¸‹é™

ç°åœ¨è®©æˆ‘ä»¬ä½¿ç”¨æ¢¯åº¦ä¸‹é™æ¥å®ç°çº¿æ€§å›å½’ï¼Œä»¥æœ€å°åŒ–æˆæœ¬å‡½æ•°ã€‚ 

- **å…¬å¼**

  é¦–å…ˆï¼Œæˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªä»¥å‚æ•°Î¸ä¸ºç‰¹å¾å‡½æ•°çš„ä»£ä»·å‡½æ•°

  ![](https://gitee.com/veal98/images/raw/master/img/20200615155938.png)

  è®¡ç®—ä»£ä»·å‡½æ•° J(Î¸)ï¼š

  ```python
  def computeCost(X, y, theta):
      inner = np.power(((X*theta.T)-y),2)
      return np.sum(inner) / (2*len(X))
  ```

- **å®ç°**

  æ•°æ®å‰é¢å·²ç»è¯»å–å®Œæ¯•ï¼Œæˆ‘ä»¬è¦ä¸ºåŠ å…¥ä¸€åˆ— xï¼Œç”¨äºæ›´æ–° Î¸0ï¼ˆå³æ·»åŠ  $x_0 = 1$ï¼‰ï¼Œç„¶åæˆ‘ä»¬å°† Î¸ åˆå§‹åŒ–ä¸º 0ï¼Œå­¦ä¹ ç‡åˆå§‹åŒ–ä¸º 0.01ï¼Œè¿­ä»£æ¬¡æ•°ä¸º 1500 æ¬¡

  ```python
  data.insert(0, 'Ones', 1)
  ```

  ![](https://gitee.com/veal98/images/raw/master/img/20200615163040.png)

  ç°åœ¨æˆ‘ä»¬æ¥åšä¸€äº›å˜é‡åˆå§‹åŒ–ï¼š

  ```python
  # åˆå§‹åŒ– X å’Œ y
  cols = data.shape[1]  # åˆ—æ•°
  X = data.iloc[:,0:cols-1]  # å–å‰cols-1åˆ—ï¼Œå³è¾“å…¥å‘é‡ / ç‰¹å¾
  y = data.iloc[:,cols-1:cols] # å–æœ€åä¸€åˆ—ï¼Œå³è¾“å‡ºå‘é‡
  ```

  ![](https://gitee.com/veal98/images/raw/master/img/20200615163506.png)

  ![](https://gitee.com/veal98/images/raw/master/img/20200615163453.png)

  

  ä»£ä»·å‡½æ•°æ˜¯åº”è¯¥æ˜¯numpyçŸ©é˜µï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦è½¬æ¢Xå’ŒYï¼Œç„¶åæ‰èƒ½ä½¿ç”¨å®ƒä»¬ã€‚ æˆ‘ä»¬è¿˜éœ€è¦åˆå§‹åŒ–thetaï¼š

  ```python
  X = np.matrix(X.values)
  y = np.matrix(y.values)
  theta = np.matrix(np.array([0,0])) # theta æ˜¯ä¸€ä¸ª(1,2)çŸ©é˜µ
  ```

  > ğŸš¨ è¿™é‡Œæˆ‘ä½¿ç”¨çš„æ˜¯ matix è€Œä¸æ˜¯ arrayï¼Œä¸¤è€…åŸºæœ¬é€šç”¨ã€‚
  >
  > ä½†æ˜¯matrixçš„ä¼˜åŠ¿å°±æ˜¯ç›¸å¯¹ç®€å•çš„è¿ç®—ç¬¦å·ï¼Œæ¯”å¦‚ä¸¤ä¸ªçŸ©é˜µç›¸ä¹˜ï¼Œå°±æ˜¯ç”¨ç¬¦å· `*`ï¼Œä½†æ˜¯arrayç›¸ä¹˜ä¸èƒ½è¿™ä¹ˆç”¨ï¼Œå¾—ç”¨æ–¹æ³• `.dot()`
  > arrayçš„ä¼˜åŠ¿å°±æ˜¯ä¸ä»…ä»…è¡¨ç¤ºäºŒç»´ï¼Œè¿˜èƒ½è¡¨ç¤º3ã€4ã€5â€¦ç»´ï¼Œè€Œä¸”åœ¨å¤§éƒ¨åˆ†Pythonç¨‹åºé‡Œï¼Œarrayä¹Ÿæ˜¯æ›´å¸¸ç”¨çš„ã€‚
  >
  > ğŸ’­ ä¸¤è€…åŒºåˆ«ï¼š
  >
  > - å¯¹åº”å…ƒç´ ç›¸ä¹˜ï¼šmatrix å¯ä»¥ç”¨ `np.multiply(X2,X1)`ï¼Œarrayç›´æ¥ `X1*X2`
  > - ç‚¹ä¹˜ï¼šmatrix ç›´æ¥ `X1*X2`ï¼Œarrayå¯ä»¥ `X1@X2 `æˆ– `X1.dot(X2)` æˆ– `np.dot(X1, X2)`

  ![](https://gitee.com/veal98/images/raw/master/img/20200615163752.png)

  çœ‹ä¸‹ç»´åº¦ï¼Œç¡®ä¿è®¡ç®—æ²¡é—®é¢˜ï¼š

  ```python
  X.shape, theta.shape, y.shape
  # ((97, 2), (1, 2), (97, 1))
  ```

- **è®¡ç®—J(Î¸)**

  è®¡ç®—ä»£ä»·å‡½æ•° (thetaåˆå§‹å€¼ä¸º0)ï¼Œç­”æ¡ˆåº”è¯¥æ˜¯32.07

  ```python
  computeCost(X, y, theta) # 32.072733877455676
  ```

- **æ¢¯åº¦ä¸‹é™**

  ![](https://gitee.com/veal98/images/raw/master/img/20200615164558.png)

  > â­ è®°ä½J(Î¸)çš„å˜é‡æ˜¯Î¸ï¼Œè€Œä¸æ˜¯Xå’Œyï¼Œæ„æ€æ˜¯è¯´ï¼Œæˆ‘ä»¬å˜åŒ–Î¸çš„å€¼æ¥ä½¿J(Î¸)å˜åŒ–ï¼Œè€Œä¸æ˜¯å˜åŒ–Xå’Œyçš„å€¼ã€‚ **ä¸€ä¸ªæ£€æŸ¥æ¢¯åº¦ä¸‹é™æ˜¯ä¸æ˜¯åœ¨æ­£å¸¸è¿ä½œçš„æ–¹å¼ï¼Œæ˜¯æ‰“å°å‡ºæ¯ä¸€æ­¥J(Î¸)çš„å€¼ï¼Œçœ‹ä»–æ˜¯ä¸æ˜¯ä¸€ç›´éƒ½åœ¨å‡å°ï¼Œå¹¶ä¸”æœ€åæ”¶æ•›è‡³ä¸€ä¸ªç¨³å®šçš„å€¼ã€‚** Î¸ æœ€åçš„ç»“æœä¼šç”¨æ¥é¢„æµ‹å°åƒåº—åœ¨35000åŠ70000äººåŸå¸‚è§„æ¨¡çš„åˆ©æ¶¦ã€‚

  ä½¿ç”¨ **vectorization å‘é‡åŒ–** åŒæ—¶æ›´æ–°æ‰€æœ‰çš„ Î¸ï¼Œå¯ä»¥å¤§å¤§æé«˜æ•ˆç‡

  ```python
  # æ¢¯åº¦ä¸‹é™
  def gradientDescent(X,y,theta,alpha,iters): # iters è¡¨ç¤ºè¿­ä»£æ¬¡æ•°
      temp = np.matrix(np.zeros(theta.shape)) # åˆå§‹åŒ– Î¸ çš„ä¸´æ—¶çŸ©é˜µï¼ˆ1ï¼Œ2ï¼‰
      parameters = int(theta.ravel().shape[1]) # å‚æ•° Î¸ çš„æ•°é‡
      cost = np.zeros(iters) # åˆå§‹åŒ–ä¸€ä¸ªndarrayï¼ŒåŒ…å«æ¯æ¬¡è¿­ä»£åä»£ä»·å‡½æ•°çš„å€¼
      m = X.shape[0] # æ ·æœ¬æ•°é‡
      
      for i in range(iters):
          temp = theta - (alpha / m) * (X * theta.T - y).T * X
          theta = temp 
          cost[i] = computeCost(X,y,theta) # è¾“å‡ºæ¯æ¬¡è¿­ä»£åä»£ä»·å‡½æ•°çš„å€¼
      return theta,cost
  ```

  åˆå§‹åŒ–ä¸€äº›é™„åŠ å˜é‡ - å­¦ä¹ é€Ÿç‡Î±å’Œè¦æ‰§è¡Œçš„è¿­ä»£æ¬¡æ•°ï¼Œ2.2.2ä¸­å·²ç»æåˆ°ï¼š

  ```python
  alpha = 0.01
  iters = 1500
  ```

  ç°åœ¨è®©æˆ‘ä»¬è¿è¡Œæ¢¯åº¦ä¸‹é™ç®—æ³•æ¥å°†æˆ‘ä»¬çš„å‚æ•°Î¸é€‚åˆäºè®­ç»ƒé›†ï¼š

  ```python
  final_theta, cost = gradientDescent(X, y, theta, alpha, iters)
  ```

  ![](https://gitee.com/veal98/images/raw/master/img/20200615170111.png)

  æœ€åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æˆ‘ä»¬æ‹Ÿåˆçš„å‚æ•°è®¡ç®—è®­ç»ƒæ¨¡å‹çš„ä»£ä»·å‡½æ•°ï¼ˆè¯¯å·®ï¼‰ï¼š

  ```python
  computeCost(X, y, final_theta) # 4.483388256587726
  ```

  

  ç°åœ¨æˆ‘ä»¬æ¥ç»˜åˆ¶çº¿æ€§æ¨¡å‹ä»¥åŠæ•°æ®ï¼Œç›´è§‚åœ°çœ‹å‡ºå®ƒçš„æ‹Ÿåˆã€‚

  `np.linspace()` åœ¨æŒ‡å®šçš„é—´éš”å†…è¿”å›å‡åŒ€é—´éš”çš„æ•°å­—ã€‚

  ```python
  x = np.linspace(data.Population.min(), data.Population.max(), 100)  # æ¨ªåæ ‡
  f = final_theta[0, 0] + (final_theta[0, 1] * x)  # çºµåæ ‡ï¼Œåˆ©æ¶¦
  
  fig = plt.figure()
  ax = fig.add_subplot(1,1,1)
  ax.plot(x, f, 'r', label='Prediction')
  ax.scatter(data['Population'], data.Profit, label='Traning Data')
  ax.legend(loc=2)  # 2è¡¨ç¤ºåœ¨å·¦ä¸Šè§’
  ax.set_xlabel('Population')
  ax.set_ylabel('Profit')
  ax.set_title('Predicted Profit vs. Population Size')
  ```

  <img src="https://gitee.com/veal98/images/raw/master/img/20200615171050.png" style="zoom:80%;" />

  ç”±äºæ¢¯åº¦æ–¹ç¨‹å¼å‡½æ•°åœ¨æ¯ä¸ªè®­ç»ƒè¿­ä»£ä¸­è¾“å‡ºäº†ä»£ä»·å‡½æ•°çš„å€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¹Ÿå¯ä»¥ç»˜åˆ¶ã€‚ è¯·æ³¨æ„ï¼Œçº¿æ€§å›å½’ä¸­çš„ä»£ä»·å‡½æ•°æ€»æ˜¯é™ä½çš„ - è¿™æ˜¯å‡¸ä¼˜åŒ–é—®é¢˜çš„ä¸€ä¸ªä¾‹å­ã€‚

  ```python
  fig, ax = plt.subplots(figsize=(6,4))
  ax.plot(np.arange(iters), cost, 'r')  # np.arange()è¿”å›ç­‰å·®æ•°ç»„
  ax.set_xlabel('Iterations')
  ax.set_ylabel('Cost')
  ax.set_title('Error vs. Training Epoch')
  ```

  <img src="https://gitee.com/veal98/images/raw/master/img/20200615172057.png" style="zoom:80%;" />



### 3. å¤šå˜é‡çº¿æ€§å›å½’

ex1data2.txt é‡Œçš„æ•°æ®ï¼Œç¬¬ä¸€åˆ—æ˜¯æˆ¿å±‹å¤§å°ï¼Œç¬¬äºŒåˆ—æ˜¯å§å®¤æ•°é‡ï¼Œç¬¬ä¸‰åˆ—æ˜¯æˆ¿å±‹å”®ä»·

**æ ¹æ®å·²æœ‰æ•°æ®ï¼Œå»ºç«‹æ¨¡å‹ï¼Œé¢„æµ‹æˆ¿å±‹çš„å”®ä»·**

> ğŸ’¡ **ex1data2.txt**
>
> 2104,3,399900
>
> 1600,3,329900
>
> 2400,3,369000
>
> 1416,2,232000
>
> 3000,4,539900
>
> 1985,4,299900
>
> 1534,3,314900
>
> 1427,3,198999
>
> 1380,3,212000

```python
data2 = pd.read_csv('ex1/ex1data2.txt', names=['Size','Bedrooms','Price'])
```

![](https://gitee.com/veal98/images/raw/master/img/20200615172627.png)



#### 3.1 ç‰¹å¾å½’ä¸€åŒ–

è§‚å¯Ÿæ•°æ®å‘ç°ï¼Œsizeå˜é‡æ˜¯bedroomså˜é‡çš„1000å€å¤§å°,**ç»Ÿä¸€é‡çº§ä¼šè®©æ¢¯åº¦ä¸‹é™æ”¶æ•›çš„æ›´å¿«**ã€‚åšæ³•å°±æ˜¯**å‡å€¼å½’ä¸€åŒ–**ï¼šå°†æ¯ç±»ç‰¹å¾å‡å»ä»–çš„å¹³å‡å€¼åé™¤ä»¥æ ‡å‡†å·®

```python
data2 = (data2 - data2.mean()) / data2.std()
```

![](https://gitee.com/veal98/images/raw/master/img/20200615172845.png)

#### 3.2 æ¢¯åº¦ä¸‹é™

ç°åœ¨æˆ‘ä»¬é‡å¤å•å˜é‡çº¿æ€§å›å½’ä¸­çš„é¢„å¤„ç†æ­¥éª¤ï¼Œå¹¶å¯¹æ–°æ•°æ®é›†è¿è¡Œçº¿æ€§å›å½’ç¨‹åºã€‚

```python
# add ones column
data2.insert(0, 'Ones', 1)

# set X (training data) and y (target variable)
cols = data2.shape[1]
X2 = data2.iloc[:,0:cols-1]
y2 = data2.iloc[:,cols-1:cols]

# convert to matrices and initialize theta
X2 = np.matrix(X2.values)
y2 = np.matrix(y2.values)
theta2 = np.matrix(np.array([0,0,0]))

# perform linear regression on the data set
g2, cost2 = gradientDescent(X2, y2, theta2, alpha, iters)

# get the cost (error) of the model
computeCost(X2, y2, g2), g2
```

![](https://gitee.com/veal98/images/raw/master/img/20200615173109.png)

æŸ¥çœ‹ J(Î¸) æ˜¯å¦åœ¨ä¸æ–­å‡å°å¹¶è¶‹äºå›ºå®šå€¼ï¼š

```python
fig, ax = plt.subplots(figsize=(6,4))
ax.plot(np.arange(iters), cost2, 'r')
ax.set_xlabel('Iterations')
ax.set_ylabel('Cost')
ax.set_title('Error vs. Training Epoch')
```

![](https://gitee.com/veal98/images/raw/master/img/20200615173307.png)

#### 3.3 æ­£è§„æ–¹ç¨‹

æ­£è§„æ–¹ç¨‹æ˜¯é€šè¿‡æ±‚è§£ä¸‹é¢çš„æ–¹ç¨‹æ¥æ‰¾å‡ºä½¿å¾—ä»£ä»·å‡½æ•°æœ€å°çš„å‚æ•°çš„ï¼š$\frac{\partial }{\partial {{\theta }_{j}}}J\left( {{\theta }_{j}} \right)=0$ ã€‚ å‡è®¾æˆ‘ä»¬çš„è®­ç»ƒé›†ç‰¹å¾çŸ©é˜µä¸º Xï¼ˆåŒ…å«äº†x0=1ï¼‰å¹¶ä¸”æˆ‘ä»¬çš„è®­ç»ƒé›†ç»“æœä¸ºå‘é‡ yï¼Œåˆ™åˆ©ç”¨æ­£è§„æ–¹ç¨‹è§£å‡ºå‘é‡ $\theta ={{\left( {{X}^{T}}X \right)}^{-1}}{{X}^{T}}y$ã€‚ ä¸Šæ ‡Tä»£è¡¨çŸ©é˜µè½¬ç½®ï¼Œä¸Šæ ‡-1 ä»£è¡¨çŸ©é˜µçš„é€†ã€‚è®¾çŸ©é˜µ $A=X^TX$ï¼Œåˆ™ï¼š${{\left( {{X}^{T}}X \right)}^{-1}}={{A}^{-1}}$

æ¢¯åº¦ä¸‹é™ä¸æ­£è§„æ–¹ç¨‹çš„æ¯”è¾ƒï¼š

- **æ¢¯åº¦ä¸‹é™**ï¼š<u>éœ€è¦é€‰æ‹©å­¦ä¹ ç‡Î±ï¼Œéœ€è¦å¤šæ¬¡è¿­ä»£</u>ï¼Œå½“ç‰¹å¾æ•°é‡nå¤§æ—¶ä¹Ÿèƒ½è¾ƒå¥½é€‚ç”¨ï¼Œé€‚ç”¨äºå„ç§ç±»å‹çš„æ¨¡å‹

- **æ­£è§„æ–¹ç¨‹**ï¼šä¸éœ€è¦é€‰æ‹©å­¦ä¹ ç‡Î±ï¼Œä¸€æ¬¡è®¡ç®—å¾—å‡ºï¼Œéœ€è¦è®¡ç®—${{\left( {{X}^{T}}X \right)}^{-1}}$ï¼Œå¦‚æœç‰¹å¾æ•°é‡nè¾ƒå¤§åˆ™è¿ç®—ä»£ä»·å¤§ï¼Œå› ä¸ºçŸ©é˜µé€†çš„è®¡ç®—æ—¶é—´å¤æ‚åº¦ä¸ºO(n^3)ï¼Œé€šå¸¸æ¥è¯´å½“nå°äº10000 æ—¶è¿˜æ˜¯å¯ä»¥æ¥å—çš„ï¼Œåªé€‚ç”¨äºçº¿æ€§æ¨¡å‹ï¼Œä¸é€‚åˆé€»è¾‘å›å½’æ¨¡å‹ç­‰å…¶ä»–æ¨¡å‹

```python
# æ­£è§„æ–¹ç¨‹
def normalEqn(X, y):
    theta = np.linalg.inv(X.T@X)@X.T@y # np.linalg.inv æ±‚é€†ï¼›X.T@Xç­‰ä»·äºX.T.dot(X)
    return theta
```

```python
final_theta2=normalEqn(X, y) # å’Œæ‰¹é‡æ¢¯åº¦ä¸‹é™çš„thetaçš„å€¼æœ‰ç‚¹å·®è·
```

![](https://gitee.com/veal98/images/raw/master/img/20200615173928.png)

## ğŸš€ Ex2ï¼šé€»è¾‘å›å½’ + æ­£åˆ™åŒ–

è½»è½¦ç†Ÿè·¯ï¼Œå…ˆå¯¼åŒ…ï¼š

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
```

### 1. é€»è¾‘å›å½’

åœ¨è¿™éƒ¨åˆ†çš„ç»ƒä¹ ä¸­ï¼Œ**ä½ å°†å»ºç«‹ä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹æ¥é¢„æµ‹ä¸€ä¸ªå­¦ç”Ÿæ˜¯å¦èƒ½è¿›å…¥å¤§å­¦**ã€‚å‡è®¾ä½ æ˜¯ä¸€æ‰€å¤§å­¦çš„è¡Œæ”¿ç®¡ç†äººå‘˜ï¼Œä½ æƒ³æ ¹æ®ä¸¤é—¨è€ƒè¯•çš„ç»“æœï¼Œæ¥å†³å®šæ¯ä¸ªç”³è¯·äººæ˜¯å¦è¢«å½•å–ã€‚ä½ æœ‰ä»¥å‰ç”³è¯·äººçš„å†å²æ•°æ®ï¼Œå¯ä»¥å°†å…¶ç”¨ä½œé€»è¾‘å›å½’è®­ç»ƒé›†ã€‚å¯¹äºæ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œ**ä½ æœ‰ç”³è¯·äººä¸¤æ¬¡æµ‹è¯„çš„åˆ†æ•°ä»¥åŠå½•å–çš„ç»“æœ**ã€‚ä¸ºäº†å®Œæˆè¿™ä¸ªé¢„æµ‹ä»»åŠ¡ï¼Œæˆ‘ä»¬å‡†å¤‡æ„å»ºä¸€ä¸ªå¯ä»¥åŸºäºä¸¤æ¬¡æµ‹è¯•è¯„åˆ†æ¥è¯„ä¼°å½•å–å¯èƒ½æ€§çš„åˆ†ç±»æ¨¡å‹ã€‚

éƒ¨åˆ†æ•°æ®å¦‚ä¸‹ï¼š

> 4.62365962451697,78.0246928153624,0
>
> 30.28671076822607,43.89499752400101,0
>
> 35.84740876993872,72.90219802708364,0
>
> 60.18259938620976,86.30855209546826,1
>
> 79.0327360507101,75.3443764369103,1
>
> 45.08327747668339,56.3163717815305,0
>
> 61.10666453684766,96.51142588489624,1
>
> 75.02474556738889,46.55401354116538,1

#### â‘  æ•°æ®å¯è§†åŒ–

```python
data = pd.read_csv('ex2/ex2data1.txt',names = ['Exam1','Exam2','Admitted'])
data.head()
```

![](https://gitee.com/veal98/images/raw/master/img/20200618200748.png)

```python
data.describe()
```

![](https://gitee.com/veal98/images/raw/master/img/20200618200856.png)

è®©æˆ‘ä»¬åˆ›å»ºä¸¤ä¸ªåˆ†æ•°çš„æ•£ç‚¹å›¾ï¼Œå¹¶ä½¿ç”¨é¢œè‰²ç¼–ç æ¥å¯è§†åŒ–ï¼Œå¦‚æœæ ·æœ¬æ˜¯æ­£çš„ï¼ˆè¢«æ¥çº³ï¼‰æˆ–è´Ÿçš„ï¼ˆæœªè¢«æ¥çº³ï¼‰

```python
positive = data[data.Admitted.isin(['1'])] # 1
negetive = data[data.Admitted.isin(['0'])] # 0

fig,ax = plt.subplots(figsize = (6,5))

# è®¾ç½® Admitter ä¸ºè“è‰² o å½¢ï¼ˆé»˜è®¤ï¼‰
ax.scatter(positive['Exam1'],positive['Exam2'],c = 'b',label = 'Admitted')
# è®¾ç½® Not Admitted ä¸ºçº¢è‰² x å½¢
ax.scatter(negetive['Exam1'], negetive['Exam2'], s=50, c='r', marker='x', label='Not Admitted')

# è®¾ç½®å›¾ä¾‹æ˜¾ç¤ºåœ¨å›¾çš„ä¸Šæ–¹
box = ax.get_position()
ax.set_position([box.x0, box.y0, box.width , box.height* 0.8])
ax.legend(loc='center left', bbox_to_anchor=(0.2, 1.12),ncol=3)

# è®¾ç½®æ¨ªçºµåæ ‡å
ax.set_xlabel('Exam 1 Score')
ax.set_ylabel('Exam 2 Score')

plt.show()
```

![](https://gitee.com/veal98/images/raw/master/img/20200618202024.png)

çœ‹èµ·æ¥åœ¨ä¸¤ç±»é—´ï¼Œæœ‰ä¸€ä¸ªæ¸…æ™°çš„å†³ç­–è¾¹ç•Œã€‚ç°åœ¨æˆ‘ä»¬éœ€è¦å®ç°é€»è¾‘å›å½’ï¼Œé‚£æ ·å°±å¯ä»¥è®­ç»ƒä¸€ä¸ªæ¨¡å‹æ¥é¢„æµ‹ç»“æœã€‚

> ğŸ’¡ `plt.scatter` è¯¦è§£ï¼š
>
> ![](https://gitee.com/veal98/images/raw/master/img/20200618201411.png)

#### â‘¡ å‡è®¾å‡½æ•° Sigmoid

é¦–å…ˆæ¥å›é¡¾ä¸‹ logisticå›å½’çš„å‡è®¾å‡½æ•°ï¼š<img src="https://gitee.com/veal98/images/raw/master/img/20200618202129.png" style="zoom: 67%;" />

å…¶ä¸­çš„ g ä»£è¡¨ä¸€ä¸ªå¸¸ç”¨çš„logistic functionä¸ºSå½¢å‡½æ•°ï¼ˆSigmoid functionï¼‰ï¼š<img src="https://gitee.com/veal98/images/raw/master/img/20200618202152.png" style="zoom: 67%;" />

```python
def sigmoid(z):
    return 1 / (1 + np.exp(-z))
```

è®©æˆ‘ä»¬åšä¸€ä¸ªå¿«é€Ÿçš„æ£€æŸ¥ï¼Œæ¥ç¡®ä¿å®ƒå¯ä»¥å·¥ä½œ

```python
x1 = np.arange(-10,10,0.1)
plt.plot(x1,sigmoid(x1),c = 'r')
plt.show()
```

![](https://gitee.com/veal98/images/raw/master/img/20200618202353.png)

#### â‘¢ ä»£ä»·å‡½æ•°

é€»è¾‘å›å½’çš„ä»£ä»·å‡½æ•°å¦‚ä¸‹ï¼Œå’Œçº¿æ€§å›å½’çš„ä»£ä»·å‡½æ•°ä¸ä¸€æ ·ï¼Œå› ä¸ºè¿™ä¸ªå‡½æ•°æ˜¯å‡¸çš„ã€‚

<img src="https://gitee.com/veal98/images/raw/master/img/20200618202440.png" style="zoom: 67%;" />

```python
def cost(theat, X, y):
    first = (-y) * np.log(sigmoid(X @ theta))
    second = (1-y) * np.log(1-sigmoid(X @ theta))
    return np.sum(first - second) / (len(X))
```

ç°åœ¨ï¼Œæˆ‘ä»¬è¦åšä¸€äº›è®¾ç½®ï¼Œè·å–æˆ‘ä»¬çš„è®­ç»ƒé›†æ•°æ®ã€‚

```python
# åŠ ä¸€åˆ—å¸¸æ•°åˆ—
data.insert(0, 'Ones', 1)

# åˆå§‹åŒ–Xï¼Œyï¼ŒÎ¸
cols = data.shape[1] # è·å–åˆ—æ•°
X = data.iloc[:,0:cols-1]
y = data.iloc[:,cols-1:cols]
theta = np.zeros(X.shape[1])

# è½¬æ¢Xï¼Œyçš„ç±»å‹
X = np.array(X.values)
y = np.array(y.values)
```

è®©æˆ‘ä»¬æ¥æ£€æŸ¥çŸ©é˜µçš„ç»´åº¦ï¼Œç¡®ä¿ä¸€åˆ‡è‰¯å¥½ã€‚

![](https://gitee.com/veal98/images/raw/master/img/20200618203843.png)

è¿è¡Œä»£ä»·å‡½æ•°ï¼š

```python
cost(theta,X,y) # 0.6931471805599453
# ä»£ä»·å‡½æ•°çš„è¿”å›å€¼å³ä»£ä»·å‡½æ•°çš„æœ€å°å€¼
```

#### â‘£ æ¢¯åº¦ä¸‹é™

<img src="https://gitee.com/veal98/images/raw/master/img/20200618204308.png" style="zoom: 80%;" />

```python
# å®ç°æ¢¯åº¦è®¡ç®—çš„å‡½æ•°ï¼ˆä½†æ˜¯ä»…ä»…è®¡ç®—å‡ºäº†Î¸ï¼Œå¹¶æ²¡æœ‰æ›´æ–°Î¸ï¼‰
def gradient(theta, X, y):
    theta = np.matrix(theta)
    X = np.matrix(X)
    y = np.matrix(y)
    
    parameters = int(theta.ravel().shape[1])
    grad = np.zeros(parameters)
    
    error = sigmoid(X * theta.T) - y
    
    for i in range(parameters):
        term = np.multiply(error, X[:,i])
        grad[i] = np.sum(term) / len(X) # è®¡ç®—å‡º3ä¸ªÎ¸å€¼
    
    return grad 
```

```python
gradient(theta,X,y) # array([ -0.1, -12.00921659, -11.26284221])
```

> ğŸ’¡ `numpy.ravel` å‡½æ•°è¯¦è§£ï¼š
>
> **æ­¤å‡½æ•°è¿”å›å±•å¹³çš„ä¸€ç»´æ•°ç»„**ã€‚åªåœ¨éœ€è¦æ—¶æ‰åˆ¶ä½œå‰¯æœ¬ã€‚è¿”å›çš„æ•°ç»„å°†ä¸è¾“å…¥æ•°ç»„çš„ç±»å‹ç›¸åŒã€‚è¯¥å‡½æ•°æœ‰ä¸€ä¸ªå‚æ•°ã€‚
>
> ```python
> numpy.ravel(a, order)
> ```
>
> æ„é€ å‡½æ•°é‡‡ç”¨ä»¥ä¸‹å‚æ•°ã€‚
>
> | åºå· | å‚æ•°å’Œæè¿°                                                   |
> | :--- | :----------------------------------------------------------- |
> | 1    | **order** 'C'ï¼šè¡Œä¸»è¦(é»˜è®¤ã€‚'F'ï¼šåˆ—ä¸»è¦'A'ï¼šæŒ‰åˆ—åˆ—ä¸»è¦é¡ºåºå±•å¹³ï¼Œå¦‚æœaæ˜¯Fortranåœ¨å†…å­˜ä¸­è¿ç»­ï¼Œåˆ™è¡Œä¸»è¦é¡ºåºå¦åˆ™'K'ï¼šæŒ‰é¡ºåºå‹æ‰aå‘ç”Ÿåœ¨è®°å¿†ä¸­ |

#### â‘¤ ç”¨å·¥å…·åº“è®¡ç®—Î¸çš„å€¼

æ³¨æ„ï¼Œ**æˆ‘ä»¬å®é™…ä¸Šæ²¡æœ‰åœ¨è¿™ä¸ªå‡½æ•°ä¸­æ‰§è¡Œæ¢¯åº¦ä¸‹é™ï¼Œæˆ‘ä»¬ä»…ä»…åœ¨è®¡ç®—æ¢¯åº¦ã€‚**åœ¨ç»ƒä¹ ä¸­ï¼Œå´æ©è¾¾è€å¸ˆä½¿ç”¨çš„æ˜¯ä¸€ä¸ªç§°ä¸ºâ€œ`fminunc`â€çš„`Octave`å‡½æ•°æ˜¯ç”¨æ¥ä¼˜åŒ–å‡½æ•°æ¥è®¡ç®—æˆæœ¬å’Œæ¢¯åº¦å‚æ•°ã€‚ç”±äºæˆ‘ä»¬ä½¿ç”¨Pythonï¼Œæˆ‘ä»¬å¯ä»¥ç”¨ `scipy.optimize.fmin_tnc` æ¥åšåŒæ ·çš„äº‹æƒ…ã€‚

è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯é«˜çº§ä¼˜åŒ–ç®—æ³•ï¼Œè¿è¡Œé€Ÿåº¦é€šå¸¸è¿œè¿œè¶…è¿‡æ¢¯åº¦ä¸‹é™ã€‚æ–¹ä¾¿å¿«æ·ã€‚
åªéœ€ä¼ å…¥ cost å‡½æ•°ï¼Œå·²ç»æ‰€æ±‚çš„å˜é‡ thetaï¼Œå’Œæ¢¯åº¦ã€‚cost å‡½æ•°å®šä¹‰å˜é‡æ—¶å˜é‡ tehta è¦æ”¾åœ¨ç¬¬ä¸€ä¸ªï¼Œè‹¥ cost å‡½æ•°åªè¿”å› costï¼Œåˆ™è®¾ç½®`fprime=gradient`ã€‚

```python
import scipy.optimize as opt
result = opt.fmin_tnc(func=cost, x0=theta, fprime=gradient, args=(X, y))
result
# (array([-25.16131867,   0.20623159,   0.20147149]), 36, 0)
```

#### â‘¥ è¯„ä¼°é€»è¾‘å›å½’æ¨¡å‹

å­¦ä¹ å¥½äº†å‚æ•°Î¸åï¼Œæˆ‘ä»¬æ¥ç”¨è¿™ä¸ªæ¨¡å‹é¢„æµ‹æŸä¸ªå­¦ç”Ÿæ˜¯å¦èƒ½è¢«å½•å–ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬éœ€è¦ç¼–å†™ä¸€ä¸ªå‡½æ•°ï¼Œç”¨æˆ‘ä»¬æ‰€å­¦çš„å‚æ•°thetaæ¥ä¸ºæ•°æ®é›†Xè¾“å‡ºé¢„æµ‹ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªå‡½æ•°æ¥ç»™æˆ‘ä»¬çš„åˆ†ç±»å™¨çš„è®­ç»ƒç²¾åº¦æ‰“åˆ†ã€‚

é€»è¾‘å›å½’æ¨¡å‹çš„å‡è®¾å‡½æ•°ï¼š<img src="https://gitee.com/veal98/images/raw/master/img/20200618210313.png" style="zoom:67%;" />

- å½“ hÎ¸ å¤§äºç­‰äº 0.5 æ—¶ï¼Œé¢„æµ‹ y = 1

- å½“ hÎ¸ å°äº 0.5 æ—¶ï¼Œé¢„æµ‹ y = 0 

```python
def predict(theta, X):
    probability = sigmoid(X@theta) 
    return [1 if x >= 0.5 else 0 for x in probability]  # return a list

final_theta = result[0] # å°†æˆ‘ä»¬çš„ç®—æ³•ç»“æœä¸å·¥å…·åº“ä¸­çš„ç®—æ³•è¿›è¡Œæ¯”è¾ƒ
predictions = predict(final_theta,X)
correct = [1 if a==b else 0 for (a, b) in zip(predictions, y)]
accuracy = sum(correct) / len(X)
accuracy
```

![](https://gitee.com/veal98/images/raw/master/img/20200618211219.png)

å¯ä»¥çœ‹åˆ°æˆ‘ä»¬é¢„æµ‹ç²¾åº¦è¾¾åˆ°äº†89%ï¼Œnot bad.

#### â‘¦ å†³ç­–è¾¹ç•Œ

<img src="https://gitee.com/veal98/images/raw/master/img/20200618212931.png" style="zoom:80%;" />

ç”»å‡ºå†³ç­–è¾¹ç•Œï¼š

```python
x1 = np.arange(130, step=0.1)
x2 = ( - result[0][0] - result[0][1] * x1) / result[0][2]

fig, ax = plt.subplots(figsize=(8,5))
ax.scatter(positive['exam1'], positive['exam2'], c='b', label='Admitted')
ax.scatter(negetive['exam1'], negetive['exam2'], s=50, c='r', marker='x', label='Not Admitted')
ax.plot(x1, x2) # ç”»å‡ºå†³ç­–è¾¹ç•Œ
ax.set_xlim(0, 130)
ax.set_ylim(0, 130)
ax.set_xlabel('x1')
ax.set_ylabel('x2')
ax.set_title('Decision Boundary')
plt.show()
```

![](https://gitee.com/veal98/images/raw/master/img/20200618212101.png)

### 2. æ­£åˆ™åŒ–é€»è¾‘å›å½’

åœ¨è®­ç»ƒçš„ç¬¬äºŒéƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†è¦é€šè¿‡åŠ å…¥æ­£åˆ™é¡¹æå‡é€»è¾‘å›å½’ç®—æ³•ã€‚ç®€è€Œè¨€ä¹‹ï¼Œæ­£åˆ™åŒ–æ˜¯æˆæœ¬å‡½æ•°ä¸­çš„ä¸€ä¸ªæœ¯è¯­ï¼Œå®ƒä½¿ç®—æ³•æ›´å€¾å‘äºâ€œæ›´ç®€å•â€çš„æ¨¡å‹ï¼ˆåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¨¡å‹å°†æ›´å°çš„ç³»æ•°ï¼‰ã€‚è¿™ä¸ªç†è®ºåŠ©äºå‡å°‘è¿‡æ‹Ÿåˆï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

è®¾æƒ³ä½ æ˜¯å·¥å‚çš„ç”Ÿäº§ä¸»ç®¡ï¼Œä½ æœ‰ä¸€äº›èŠ¯ç‰‡åœ¨ä¸¤æ¬¡æµ‹è¯•ä¸­çš„æµ‹è¯•ç»“æœã€‚å¯¹äºè¿™ä¸¤æ¬¡æµ‹è¯•ï¼Œä½ æƒ³å†³å®šæ˜¯å¦èŠ¯ç‰‡è¦è¢«æ¥å—æˆ–æŠ›å¼ƒã€‚ä¸ºäº†å¸®åŠ©ä½ åšå‡ºè‰°éš¾çš„å†³å®šï¼Œä½ æ‹¥æœ‰è¿‡å»èŠ¯ç‰‡çš„æµ‹è¯•æ•°æ®é›†ï¼Œä»å…¶ä¸­ä½ å¯ä»¥æ„å»ºä¸€ä¸ªé€»è¾‘å›å½’æ¨¡å‹ã€‚

éƒ¨åˆ†æ•°æ®å¦‚ä¸‹ï¼š

> 0.051267,0.69956,1
>
> -0.092742,0.68494,1
>
> -0.21371,0.69225,1
>
> -0.375,0.50219,1
>
> -0.51325,0.46564,1
>
> -0.52477,0.2098,1
>
> -0.39804,0.034357,1
>
> -0.30588,-0.19225,1

#### â‘  æ•°æ®å¯è§†åŒ–

```python
data_init = pd.read_csv('ex2/ex2data2.txt', names=['Test1', 'Test2', 'Accepted'])
data_init.head()
```

![](https://gitee.com/veal98/images/raw/master/img/20200620102339.png)

æ¥ä¸‹é‡Œç”¨æ•£ç‚¹å›¾ç»˜åˆ¶æ•°æ®ï¼š

```python
def plot_data():
    positive = data_init[data_init['Accepted'].isin([1])]
    negative = data_init[dadata_initta2['Accepted'].isin([0])]
    
    fig,ax = plt.subplots(figsize = (8,5))
    ax.scatter(positive['Test1'],positive['Test2'], s = 50, c = 'b', marker = 'o', label = 'Accepted')
    ax.scatter(negative['Test1'],negative['Test2'], s = 50, c = 'r', marker = 'x', label = 'Rejected')
    ax.legend()
    ax.set_xlabel('Test1 Score')
    ax.set_ylabel('Test2 Score')

plot_data()
```

![](https://gitee.com/veal98/images/raw/master/img/20200620100814.png)

ä»¥ä¸Šå›¾ç‰‡æ˜¾ç¤ºï¼Œè¿™ä¸ªæ•°æ®é›†ä¸èƒ½åƒä¹‹å‰ä¸€æ ·ä½¿ç”¨ç›´çº¿å°†ä¸¤éƒ¨åˆ†åˆ†å‰²ã€‚è€Œé€»è¾‘å›å½’åªé€‚ç”¨äºçº¿æ€§çš„åˆ†å‰²ï¼Œæ‰€ä»¥ï¼Œè¿™ä¸ªæ•°æ®é›†ä¸é€‚åˆç›´æ¥ä½¿ç”¨é€»è¾‘å›å½’ã€‚

#### â‘¡ ç‰¹å¾æ˜ å°„ Feature mapping

>  ğŸ’¡ é¦–å…ˆè§£é‡Šä¸€ä¸‹**ä»€ä¹ˆæ˜¯ç‰¹å¾æ˜ å°„**ï¼š
>
>  å¦‚æœæ ·æœ¬é‡å¤šï¼Œé€»è¾‘å›å½’é—®é¢˜å¾ˆå¤æ‚ï¼Œè€ŒåŸå§‹ç‰¹å¾åªæœ‰ x1, x2ï¼Œå¯ä»¥ç”¨å¤šé¡¹å¼åˆ›å»ºæ›´å¤šçš„ç‰¹å¾x1ã€x2ã€x1x2ã€x1^2ã€x2^2ã€... X1^nX2^nã€‚å› ä¸ºæ›´å¤šçš„ç‰¹å¾è¿›è¡Œé€»è¾‘å›å½’æ—¶ï¼Œå¾—åˆ°çš„åˆ†å‰²çº¿å¯ä»¥æ˜¯ä»»æ„é«˜é˜¶å‡½æ•°çš„å½¢çŠ¶ã€‚

ä¸€ä¸ªæ‹Ÿåˆæ•°æ®çš„æ›´å¥½çš„æ–¹æ³•æ˜¯ä»æ¯ä¸ªæ•°æ®ç‚¹åˆ›å»ºæ›´å¤šçš„ç‰¹å¾ã€‚

æˆ‘ä»¬å°†æŠŠè¿™äº›ç‰¹å¾æ˜ å°„åˆ°æ‰€æœ‰çš„ x1 å’Œ x2 çš„å¤šé¡¹å¼é¡¹ä¸Šï¼Œç›´åˆ°ç¬¬å…­æ¬¡å¹‚ã€‚

![](https://gitee.com/veal98/images/raw/master/img/20200620102006.png)



```python
def feature_mapping(x1, x2, power):
    data = {}
    for i in np.arange(power + 1):
        for p in np.arange(i + 1):
            data["f{}{}".format(i - p, p)] = np.power(x1, i - p) * np.power(x2, p)

    return pd.DataFrame(data)

x1 = data_init['Test1'].values
x2 = data_init['Test2'].values

data = feature_mapping(x1, x2, power=6)
data.head()
```

![](https://gitee.com/veal98/images/raw/master/img/20200620120315.png)

ç»è¿‡æ˜ å°„ï¼Œæˆ‘ä»¬å°†æœ‰ä¸¤ä¸ªç‰¹å¾çš„å‘é‡è½¬åŒ–æˆäº†ä¸€ä¸ª 28 ç»´çš„å‘é‡ã€‚

åœ¨è¿™ä¸ªé«˜ç»´ç‰¹å¾å‘é‡ä¸Šè®­ç»ƒçš„logisticå›å½’åˆ†ç±»å™¨å°†ä¼šæœ‰ä¸€ä¸ªæ›´å¤æ‚çš„å†³ç­–è¾¹ç•Œï¼Œå½“æˆ‘ä»¬åœ¨äºŒç»´å›¾ä¸­ç»˜åˆ¶æ—¶ï¼Œä¼šå‡ºç°éçº¿æ€§ã€‚

è™½**ç„¶ç‰¹å¾æ˜ å°„å…è®¸æˆ‘ä»¬æ„å»ºä¸€ä¸ªæ›´æœ‰è¡¨ç°åŠ›çš„åˆ†ç±»å™¨ï¼Œä½†å®ƒä¹Ÿæ›´å®¹æ˜“è¿‡æ‹Ÿåˆ**ã€‚åœ¨æ¥ä¸‹æ¥çš„ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬å°†å®ç°æ­£åˆ™åŒ–çš„logisticå›å½’æ¥æ‹Ÿåˆæ•°æ®ï¼Œå¹¶ä¸”å¯ä»¥çœ‹åˆ°æ­£åˆ™åŒ–å¦‚ä½•å¸®åŠ©è§£å†³è¿‡æ‹Ÿåˆçš„é—®é¢˜ã€‚

#### â‘¢ ä»£ä»·å‡½æ•°

æ­£åˆ™åŒ–é€»è¾‘å›å½’æ¨¡å‹çš„ä»£ä»·å‡½æ•°å¦‚ä¸‹ï¼š

![](https://gitee.com/veal98/images/raw/master/img/20200603215306.png)

æ³¨æ„ï¼šÎ¸0 æ˜¯ä¸éœ€è¦æ­£åˆ™åŒ–çš„ï¼Œä¸‹æ ‡ä» 1 å¼€å§‹

```python
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def costReg(theta, X, y, learningRate):
    theta = np.matrix(theta)
    X = np.matrix(X)
    y = np.matrix(y)
    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))
    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))
    # æ­£åˆ™é¡¹
    reg = (learningRate / (2 * len(X))) * np.sum(np.power(theta[:,1:theta.shape[1]], 2))
    return np.sum(first - second) / len(X) + reg
```

```python
# åˆå§‹åŒ–Xï¼Œyï¼ŒÎ¸
cols = data.shape[1]
X = data.iloc[:,1:cols]
y = data.iloc[:,0:1]
theta = np.zeros(cols - 1) # Î¸0 æ˜¯ä¸éœ€è¦æ­£åˆ™åŒ–çš„
```

```python
# ç±»å‹è½¬æ¢
X = np.array(X.values)
y = np.array(y.values)

# Î»è®¾ä¸º1
learningRate = 1
```

è®¡ç®—åˆå§‹ä»£ä»·ï¼š

```python
# è®¡ç®—åˆå§‹ä»£ä»·
costReg(theta, X, y, learningRate)
```

![](https://gitee.com/veal98/images/raw/master/img/20200620104950.png)

#### â‘£ æ¢¯åº¦ä¸‹é™

å› ä¸ºæˆ‘ä»¬æœªå¯¹ Î¸0 è¿›è¡Œæ­£åˆ™åŒ–ï¼Œæ‰€ä»¥æ¢¯åº¦ä¸‹é™ç®—æ³•å°†åˆ†ä¸¤ç§æƒ…å½¢ï¼š

![](https://gitee.com/veal98/images/raw/master/img/20200603215413.png)

å¯¹ä¸Šé¢çš„ç®—æ³•ä¸­ j = 1,2,3...n æ—¶çš„æ›´æ–°å¼å­è¿›è¡Œè°ƒæ•´å¯å¾—ï¼š

<img src="https://gitee.com/veal98/images/raw/master/img/20200603214135.png" style="zoom: 80%;" />



```python
# é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™
def gradient(theta, X, y):
    theta = np.matrix(theta)
    X = np.matrix(X)
    y = np.matrix(y)
    
    parameters = int(theta.ravel().shape[1])
    grad = np.zeros(parameters)
    
    error = sigmoid(X * theta.T) - y
    
    for i in range(parameters):
        term = np.multiply(error, X[:,i])
        grad[i] = np.sum(term) / len(X) # è®¡ç®—å‡º3ä¸ªÎ¸å€¼
    
    return grad 

# æ­£åˆ™åŒ–é€»è¾‘å›å½’æ¢¯åº¦ä¸‹é™
def gradientReg(theta, X, y, learningRate):
    reg = (learningRate / len(X)) * theta
    reg[0] = 0
    return gradient(theta, X, y) + reg
```

![](https://gitee.com/veal98/images/raw/master/img/20200620112828.png)

#### â‘¤ ç”¨å·¥å…·åº“æ±‚è§£å‚æ•°

ä½¿ç”¨ `scipy.optimize.fmin_tnc` è®¡ç®—ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦

```python
import scipy.optimize as opt
result = opt.fmin_tnc(func=costReg, x0=theta, fprime=gradientReg, args=(X, y, learningRate))

result
```

![](https://gitee.com/veal98/images/raw/master/img/20200620113045.png)

#### â‘¥ è¯„ä¼°æ­£åˆ™åŒ–é€»è¾‘å›å½’æ¨¡å‹

åŒæ ·ï¼Œä½¿ç”¨ä¸Šä¸€èŠ‚å®éªŒä¸­çš„è¯„ä¼°å‡½æ•°æŸ¥çœ‹æˆ‘ä»¬çš„å‡†ç¡®åº¦

```python
def predict(theta, X):
    probability = sigmoid(X@theta) 
    return [1 if x >= 0.5 else 0 for x in probability]  # return a list

final_theta = result[0] # å°†æˆ‘ä»¬çš„ç®—æ³•ç»“æœä¸å·¥å…·åº“ä¸­çš„ç®—æ³•è¿›è¡Œæ¯”è¾ƒ
predictions = predict(final_theta,X)
correct = [1 if a==b else 0 for (a, b) in zip(predictions, y)]
accuracy = sum(correct) / len(correct)
accuracy
```

![](https://gitee.com/veal98/images/raw/master/img/20200620113624.png)

#### â‘¦ å†³ç­–è¾¹ç•Œ

> âœ… Todo

## ğŸš€ Ex3ï¼šå¤šç±»åˆ«é€»è¾‘å›å½’ + ç¥ç»ç½‘ç»œ

### 1. å¤šç±»åˆ†ç±»

è¿™ä¸ªéƒ¨åˆ†éœ€è¦å®ç°æ‰‹å†™æ•°å­—ï¼ˆ0åˆ°9ï¼‰çš„è¯†åˆ«ã€‚æˆ‘ä»¬å°†æ‰©å±•æˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚ç¼–ç¨‹ä½œä¸šä¸­å†™çš„ logistic å›å½’çš„å®ç°ï¼Œå¹¶å°†å…¶åº”ç”¨äºä¸€å¯¹å¤šçš„åˆ†ç±»ï¼ˆä¸æ­¢ä¸¤ä¸ªç±»åˆ«ï¼‰ã€‚

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.io import loadmat
```

#### â‘  æ•°æ®é›† DataSet

é¦–å…ˆï¼ŒåŠ è½½æ•°æ®é›†ã€‚è¿™é‡Œçš„æ•°æ®ä¸ºMATLABçš„æ ¼å¼ï¼Œæ‰€ä»¥è¦ä½¿ç”¨`SciPy.io`çš„`loadmat`å‡½æ•°ã€‚

è¿™ä¸ª MATLAB æ ¼å¼çš„ `.mat` æ–‡ä»¶ï¼ŒåŒ…å« 5000 ä¸ª 20*20 åƒç´ çš„æ‰‹å†™å­—ä½“å›¾åƒï¼Œä»¥åŠä»–å¯¹åº”çš„æ•°å­—ã€‚å¦å¤–ï¼Œæ•°å­—0 çš„ y å€¼ï¼Œå¯¹åº”çš„æ˜¯10

```python
def load_data(path):
    data = loadmat(path)
    X = data['X']
    y = data['y']
    return X,y

X,y = load_data('ex3/ex3data1.mat')
print(np.unique(y))  # çœ‹ä¸‹æœ‰å‡ ç±»æ ‡ç­¾ [ 1  2  3  4  5  6  7  8  9 10]
X.shape, y.shape  # (5000, 400), (5000, 1))
```

å…¶ä¸­æœ‰5000ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯20*20åƒç´ çš„æ•°å­—çš„ç°åº¦å›¾åƒã€‚æ¯ä¸ªåƒç´ ä»£è¡¨ä¸€ä¸ªæµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºè¯¥ä½ç½®çš„ç°åº¦å¼ºåº¦ã€‚20Ã—20 çš„åƒç´ ç½‘æ ¼è¢«å±•å¼€æˆä¸€ä¸ª 400 ç»´çš„å‘é‡ã€‚åœ¨æˆ‘ä»¬çš„æ•°æ®çŸ©é˜µXä¸­ï¼Œæ¯ä¸€ä¸ªæ ·æœ¬éƒ½å˜æˆäº†ä¸€è¡Œï¼Œè¿™ç»™äº†æˆ‘ä»¬ä¸€ä¸ª 5000Ã—400 çŸ©é˜µ Xï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªæ‰‹å†™æ•°å­—å›¾åƒçš„è®­ç»ƒæ ·æœ¬ã€‚

<img src="https://gitee.com/veal98/images/raw/master/img/20200621114035.png" style="zoom:80%;" />

#### â‘¡ æ•°æ®å¯è§†åŒ–

```python
def plot_an_image(X):
    # éšæœºæ‰“å°ä¸€ä¸ªæ•°å­—
    pick_one = np.random.randint(0,5000)
    image = X[pick_one,:]
    fig,ax = plt.subplots(figsize = (1,1))
    ax.matshow(image.reshape((20,20)),cmap = 'gray_r')
    plt.show()
    print('this should be {}'.format(y[pick_one]))

plot_an_image(X)
```

![](https://gitee.com/veal98/images/raw/master/img/20200621114530.png)

```python
def plot_100_image(X):
    # éšæœºæ‰¾å‡º 100 å¼ å›¾ç‰‡
    sample_idx =np.random.choice(np.arange(X.shape[0]),100) # éšæœºé€‰ 100 ä¸ªæ ·æœ¬
    sample_images = X[sample_idx,:] # (100,400)
    fig,ax_array = plt.subplots(nrows = 10, ncols = 10, sharey = True, sharex = True, figsize = (8,8))
    
    for row in range(10):
        for column in range(10):
            ax_array[row,column].matshow(sample_images[10*row + column].reshape((20,20)),cmap = 'gray_r')
          
    plt.xticks([]) # å»é™¤åˆ»åº¦ï¼Œç¾è§‚
    plt.yticks([])        
    plt.show()
    
plot_100_image(X)
```

![](https://gitee.com/veal98/images/raw/master/img/20200621115348.png)

#### â‘¢ å‘é‡åŒ–é€»è¾‘å›å½’ Vectorizing

ä½ å°†ç”¨å¤šåˆ†ç±»é€»è¾‘å›å½’åšä¸€ä¸ªåˆ†ç±»å™¨ã€‚å› ä¸ºç°åœ¨æœ‰10ä¸ªæ•°å­—ç±»åˆ«ï¼Œæ‰€ä»¥ä½ éœ€è¦è®­ç»ƒ10ä¸ªä¸åŒçš„é€»è¾‘å›å½’åˆ†ç±»å™¨ã€‚ä¸ºäº†è®©è®­ç»ƒæ•ˆç‡æ›´é«˜ï¼Œ**å°†é€»è¾‘å›å½’å‘é‡åŒ–**æ˜¯éå¸¸é‡è¦çš„ï¼Œä¸è¦ç”¨å¾ªç¯ã€‚

<u>åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†å®ç°ä¸€ä¸ªä¸ä½¿ç”¨ä»»ä½•forå¾ªç¯çš„å‘é‡åŒ–çš„logisticå›å½’ç‰ˆæœ¬</u>ã€‚

##### â…  å‘é‡åŒ–ä»£ä»·å‡½æ•°

é¦–å…ˆå†™å‡ºå‘é‡åŒ–çš„ä»£ä»·å‡½æ•°ã€‚

å›æƒ³æ­£åˆ™åŒ–çš„logisticå›å½’çš„ä»£ä»·å‡½æ•°æ˜¯ï¼š

![](https://gitee.com/veal98/images/raw/master/img/20200621115706.png)

äº‹å®ä¸Šæˆ‘ä»¬å¯ä»¥å¯¹æ‰€æœ‰çš„æ ·æœ¬ç”¨çŸ©é˜µä¹˜æ³•æ¥å¿«é€Ÿçš„è®¡ç®—ã€‚è®©æˆ‘ä»¬å¦‚ä¸‹æ¥å®šä¹‰ X å’Œ Î¸ ï¼š

<img src="https://gitee.com/veal98/images/raw/master/img/20200621115845.png" style="zoom:80%;" />

ğŸš© å¦‚æœ a å’Œ b éƒ½æ˜¯å‘é‡ï¼Œé‚£ä¹ˆ $a^Tb = b^Ta$ï¼Œåˆ™ï¼š

<img src="https://gitee.com/veal98/images/raw/master/img/20200621120015.png" style="zoom:80%;" />

```python
def sigmoid(z):
    return 1 / (1 + np.exp(-z))

def regularized_cost(theta, X, y, l):
    """
    args:
        X: feature matrix, (m, n+1) # æ’å…¥äº†x0=1
        y: target vector, (m, )
        l: lambda constant for regularization
    """
    thetaReg = theta[1:] # theta_0 ä¸éœ€è¦æ­£åˆ™åŒ–
    first = (-y*np.log(sigmoid(X@theta))) + (y-1)*np.log(1-sigmoid(X@theta))
    reg = (thetaReg@thetaReg)*l / (2*len(X))
    return np.mean(first) + reg
```

##### â…¡ å‘é‡åŒ–æ¢¯åº¦

å›é¡¾æ­£åˆ™åŒ–logisticå›å½’ä»£ä»·å‡½æ•°çš„æ¢¯åº¦ä¸‹é™æ³•å¦‚ä¸‹è¡¨ç¤ºï¼Œå› ä¸ºä¸æƒ©ç½š $\theta_0$ï¼Œæ‰€ä»¥åˆ†ä¸ºä¸¤ç§æƒ…å†µï¼š

![](https://gitee.com/veal98/images/raw/master/img/20200603215413.png)

ä»¤ $(h_\theta(x^{(i)})-y^{(i)}) = Î²_i$  åŒç†ï¼š

<img src="https://gitee.com/veal98/images/raw/master/img/20200621141545.png" style="zoom:80%;" />

æ‰€ä»¥å…¶ä¸­çš„æ¢¯åº¦è¡¨ç¤ºå¦‚ä¸‹ï¼š

```python
def regularized_gradient(theta, X, y, l):
    """
    don't penalize theta_0
    args:
        l: lambda constant
    return:
        a vector of gradient
    """
    thetaReg = theta[1:]
    first = (1 / len(X)) * X.T @ (sigmoid(X @ theta) - y)
    
    # è¿™é‡Œäººä¸ºæ’å…¥ä¸€ç»´0ï¼Œä½¿å¾—å¯¹theta_0ä¸æƒ©ç½šï¼Œæ–¹ä¾¿è®¡ç®—
    reg = np.concatenate([np.array([0]), (l / len(X)) * thetaReg])
    return first + reg
```

> ğŸ’¡ `concatenate((a1, a2, â€¦), axis=0)` æ•°ç»„æ‹¼æ¥å‡½æ•° 
>
> å‚æ•°: 
>
> - a1, a2 â€¦â€¦ä¸ºè¦æ‹¼æ¥çš„æ•°ç»„ 
> - axis ä¸ºåœ¨å“ªä¸ªç»´åº¦ä¸Šè¿›è¡Œæ‹¼æ¥ï¼Œé»˜è®¤ä¸º 0

#### â‘£ ä¸€å¯¹å¤šåˆ†ç±»å™¨ One-vs-all Classification

ç°åœ¨æˆ‘ä»¬å·²ç»å®šä¹‰äº†ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦å‡½æ•°ï¼Œç°åœ¨æ˜¯æ„å»ºåˆ†ç±»å™¨çš„æ—¶å€™äº†ã€‚ å¯¹äºè¿™ä¸ªä»»åŠ¡ï¼Œæˆ‘ä»¬æœ‰10ä¸ªå¯èƒ½çš„ç±»ï¼Œå¹¶ä¸”ç”±äºé€»è¾‘å›å½’åªèƒ½ä¸€æ¬¡åœ¨ 2 ä¸ªç±»ä¹‹é—´è¿›è¡Œåˆ†ç±»ï¼Œæˆ‘ä»¬éœ€è¦å¤šç±»åˆ†ç±»çš„ç­–ç•¥ã€‚ åœ¨æœ¬ç»ƒä¹ ä¸­ï¼Œæˆ‘ä»¬çš„ä»»åŠ¡æ˜¯å®ç°ä¸€å¯¹ä¸€å…¨åˆ†ç±»æ–¹æ³•ï¼Œå…¶ä¸­**å…·æœ‰ k ä¸ªä¸åŒç±»çš„æ ‡ç­¾å°±æœ‰ k ä¸ªåˆ†ç±»å™¨ï¼Œæ¯ä¸ªåˆ†ç±»å™¨åœ¨ â€œç±»åˆ« iâ€ å’Œ â€œä¸æ˜¯ iâ€ ä¹‹é—´å†³å®š**ã€‚ æˆ‘ä»¬å°†æŠŠåˆ†ç±»å™¨è®­ç»ƒåŒ…å«åœ¨ä¸€ä¸ªå‡½æ•°ä¸­ï¼Œè¯¥å‡½æ•°è®¡ç®— 10 ä¸ªåˆ†ç±»å™¨ä¸­çš„æ¯ä¸ªåˆ†ç±»å™¨çš„æœ€ç»ˆæƒé‡ï¼Œå¹¶å°†æƒé‡è¿”å›ä¸º `k * (n + 1)` æ•°ç»„ï¼Œå…¶ä¸­ n æ˜¯å‚æ•°æ•°é‡ã€‚

è¿™é‡Œéœ€è¦æ³¨æ„çš„å‡ ç‚¹ï¼š

- é¦–å…ˆï¼Œæˆ‘ä»¬ä¸ºXæ·»åŠ äº†ä¸€åˆ—å¸¸æ•°é¡¹ 1 ï¼Œä»¥è®¡ç®—æˆªè·é¡¹ï¼ˆå¸¸æ•°é¡¹ï¼‰ã€‚ 
- å…¶æ¬¡ï¼Œæˆ‘ä»¬å°† y ä»ç±»æ ‡ç­¾è½¬æ¢ä¸ºæ¯ä¸ªåˆ†ç±»å™¨çš„äºŒè¿›åˆ¶å€¼ï¼ˆè¦ä¹ˆæ˜¯ç±» iï¼Œè¦ä¹ˆä¸æ˜¯ç±» iï¼‰ã€‚ 
- æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨ `SciPy` çš„è¾ƒæ–°ä¼˜åŒ–APIæ¥æœ€å°åŒ–æ¯ä¸ªåˆ†ç±»å™¨çš„ä»£ä»·å‡½æ•°ã€‚ å¦‚æœæŒ‡å®šçš„è¯ï¼ŒAPI å°†é‡‡ç”¨ç›®æ ‡å‡½æ•°ï¼Œåˆå§‹å‚æ•°é›†ï¼Œä¼˜åŒ–æ–¹æ³•å’Œ`jacobian`ï¼ˆæ¸å˜ï¼‰å‡½æ•°ã€‚ ç„¶åå°†ä¼˜åŒ–ç¨‹åºæ‰¾åˆ°çš„å‚æ•°åˆ†é…ç»™å‚æ•°æ•°ç»„ã€‚

```python
from scipy.optimize import minimize

def one_vs_all(X, y, l, K):
    """generalized logistic regression
    args:
        X: feature matrix, (m, n+1) # with incercept x0=1
        y: target vector, (m, )
        l: lambda constant for regularization
        K: numbel of labels
    return: trained parameters
    """
    all_theta = np.zeros((K, X.shape[1]))  # (10, 401)
    
    for i in range(1, K+1):
        theta = np.zeros(X.shape[1])
        y_i = np.array([1 if label == i else 0 for label in y])
    
        ret = minimize(fun=regularized_cost, x0=theta, args=(X, y_i, l), method='TNC',
                        jac=regularized_gradient, options={'disp': True})
        all_theta[i-1,:] = ret.x
                         
    return all_theta
```



> ğŸ’¡ `scipy.optimize.minimize`å‡½æ•°è¯¦è§£ï¼š(`minimize` æ˜¯å±€éƒ¨æœ€ä¼˜çš„è§£æ³• )
>
> ```python
> scipy.optimize.minimize(fun, x0, args=(), method=None, jac=None, hess=None, hessp=None, bounds=None, constraints=(), tol=None,  callback=None, options=None)
> ```
>
> - `fun `:  æ±‚æœ€å°å€¼çš„ç›®æ ‡å‡½æ•° 
>
> - `x0`: å˜é‡çš„åˆå§‹çŒœæµ‹å€¼ï¼Œå¦‚æœæœ‰å¤šä¸ªå˜é‡ï¼Œéœ€è¦ç»™æ¯ä¸ªå˜é‡ä¸€ä¸ªåˆå§‹çŒœæµ‹å€¼ã€‚
>
> - `args`: å¸¸æ•°å€¼ï¼Œfun ä¸­æ²¡æœ‰æ•°å­—ï¼Œéƒ½ä»¥å˜é‡çš„å½¢å¼è¡¨ç¤ºï¼Œå¯¹äºå¸¸æ•°é¡¹ï¼Œéœ€è¦åœ¨è¿™é‡Œç»™å€¼ 
>
> - `method`: æ±‚æå€¼çš„æ–¹æ³•ï¼Œå®˜æ–¹æ–‡æ¡£ç»™äº†å¾ˆå¤šç§ã€‚ä¸€èˆ¬ä½¿ç”¨é»˜è®¤ 
>
>   ![](https://gitee.com/veal98/images/raw/master/img/20200621143625.png)
>
> - `jac`ï¼šæ¸å˜å‡½æ•°
>
> - `constraints `: çº¦æŸæ¡ä»¶ï¼Œé’ˆå¯¹funä¸­ä¸ºå‚æ•°çš„éƒ¨åˆ†è¿›è¡Œçº¦æŸé™åˆ¶

å®ç°å‘é‡åŒ–ä»£ç çš„ä¸€ä¸ªæ›´å…·æŒ‘æˆ˜æ€§çš„éƒ¨åˆ†æ˜¯æ­£ç¡®åœ°å†™å…¥æ‰€æœ‰çš„çŸ©é˜µï¼Œä¿è¯ç»´åº¦æ­£ç¡®ã€‚

```python
def predict_all(X, all_theta):
    # compute the class probability for each class on each training instance   
    h = sigmoid(X @ all_theta.T)  # æ³¨æ„çš„è¿™é‡Œçš„all_thetaéœ€è¦è½¬ç½®
    
    # create array of the index with the maximum probability
    # Returns the indices of the maximum values along an axis.
    h_argmax = np.argmax(h, axis=1)
    
    # because our array was zero-indexed we need to add one for the true label prediction
    h_argmax = h_argmax + 1
    
    return h_argmax
```

è¿™é‡Œçš„`h`å…±5000è¡Œï¼Œ10åˆ—ï¼Œæ¯è¡Œä»£è¡¨ä¸€ä¸ªæ ·æœ¬ï¼Œæ¯åˆ—æ˜¯é¢„æµ‹å¯¹åº”æ•°å­—çš„æ¦‚ç‡ã€‚æˆ‘**ä»¬å–æ¦‚ç‡æœ€å¤§å¯¹åº”çš„`index`åŠ  1 å°±æ˜¯æˆ‘ä»¬åˆ†ç±»å™¨æœ€ç»ˆé¢„æµ‹å‡ºæ¥çš„ç±»åˆ«**ã€‚è¿”å›çš„`h_argmax`æ˜¯ä¸€ä¸ªarrayï¼ŒåŒ…å«5000ä¸ªæ ·æœ¬å¯¹åº”çš„é¢„æµ‹å€¼ã€‚

```python
raw_X, raw_y = load_data('ex3data1.mat')
X = np.insert(raw_X, 0, 1, axis=1) # (5000, 401)
y = raw_y.flatten()  # è¿™é‡Œæ¶ˆé™¤äº†ä¸€ä¸ªç»´åº¦å˜æˆä¸€ç»´æ•°ç»„ï¼Œæ–¹ä¾¿åé¢çš„è®¡ç®— or .reshape(-1) ï¼ˆ5000ï¼Œï¼‰


all_theta = one_vs_all(X, y, 1, 10)
all_theta  # æ¯ä¸€è¡Œæ˜¯ä¸€ä¸ªåˆ†ç±»å™¨çš„ä¸€ç»„å‚æ•°
```

> ğŸ’¡ `numpy.ndarray.flatten` å‡½æ•°ï¼š
>
> è¿”å›ä¸€ä¸ªæŠ˜å æˆä¸€ç»´çš„æ•°ç»„ã€‚ä½†æ˜¯è¯¥å‡½æ•°åªèƒ½é€‚ç”¨äºnumpyå¯¹è±¡ï¼Œå³arrayæˆ–è€…matï¼Œæ™®é€šçš„liståˆ—è¡¨æ˜¯ä¸è¡Œçš„ã€‚

![](https://gitee.com/veal98/images/raw/master/img/20200621151149.png)

```python
y_pred = predict_all(X, all_theta)
accuracy = np.mean(y_pred == y)
print ('accuracy = {0}%'.format(accuracy * 100))
```

![](https://gitee.com/veal98/images/raw/master/img/20200621151214.png)

### 2. ç¥ç»ç½‘ç»œ

ä¸Šé¢ä½¿ç”¨äº†å¤šç±»logisticå›å½’ï¼Œç„¶è€Œlogisticå›å½’ä¸èƒ½å½¢æˆæ›´å¤æ‚çš„å‡è®¾ï¼Œå› ä¸ºå®ƒåªæ˜¯ä¸€ä¸ªçº¿æ€§åˆ†ç±»å™¨ã€‚

æ¥ä¸‹æ¥æˆ‘ä»¬ç”¨ç¥ç»ç½‘ç»œæ¥å°è¯•ä¸‹ï¼Œç¥ç»ç½‘ç»œå¯ä»¥å®ç°éå¸¸å¤æ‚çš„éçº¿æ€§çš„æ¨¡å‹ã€‚æˆ‘ä»¬å°†åˆ©ç”¨å·²ç»è®­ç»ƒå¥½äº†çš„æƒé‡è¿›è¡Œé¢„æµ‹ã€‚

#### â‘  æ¨¡å‹è¡¨è¾¾

<img src="https://gitee.com/veal98/images/raw/master/img/20200621151250.png" style="zoom:80%;" />

è¾“å…¥æ˜¯å›¾ç‰‡çš„åƒç´ å€¼ï¼Œ20*20åƒç´ çš„å›¾ç‰‡æœ‰400ä¸ªè¾“å…¥å±‚å•å…ƒï¼Œä¸åŒ…æ‹¬éœ€è¦é¢å¤–æ·»åŠ çš„åŠ ä¸Šå¸¸æ•°é¡¹ã€‚ ææ–™å·²ç»æä¾›äº†è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œçš„å‚æ•°Î˜(1),Î˜(2)ï¼Œæœ‰25ä¸ªéšå±‚å•å…ƒå’Œ10ä¸ªè¾“å‡ºå•å…ƒï¼ˆ10ä¸ªè¾“å‡ºï¼‰

#### â‘¡ å‰é¦ˆç¥ç»ç½‘ç»œå’Œé¢„æµ‹

ä½ éœ€è¦å®ç°å‰é¦ˆç¥ç»ç½‘ç»œé¢„æµ‹æ‰‹å†™æ•°å­—çš„åŠŸèƒ½ã€‚å’Œä¹‹å‰çš„ä¸€å¯¹å¤šåˆ†ç±»ä¸€æ ·ï¼Œç¥ç»ç½‘ç»œçš„é¢„æµ‹ä¼šæŠŠ$(h_\theta(x))_k$ä¸­å€¼æœ€å¤§çš„ï¼Œä½œä¸ºé¢„æµ‹è¾“å‡º

```python
def load_weight(path):
    data = loadmat(path)
    return data['Theta1'], data['Theta2']

theta1, theta2 = load_weight('ex3/ex3weights.mat')
theta1.shape, theta2.shape # ((25, 401), (10, 26))
```

æ’å…¥å¸¸æ•°é¡¹

```python
X, y = load_data('ex3/ex3data1.mat')
y = y.flatten()  # å°† y è½¬æˆä¸€ç»´æ•°ç»„ï¼Œä¾¿äºè®¡ç®—
X = np.insert(X, 0, values=np.ones(X.shape[0]), axis=1)  # æ’å…¥å¸¸æ•°é¡¹

X.shape, y.shape # ((5000, 401), (5000,))
```

æŒ‰ç…§ä¸Šé¢çš„æ¨¡å‹è¡¨ç¤ºï¼š

```python
a1 = X
z2 = a1 @ theta1.T
z2.shape
```

```python
z2 = np.insert(z2, 0, 1, axis=1)
z2.shape # (5000, 26)
```

```python
a2 = sigmoid(z2)
a2.shape # (5000, 26)
```

```python
z3 = a2 @ theta2.T
z3.shape # (5000, 10)
```

```python
a3 = sigmoid(z3)
a3.shape # (5000, 10)
```

è¯„ä¼°å‡†ç¡®åº¦ï¼š

```python
y_pred = np.argmax(a3, axis=1) + 1 
accuracy = np.mean(y_pred == y)
print ('accuracy = {0}%'.format(accuracy * 100))  # accuracy = 97.52%
```

![](https://gitee.com/veal98/images/raw/master/img/20200621152626.png)

è™½ç„¶äººå·¥ç¥ç»ç½‘ç»œæ˜¯éå¸¸å¼ºå¤§çš„æ¨¡å‹ï¼Œä½†è®­ç»ƒæ•°æ®çš„å‡†ç¡®æ€§æœ‰å¯èƒ½æ— æ³•å®Œç¾é¢„æµ‹å®é™…æ•°æ®ï¼Œå¾ˆå®¹æ˜“è¿‡æ‹Ÿåˆã€‚

## ğŸš€ Ex4ï¼šåå‘ä¼ æ’­ç¥ç»ç½‘ç»œ

### 1. ç¥ç»ç½‘ç»œ

åœ¨è¿™ä¸ªç»ƒä¹ ä¸­ï¼Œä½ å°†å®ç°**åå‘ä¼ æ’­ç®—æ³•æ¥å­¦ä¹ ç¥ç»ç½‘ç»œçš„å‚æ•°**ã€‚ä¾æ—§æ˜¯ä¸Šæ¬¡é¢„æµ‹æ‰‹å†™æ•°æ•°å­—çš„ä¾‹å­ã€‚

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat
```

#### â‘  å¯è§†åŒ–æ•°æ®

è¿™éƒ¨åˆ†æˆ‘ä»¬éšæœºé€‰å–100ä¸ªæ ·æœ¬å¹¶å¯è§†åŒ–ã€‚è®­ç»ƒé›†å…±æœ‰5000ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯20*20åƒç´ çš„æ•°å­—çš„ç°åº¦å›¾åƒã€‚æ¯ä¸ªåƒç´ ä»£è¡¨ä¸€ä¸ªæµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºè¯¥ä½ç½®çš„ç°åº¦å¼ºåº¦ã€‚20Ã—20çš„åƒç´ ç½‘æ ¼è¢«å±•å¼€æˆä¸€ä¸ª400ç»´çš„å‘é‡ã€‚åœ¨æˆ‘ä»¬çš„æ•°æ®çŸ©é˜µXä¸­ï¼Œæ¯ä¸€ä¸ªæ ·æœ¬éƒ½å˜æˆäº†ä¸€è¡Œï¼Œè¿™ç»™äº†æˆ‘ä»¬ä¸€ä¸ª 5000Ã—400 çŸ©é˜µXï¼Œæ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ªæ‰‹å†™æ•°å­—å›¾åƒçš„è®­ç»ƒæ ·æœ¬ã€‚

```python
def load_mat(path):
    # è¯»å–æ•°æ®
    data = loadmat(path)
    X = data['X']
    y = data['y'].flatten()
    return X,y
```

```python
def plot_100_images(X):
    """éšæœºç”»100ä¸ªæ•°å­—"""
    index = np.random.choice(range(5000), 100)
    images = X[index]
    fig, ax_array = plt.subplots(10, 10, sharey=True, sharex=True, figsize=(8, 8))
    for r in range(10):
        for c in range(10):
            ax_array[r, c].matshow(images[r*10 + c].reshape(20,20), cmap='gray_r')
    plt.xticks([])
    plt.yticks([])
    plt.show()
```

```python
X,y = load_mat('ex4/ex4data1.mat')
plot_100_images(X)
```

![](https://gitee.com/veal98/images/raw/master/img/20200622144244.png)

#### â‘¡ æ¨¡å‹å±•ç¤º

æˆ‘ä»¬çš„ç½‘ç»œæœ‰ä¸‰å±‚ï¼Œè¾“å…¥å±‚ï¼Œéšè—å±‚ï¼Œè¾“å‡ºå±‚ã€‚æˆ‘ä»¬çš„è¾“å…¥æ˜¯æ•°å­—å›¾åƒçš„åƒç´ å€¼ï¼Œå› ä¸ºæ¯ä¸ªæ•°å­—çš„å›¾åƒå¤§å°ä¸º20*20ï¼Œæ‰€ä»¥æˆ‘ä»¬è¾“å…¥å±‚æœ‰400ä¸ªå•å…ƒï¼ˆè¿™é‡Œä¸åŒ…æ‹¬æ€»æ˜¯è¾“å‡ºè¦åŠ ä¸€ä¸ªåç½®å•å…ƒï¼‰ã€‚

![](https://gitee.com/veal98/images/raw/master/img/20200622144522.png)

##### â…  è¯»å–æ•°æ®

é¦–å…ˆæˆ‘ä»¬è¦**å°†æ ‡ç­¾å€¼ï¼ˆ1ï¼Œ2ï¼Œ3ï¼Œ4ï¼Œâ€¦ï¼Œ10ï¼‰è½¬åŒ–æˆéçº¿æ€§ç›¸å…³çš„å‘é‡**ï¼Œå‘é‡å¯¹åº”ä½ç½®ï¼ˆ`y[i-1]`ï¼‰ä¸Šçš„å€¼ç­‰äº1ï¼Œä¾‹å¦‚ `y[0]=6` è½¬åŒ–ä¸º `y[0]=[0,0,0,0,0,1,0,0,0,0]`ã€‚

```python
def expand_y(y):
    result = []
    
    for i in y:
        y_array = np.zeros(10)
        y_array[i-1] = 1
        result.append(y_array)
        
    return np.array(result)
```

è·å–è®­ç»ƒæ•°æ®é›†ï¼Œä»¥åŠå¯¹è®­ç»ƒé›†åšç›¸åº”çš„å¤„ç†ï¼Œå¾—åˆ°æˆ‘ä»¬çš„ input Xï¼Œlables yï¼š

```python
raw_X, raw_y = load_mat('ex4/ex4data1.mat')
X = np.insert(raw_X, 0, 1, axis = 1) # æ’å…¥åç½®é¡¹ 1
y = expand_y(raw_y) # å°†æ ‡ç­¾å€¼è½¬æ¢æˆå‘é‡
X.shape,y.shape # ((5000, 401), (5000, 10))
```

##### â…¡ è¯»å–å‚æ•°

`ex4weights.mat` æ–‡ä»¶ä¸­å·²ç»æä¾›äº†è®­ç»ƒå¥½çš„å‚æ•° Î¸1 å’Œ Î¸2ã€‚è¿™äº›å‚æ•°çš„ç»´åº¦ç”±ç¥ç»ç½‘ç»œçš„å¤§å°å†³å®šï¼Œç¬¬äºŒå±‚æœ‰ 25 ä¸ªå•å…ƒï¼Œè¾“å‡ºå±‚æœ‰ 10 ä¸ªå•å…ƒ(å¯¹åº”10ä¸ªæ•°å­—ç±»/æ ‡ç­¾)ã€‚

```python
def load_weight(path):
    data = loadmat(path)
    return data['Theta1'],data['Theta2']
```

```python
t1,t2 = load_weight('ex4/ex4weights.mat')
t1.shape,t2.shape # ((25, 401), (10, 26))
```

##### â…¢ å±•å¼€å‚æ•°

å½“æˆ‘ä»¬ä½¿ç”¨é«˜çº§ä¼˜åŒ–æ–¹æ³•æ¥ä¼˜åŒ–ç¥ç»ç½‘ç»œæ—¶ï¼Œæˆ‘ä»¬éœ€è¦**å°†å¤šä¸ªå‚æ•°çŸ©é˜µå±•å¼€æˆå‘é‡**ï¼Œæ‰èƒ½ä¼ å…¥ä¼˜åŒ–å‡½æ•°ï¼Œç„¶åå†æ¢å¤å½¢çŠ¶ã€‚

```python
def serialize(a,b):
    # å±•å¼€å‚æ•°
    return np.r_[a.flatten(),b.flatten()]

theta = serialize(t1,t2) # æ‰å¹³åŒ–å‚æ•°ï¼Œ25*401+10*26=10285
theta.shape # (10285,)
```

```python
def deserialize(seq):
    '''æå–å‚æ•°'''
    return seq[:25*401].reshape(25, 401), seq[25*401:].reshape(10, 26)
```

> ğŸ’¡ `numpy.r_`ï¼šæŒ‰åˆ—è¿æ¥ä¸¤ä¸ªçŸ©é˜µã€‚å°±æ˜¯æŠŠä¸¤çŸ©é˜µä¸Šä¸‹ç›¸åŠ ï¼Œè¦æ±‚åˆ—æ•°ç›¸ç­‰ã€‚
>
> `np.c_`ï¼šæŒ‰è¡Œè¿æ¥ä¸¤ä¸ªçŸ©é˜µã€‚å°±æ˜¯æŠŠä¸¤çŸ©é˜µå·¦å³ç›¸åŠ ï¼Œè¦æ±‚è¡Œæ•°ç›¸ç­‰ã€‚
>
> ä¸¾ä¾‹å¦‚ä¸‹ï¼š
>
> ```python
> a = np.array([[1, 2, 3],[7,8,9]])
> 
> b=np.array([[4,5,6],[1,2,3]])
> 
> a
> Out[4]: 
> array([[1, 2, 3],
>     [7, 8, 9]])
> 
> b
> Out[5]: 
> array([[4, 5, 6],
>     [1, 2, 3]])
> 
> c=np.c_[a,b]
> 
> c
> Out[7]: 
> array([[1, 2, 3, 4, 5, 6],
>     [7, 8, 9, 1, 2, 3]])
> 
> 
> 
> d= np.array([7,8,9])
> 
> e=np.array([1, 2, 3])
> 
> f=np.c_[d,e]
> 
> f
> Out[12]: 
> array([[7, 1],
>     [8, 2],
>     [9, 3]])
> ```

#### â‘¢ å‰é¦ˆå’Œä»£ä»·å‡½æ•° Feedforward and cost function

##### â…  å‰é¦ˆ

ç¡®ä¿æ¯å±‚çš„å•å…ƒæ•°ï¼Œæ³¨æ„è¾“å‡ºæ—¶åŠ ä¸€ä¸ªåç½®å•å…ƒï¼Œs(1)=400+1ï¼Œs(2)=25+1ï¼Œs(3)=10ã€‚

![](https://gitee.com/veal98/images/raw/master/img/20200622150846.png)

```python
def sigmoid(z):
    return 1 / (1 + np.exp(-z))
```

```python
def feed_forward(theta,X,):
    '''å¾—åˆ°æ¯å±‚çš„è¾“å…¥å’Œè¾“å‡º'''
    t1, t2 = deserialize(theta)
    # å‰é¢å·²ç»æ’å…¥è¿‡åç½®å•å…ƒï¼Œè¿™é‡Œå°±ä¸ç”¨æ’å…¥äº†
    a1 = X
    z2 = a1 @ t1.T
    a2 = np.insert(sigmoid(z2),0,1,axis = 1)
    z3 = a2 @ t2.T
    a3 = sigmoid(z3)
    
    return a1,z2,a2,z3,a3
```

```python
a1, z2, a2, z3, h = feed_forward(theta, X)
```

![](https://gitee.com/veal98/images/raw/master/img/20200622151351.png)

##### â…¡ ä»£ä»·å‡½æ•°

å›é¡¾ä¸‹ç¥ç»ç½‘ç»œçš„ä»£ä»·å‡½æ•°ï¼ˆä¸å¸¦æ­£åˆ™åŒ–é¡¹ï¼‰

![](https://gitee.com/veal98/images/raw/master/img/20200622151435.png)

è¾“å‡ºå±‚è¾“å‡ºçš„æ˜¯å¯¹æ ·æœ¬çš„é¢„æµ‹ï¼ŒåŒ…å«5000ä¸ªæ•°æ®ï¼Œæ¯ä¸ªæ•°æ®å¯¹åº”äº†ä¸€ä¸ªåŒ…å«10ä¸ªå…ƒç´ çš„å‘é‡ï¼Œä»£è¡¨äº†ç»“æœæœ‰10ç±»ã€‚åœ¨å…¬å¼ä¸­ï¼Œæ¯ä¸ªå…ƒç´ ä¸logé¡¹å¯¹åº”ç›¸ä¹˜ã€‚

æœ€åæˆ‘ä»¬ä½¿ç”¨æä¾›è®­ç»ƒå¥½çš„å‚æ•°Î¸ï¼Œç®—å‡ºçš„coståº”è¯¥ä¸º0.287629

```python
def cost(theta, X, y):
    a1, z2, a2, z3, h = feed_forward(theta, X)
    J = 0
    for i in range(len(X)):
        first = -y[i] * np.log(h[i])
        second = (1 - y[i]) * np.log(1 - h[i])
        J = J + np.sum(first - second)
    J = J / len(X)
    return J
```

![](https://gitee.com/veal98/images/raw/master/img/20200622151942.png)

#### â‘£ æ­£åˆ™åŒ–ä»£ä»·å‡½æ•°

![](https://gitee.com/veal98/images/raw/master/img/20200622152204.png)



**æ³¨æ„ä¸è¦å°†æ¯å±‚çš„åç½®é¡¹æ­£åˆ™åŒ–ã€‚**

```python
def regularized_cost(theta, X, y, l = 1):
    '''æ­£åˆ™åŒ–æ—¶å¿½ç•¥æ¯å±‚çš„åç½®é¡¹ï¼Œä¹Ÿå°±æ˜¯å‚æ•°çŸ©é˜µçš„ç¬¬ä¸€åˆ—'''
    t1,t2 = deserialize(theta)
    reg = np.sum(t1[:,1:] ** 2) + np.sum(t2[:,1:] ** 2)
    return 1 / (2 * len(X)) * reg + cost(theta, X, y)
```

![](https://gitee.com/veal98/images/raw/master/img/20200622152749.png)

### 2. åå‘ä¼ æ’­ç®—æ³•

#### â‘  sigmoid æ¢¯åº¦

ä½ éœ€è¦å®ç°sigmoidå‡½æ•°çš„æ¢¯åº¦ï¼ˆå¯¼æ•°ï¼‰ï¼Œå…¬å¼å¦‚ä¸‹ï¼š

![](https://gitee.com/veal98/images/raw/master/img/20200622153858.png)

```python
def sigmoid_gradient(z):
    return sigmoid(z) * (1 - sigmoid(z))
```

#### â‘¡ éšæœºåˆå§‹åŒ– Random initialization

å½“æˆ‘ä»¬è®­ç»ƒç¥ç»ç½‘ç»œæ—¶ï¼Œéšæœºåˆå§‹åŒ–å‚æ•°æ˜¯å¾ˆé‡è¦çš„ï¼Œå¯ä»¥æ‰“ç ´æ•°æ®çš„å¯¹ç§°æ€§ã€‚ä¸€ä¸ªæœ‰æ•ˆçš„ç­–ç•¥æ˜¯åœ¨å‡åŒ€åˆ†å¸ƒ**(âˆ’eï¼Œe)**ä¸­éšæœºé€‰æ‹©å€¼ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹© **e = 0.12** è¿™ä¸ªèŒƒå›´çš„å€¼æ¥ç¡®ä¿å‚æ•°è¶³å¤Ÿå°ï¼Œä½¿å¾—è®­ç»ƒæ›´æœ‰æ•ˆç‡ã€‚

```python
def random_init(size):
    '''ä»æœä»çš„å‡åŒ€åˆ†å¸ƒçš„èŒƒå›´ä¸­éšæœºè¿”å›sizeå¤§å°çš„å€¼'''
    return np.random.uniform(-0.12,0.12, size)
```

#### â‘¢ åå‘ä¼ æ’­ Backpropagation

![](https://gitee.com/veal98/images/raw/master/img/20200622155034.png)

![](https://gitee.com/veal98/images/raw/master/img/20200622154115.png)

ç›®æ ‡ï¼šè·å–æ•´ä¸ªç½‘ç»œä»£ä»·å‡½æ•°çš„æ¢¯åº¦ã€‚ä»¥ä¾¿åœ¨ä¼˜åŒ–ç®—æ³•ä¸­æ±‚è§£ã€‚

é¦–å…ˆæ˜ç¡®å„ä¸ªå‚æ•°çš„ç»´åº¦ï¼š

```python
print('a1', a1.shape,'t1', t1.shape)
print('z2', z2.shape)
print('a2', a2.shape, 't2', t2.shape)
print('z3', z3.shape)
print('a3', h.shape)
```

![](https://gitee.com/veal98/images/raw/master/img/20200622154316.png)

```python
def gradient(theta, X, y):
    t1,t2 = deserialize(theta)
    a1, z2, a2, z3, h = feed_forward(theta, X)
    d3 = h - y # å®é™…è¾“å‡ºå’Œé¢„è®¡è¾“å‡ºçš„è¯¯å·®
    d2 = d3 @ t2[:,1:] * sigmoid_gradient(z2)
    D2 = d3.T @ a2
    D1 = d2.T @ a1
    D = (1 / len(X)) * serialize(D1,D2)
    
    return D
```

#### â‘£ æ¢¯åº¦æ ¡éªŒ

![](https://gitee.com/veal98/images/raw/master/img/20200622155301.png)

<img src="https://gitee.com/veal98/images/raw/master/img/20200622155723.png" style="zoom:80%;" />

å¦‚æœä½ çš„åå‘ä¼ æ’­è®¡ç®—æ­£ç¡®ï¼Œé‚£ä½ å¾—å‡ºçš„è¿™ä¸ªæ•°å­—åº”è¯¥**å°äº10e-9**

```python
def gradient_checking(theta, X, y, e):
    def a_numeric_grad(plus, minus):
        """
        å¯¹æ¯ä¸ªå‚æ•°theta_iè®¡ç®—æ•°å€¼æ¢¯åº¦ï¼Œå³ç†è®ºæ¢¯åº¦ã€‚
        """
        return (regularized_cost(plus, X, y) - regularized_cost(minus, X, y)) / (e * 2)
   
    numeric_grad = [] 
    for i in range(len(theta)):
        plus = theta.copy()  # deep copy otherwise you will change the raw theta
        minus = theta.copy()
        plus[i] = plus[i] + e
        minus[i] = minus[i] - e
        grad_i = a_numeric_grad(plus, minus)
        numeric_grad.append(grad_i)
    
    numeric_grad = np.array(numeric_grad)
    analytic_grad = regularized_gradient(theta, X, y)
    diff = np.linalg.norm(numeric_grad - analytic_grad) / np.linalg.norm(numeric_grad + analytic_grad)
 
gradient_checking(theta, X, y, epsilon= 0.0001) # è¿™ä¸ªè¿è¡Œå¾ˆæ…¢ï¼Œè°¨æ…è¿è¡Œ
```

#### â‘¤ æ­£åˆ™åŒ–ç¥ç»ç½‘ç»œ

æ¢¯åº¦ä¸‹é™ä¸­åŠ å…¥æ­£åˆ™é¡¹ï¼š

<img src="https://gitee.com/veal98/images/raw/master/img/20200622160921.png" style="zoom:80%;" />

å…¶ä¸­ï¼š$â–³_{ij}^{(l)}$ è¡¨ç¤ºè¯¯å·®çŸ©é˜µ

```python
def regularized_gradient(theta,X, y, l = 1):
    """ä¸æƒ©ç½šåç½®å•å…ƒçš„å‚æ•°"""
    a1, z2, a2, z3, h = feed_forward(theta, X)
    D1,D2 = deserialize(gradient(theta,X,y)) # D1,D2 è¡¨ç¤ºéæ­£åˆ™åŒ–è®¡ç®—å‡ºæ¥çš„æ¢¯åº¦
    t1,t2 = deserialize(theta)
    t1[:,0] = 0
    t2[:,0] = 0
    reg_D1 = D1 + (l / len(X)) * t1
    reg_D2 = D2 + (l / len(X)) * t2
    
    return serialize(reg_D1,reg_D2)
```

#### â‘¥ ä½¿ç”¨å·¥å…·åº“è®¡ç®—å‚æ•°æœ€ä¼˜è§£

```python
import scipy.optimize as opt
from scipy.optimize import minimize

def nn_training(X, y):
    init_theta = random_init(10285)  # 25*401 + 10*26

    res = opt.minimize(fun=regularized_cost,
                       x0=init_theta,
                       args=(X, y, 1),
                       method='TNC',
                       jac=regularized_gradient,
                       options={'maxiter': 400})
    return res
```

```python
res = nn_training(X, y)
res
```

> è®­ç»ƒè¯¯å·®å·²ç»å¤Ÿä½äº†ï¼Œä¸æ˜ç™½ä¸ºå•¥è¿˜æ˜¯False ğŸ˜’

![](https://gitee.com/veal98/images/raw/master/img/20200622164638.png)

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—å‡†ç¡®åº¦ï¼Œçœ‹çœ‹æˆ‘ä»¬è®­ç»ƒå®Œæ¯•çš„ç¥ç»ç½‘ç»œæ•ˆæœæ€ä¹ˆæ ·ã€‚

```python
# é¢„æµ‹å€¼ä¸å®é™…å€¼æ¯”è¾ƒ
from sklearn.metrics import classification_report #è¿™ä¸ªåŒ…æ˜¯è¯„ä»·æŠ¥å‘Š

def accuracy(theta, X, y):
    a1, z2, a2, z3, h = feed_forward(res.x, X)
    y_pred = np.argmax(h, axis=1) + 1
    print(classification_report(y, y_pred))
```

![](https://gitee.com/veal98/images/raw/master/img/20200622161939.png)

#### â‘¦ å¯è§†åŒ–éšè—å±‚

ç†è§£ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•å­¦ä¹ çš„ä¸€ä¸ªå¾ˆå¥½çš„åŠæ³•æ˜¯ï¼Œå¯è§†åŒ–éšè—å±‚å•å…ƒæ‰€æ•è·çš„å†…å®¹ã€‚é€šä¿—çš„è¯´ï¼Œå¯¹äºä¸€ä¸ªéšè—å±‚å•å…ƒï¼Œå¯è§†åŒ–å®ƒæ‰€è®¡ç®—çš„å†…å®¹çš„æ–¹æ³•æ˜¯ï¼šæ‰¾åˆ°ä¸€ä¸ªè¾“å…¥xï¼Œxå¯ä»¥æ¿€æ´»è¿™ä¸ªå•å…ƒï¼ˆä¹Ÿå°±æ˜¯è¯´æœ‰ä¸€ä¸ªæ¿€æ´»å€¼ $a^{(l)}_i$ æ¥è¿‘ä¸1ï¼‰ã€‚å¯¹äºæˆ‘ä»¬æ‰€è®­ç»ƒçš„ç½‘ç»œï¼Œæ³¨æ„åˆ° Î¸1 ä¸­æ¯ä¸€è¡Œéƒ½æ˜¯ä¸€ä¸ª 401 ç»´çš„å‘é‡ï¼Œä»£è¡¨æ¯ä¸ªéšè—å±‚å•å…ƒçš„å‚æ•°ã€‚<u>å¦‚æœæˆ‘ä»¬å¿½ç•¥åç½®é¡¹ï¼Œæˆ‘ä»¬å°±èƒ½å¾—åˆ°400ç»´çš„å‘é‡ï¼Œè¿™ä¸ªå‘é‡ä»£è¡¨æ¯ä¸ªæ ·æœ¬è¾“å…¥åˆ°æ¯ä¸ªéšå±‚å•å…ƒçš„åƒç´ çš„æƒé‡ã€‚**å› æ­¤å¯è§†åŒ–çš„ä¸€ä¸ªæ–¹æ³•æ˜¯ï¼Œreshape è¿™ä¸ª400ç»´çš„å‘é‡ä¸ºï¼ˆ20ï¼Œ20ï¼‰çš„å›¾åƒç„¶åè¾“å‡º**ã€‚</u>

```python
def plot_hidden(theta):
    t1, t2 = deserialize(theta)
    t1 = t1[:, 1:] # å¿½ç•¥åç½®é¡¹
    fig,ax_array = plt.subplots(5, 5, sharex=True, sharey=True, figsize=(6,6))
    for r in range(5):
        for c in range(5):
            ax_array[r, c].matshow(t1[r * 5 + c].reshape(20, 20), cmap='gray_r')
            plt.xticks([])
            plt.yticks([])
    plt.show()
```

![](https://gitee.com/veal98/images/raw/master/img/20200622162306.png)

## ğŸš€ Ex5ï¼šåå·®å’Œæ–¹å·®

> ğŸ”Š åœ¨æœ¬ç»ƒä¹ ä¸­ï¼Œæ‚¨å°†å®ç°æ­£åˆ™åŒ–çš„çº¿æ€§å›å½’å’Œå¤šé¡¹å¼å›å½’ï¼Œå¹¶ä½¿ç”¨å®ƒæ¥ç ”ç©¶å…·æœ‰ä¸åŒåå·® -æ–¹å·®å±æ€§çš„æ¨¡å‹

### 1. æ­£åˆ™åŒ–çº¿æ€§å›å½’

åœ¨å‰åŠéƒ¨åˆ†çš„ç»ƒä¹ ä¸­ï¼Œä½ å°†å®ç°æ­£åˆ™åŒ–çº¿æ€§å›å½’ï¼Œä»¥é¢„æµ‹æ°´åº“ä¸­çš„æ°´ä½å˜åŒ–ï¼Œä»è€Œé¢„æµ‹å¤§åæµå‡ºçš„æ°´é‡ã€‚åœ¨ä¸‹åŠéƒ¨åˆ†ä¸­ï¼Œæ‚¨å°†é€šè¿‡ä¸€äº›è°ƒè¯•å­¦ä¹ ç®—æ³•çš„è¯Šæ–­ï¼Œå¹¶æ£€æŸ¥åå·® v.s. æ–¹å·®çš„å½±å“ã€‚

```python
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat
```

#### â‘  å¯è§†åŒ–æ•°æ®

æˆ‘ä»¬å°†ä»å¯è§†åŒ–æ•°æ®é›†å¼€å§‹ï¼Œå…¶ä¸­åŒ…å«æ°´ä½å˜åŒ–çš„å†å²è®°å½• Xï¼Œä»¥åŠä»å¤§åæµå‡ºçš„æ°´é‡ yã€‚

è¿™ä¸ªæ•°æ®é›†åˆ†ä¸ºäº†ä¸‰ä¸ªéƒ¨åˆ†ï¼š

- è®­ç»ƒé›†ï¼šè®­ç»ƒæ¨¡å‹
- äº¤å‰éªŒè¯é›†ï¼šé€‰æ‹©æ­£åˆ™åŒ–å‚æ•°
- æµ‹è¯•é›†ï¼šè¯„ä¼°æ€§èƒ½ï¼Œæ¨¡å‹è®­ç»ƒä¸­ä¸æ›¾ç”¨è¿‡çš„æ ·æœ¬

```python
path = 'ex5/ex5data1.mat'
data = loadmat(path)

# Training set
X, y = data['X'], data['y']
# Cross validation set
Xval, yval = data['Xval'], data['yval']
# Test set
Xtest, ytest = data['Xtest'], data['ytest']

# æ’å…¥åç½®é¡¹
X = np.insert(X,0,1,axis = 1)
Xval = np.insert(Xval ,0,1,axis=1)
Xtest = np.insert(Xtest,0,1,axis=1)
```

![](https://gitee.com/veal98/images/raw/master/img/20200623111426.png)

```python
def plotData():
    """ç§ä¸€ç§æ•°æ®é•¿å•¥æ ·"""
    plt.figure(figsize=(8,5))
    plt.scatter(X[:,1:], y, c='r', marker='x')
    plt.xlabel('Change in water level (x)')
    plt.ylabel('Water flowing out of the dam (y)')
    
plotData()
```

![](https://gitee.com/veal98/images/raw/master/img/20200623111803.png)

#### â‘¡ æ­£åˆ™åŒ–çº¿æ€§å›å½’çš„ä»£ä»·å‡½æ•°

<img src="https://gitee.com/veal98/images/raw/master/img/20200623111845.png" style="zoom:80%;" />

```python
def costReg(theta, X, y, l):
    '''do not regularizethe theta0
    theta is a 1-d array with shape (n+1,)
    X is a matrix with shape (m, n+1)
    y is a matrix with shape (m, 1)
    '''
    cost = np.sum((X @ theta - y.flatten()) ** 2)
    regterm = l * (theta[1:] @ theta[1:]) # ä¸éœ€è¦æ­£åˆ™åŒ– Î¸_0
    return (cost + regterm) / (2 * len(X))
```

Î¸ åˆå§‹å€¼ä¸º [1,1]ï¼ŒÎ» = 1

```python
theta = np.ones(X.shape[1]) # thetaåˆå§‹å€¼ä¸º[1,1]
print(costReg(theta, X, y, 1))  # 303.9931922202643
```

![](https://gitee.com/veal98/images/raw/master/img/20200623112438.png)

#### â‘¢ æ­£åˆ™åŒ–çº¿æ€§å›å½’çš„æ¢¯åº¦

<img src="https://gitee.com/veal98/images/raw/master/img/20200623112509.png" style="zoom:80%;" />

```python
def gradientReg(theta, X, y, l):
    """
    theta: 1-d array with shape (2,)
    X: 2-d array with shape (12, 2)
    y: 2-d array with shape (12, 1)
    l: lambda constant
    grad has same shape as theta (2,)
    """
    grad = (X @ theta - y.flatten()) @ X
    regterm = l * theta
    regterm[0] = 0  # #don't regulate bias term
    return (grad + regterm) / len(X)

# Using theta initialized at [1; 1] you should expect to see a 
# gradient of [-15.303016; 598.250744] (with lambda=1)
print(gradientReg(theta, X, y, 1)) # [-15.30301567 598.25074417]
```

![](https://gitee.com/veal98/images/raw/master/img/20200623113044.png)

#### â‘£ æ‹Ÿåˆçº¿æ€§å›å½’

```python
def trainLinearReg(X, y, l):
    theta = np.zeros(X.shape[1])
    res = opt.minimize(fun=costReg, 
                       x0=theta, 
                       args=(X, y ,l), 
                       method='TNC', 
                       jac=gradientReg)
    return res.x
```

```python
fit_theta = trainLinearReg(X, y, 0)
plotData()
plt.plot(X[:,1], X @ fit_theta) # xè½´æ˜¯ è¾“å…¥æ•°æ® Xï¼Œyè½´æ˜¯å‡è®¾å‡½æ•° h(Î¸) = Î¸^T * X = X * Î¸
```

![](https://gitee.com/veal98/images/raw/master/img/20200623115402.png)

**è¿™é‡Œæˆ‘ä»¬æŠŠ `Î»  = 0`ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨å®ç°çš„çº¿æ€§å›å½’åªæœ‰ä¸¤ä¸ªå‚æ•°ï¼Œè¿™ä¹ˆä½çš„ç»´åº¦ï¼Œæ­£åˆ™åŒ–å¹¶æ²¡æœ‰ç”¨**ã€‚

ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œæ‹Ÿåˆæœ€å¥½çš„è¿™æ¡ç›´çº¿å‘Šè¯‰æˆ‘ä»¬è¿™ä¸ªæ¨¡å‹å¹¶ä¸é€‚åˆè¿™ä¸ªæ•°æ®ã€‚

åœ¨ä¸‹ä¸€èŠ‚ä¸­ï¼Œæ‚¨å°†å®ç°ä¸€ä¸ªå‡½æ•°æ¥ç”Ÿæˆå­¦ä¹ æ›²çº¿ï¼Œå®ƒå¯ä»¥å¸®åŠ©æ‚¨è°ƒè¯•å­¦ä¹ ç®—æ³•ï¼Œå³ä½¿å¯è§†åŒ–æ•°æ®ä¸é‚£ä¹ˆå®¹æ˜“ã€‚

### 2. åå·®å’Œæ–¹å·®

åå·®è¾ƒå¤§çš„æ¨¡å‹ä¼šæ¬ æ‹Ÿåˆï¼Œè€Œæ–¹å·®è¾ƒå¤§çš„æ¨¡å‹ä¼šè¿‡æ‹Ÿåˆã€‚è¿™éƒ¨åˆ†ä¼šè®©ä½ ç”»å‡ºå­¦ä¹ æ›²çº¿æ¥åˆ¤æ–­æ–¹å·®å’Œåå·®çš„é—®é¢˜ã€‚

#### â‘  ç»˜åˆ¶å­¦ä¹ æ›²çº¿

![](https://gitee.com/veal98/images/raw/master/img/20200623115531.png)

è®­ç»ƒæ ·æœ¬ X ä» 1 å¼€å§‹é€æ¸å¢åŠ ï¼Œè®­ç»ƒå‡ºä¸åŒçš„å‚æ•°å‘é‡ Î¸ã€‚æ¥ç€é€šè¿‡äº¤å‰éªŒè¯æ ·æœ¬ Xval è®¡ç®—éªŒè¯è¯¯å·®ã€‚

- ä½¿ç”¨è®­ç»ƒé›†çš„å­é›†æ¥è®­ç»ƒæ¨¡å‹ï¼Œå¾—åˆ°ä¸åŒçš„ Î¸ã€‚

- é€šè¿‡ Î¸ è®¡ç®—è®­ç»ƒä»£ä»·å’Œäº¤å‰éªŒè¯ä»£ä»·ï¼Œåˆ‡è®°æ­¤æ—¶ä¸è¦ä½¿ç”¨æ­£åˆ™åŒ–ï¼Œ Î» = 0ã€‚

- è®¡ç®—äº¤å‰éªŒè¯ä»£ä»·æ—¶è®°å¾—æ•´ä¸ªäº¤å‰éªŒè¯é›†æ¥è®¡ç®—ï¼Œæ— éœ€åˆ†ä¸ºå­é›†ã€‚

ç”»å‡ºå­¦ä¹ æ›²çº¿ï¼Œå³äº¤å‰éªŒè¯è¯¯å·®å’Œè®­ç»ƒè¯¯å·®éšæ ·æœ¬æ•°é‡çš„å˜åŒ–çš„å˜åŒ–ï¼š

```python
def plot_learning_curve(X, y, Xval, yval, l):
    """ç”»å‡ºå­¦ä¹ æ›²çº¿ï¼Œå³äº¤å‰éªŒè¯è¯¯å·®å’Œè®­ç»ƒè¯¯å·®éšæ ·æœ¬æ•°é‡çš„å˜åŒ–çš„å˜åŒ–"""
    xx = range(1, len(X) + 1)  # at least has one example 
    training_cost, cv_cost = [], []
    for i in xx:
        res = trainLinearReg(X[:i], y[:i], l) # é€šè¿‡è®­ç»ƒé›†æ•°æ®è®¡ç®— Î¸
        training_cost_i = costReg(res, X[:i], y[:i], 0) # é€šè¿‡ Î¸ è®¡ç®—è®­ç»ƒé›†ä»£ä»·
        cv_cost_i = costReg(res, Xval, yval, 0) # é€šè¿‡ Î¸ è®¡ç®—éªŒè¯é›†ä»£ä»·
        training_cost.append(training_cost_i)
        cv_cost.append(cv_cost_i)
        
    plt.figure(figsize=(8,5))
    plt.plot(xx, training_cost, label='training cost')  
    plt.plot(xx, cv_cost, label='cv cost') 
    plt.legend()
    plt.xlabel('Number of training examples')
    plt.ylabel('Error')
    plt.title('Learning curve for linear regression')
    plt.grid(True) # æ˜¾ç¤ºå¯¹é½æ ¼å­
```

![](https://gitee.com/veal98/images/raw/master/img/20200623120540.png)

ä»å›¾ä¸­çœ‹å‡ºæ¥ï¼Œéšç€æ ·æœ¬æ•°é‡çš„å¢åŠ ï¼Œè®­ç»ƒè¯¯å·®å’Œäº¤å‰éªŒè¯è¯¯å·®éƒ½å¾ˆé«˜ï¼Œå±äºé«˜åå·®ï¼Œæ¬ æ‹Ÿåˆã€‚

### 3. å¤šé¡¹å¼å›å½’

æˆ‘ä»¬çš„çº¿æ€§æ¨¡å‹å¯¹äºæ•°æ®æ¥è¯´å¤ªç®€å•äº†ï¼Œå¯¼è‡´äº†æ¬ æ‹Ÿåˆ(é«˜åå·®)ã€‚åœ¨è¿™ä¸€éƒ¨åˆ†çš„ç»ƒä¹ ä¸­ï¼Œæ‚¨å°†é€šè¿‡æ·»åŠ æ›´å¤šçš„ç‰¹å¾æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

ä½¿ç”¨å¤šé¡¹å¼å›å½’ï¼Œå‡è®¾å‡½æ•°å½¢å¼å¦‚ä¸‹ï¼š

![](https://gitee.com/veal98/images/raw/master/img/20200623120841.png)

#### â‘  æ•°æ®é¢„å¤„ç†

- ä½¿ç”¨ä¹‹å‰çš„ä»£ä»·å‡½æ•°å’Œæ¢¯åº¦å‡½æ•°
- æ‰©å±•ç‰¹å¾åˆ° 8 é˜¶ç‰¹å¾ï¼ˆ**è¿™é‡Œæˆ‘ä»¬é€‰æ‹©å¢åŠ åˆ° 6 æ¬¡æ–¹**ï¼Œè‹¥é€‰ 8 æ¬¡æ–¹æ— æ³•è¾¾åˆ°ä½œä¸š pdf ä¸Šçš„æ•ˆæœå›¾ï¼Œè¿™æ˜¯å› ä¸º `scipy `å’Œ `octave `ç‰ˆæœ¬çš„ä¼˜åŒ–ç®—æ³•ä¸åŒã€‚ï¼‰
- ä½¿ç”¨ **å‡å€¼å½’ä¸€åŒ–** æ¥å¤„ç† xn
- Î» = 0

```python
def genPolyFeatures(X, power):
    """æ·»åŠ å¤šé¡¹å¼ç‰¹å¾
    æ¯æ¬¡åœ¨arrayçš„æœ€åä¸€åˆ—æ’å…¥ç¬¬äºŒåˆ—çš„i+2æ¬¡æ–¹ï¼ˆç¬¬ä¸€åˆ—ä¸ºåç½®ï¼‰
    ä»äºŒæ¬¡æ–¹å¼€å§‹å¼€å§‹æ’å…¥ï¼ˆå› ä¸ºæœ¬èº«å«æœ‰ä¸€åˆ—ä¸€æ¬¡æ–¹ï¼‰
    """
    Xpoly = X.copy()
    for i in range(2, power + 1):
        Xpoly = np.insert(Xpoly, Xpoly.shape[1], np.power(Xpoly[:,1], i), axis=1)
    return Xpoly

def get_means_std(X):
    """è·å–è®­ç»ƒé›†çš„å‡å€¼å’Œè¯¯å·®ï¼Œç”¨æ¥æ ‡å‡†åŒ–æ‰€æœ‰æ•°æ®ã€‚"""
    means = np.mean(X,axis=0)
    stds = np.std(X,axis=0,ddof=1)  # ddof=1 means æ ·æœ¬æ ‡å‡†å·®
    return means, stds

def featureNormalize(myX, means, stds):
    """æ ‡å‡†åŒ–"""
    X_norm = myX.copy()
    X_norm[:,1:] = X_norm[:,1:] - means[1:]
    X_norm[:,1:] = X_norm[:,1:] / stds[1:]
    return X_norm
```

> ğŸ’¡ å…³äºå½’ä¸€åŒ–ï¼Œæ‰€æœ‰æ•°æ®é›†åº”è¯¥éƒ½ç”¨è®­ç»ƒé›†çš„å‡å€¼å’Œæ ·æœ¬æ ‡å‡†å·®å¤„ç†ã€‚åˆ‡è®°ã€‚æ‰€ä»¥**è¦å°†è®­ç»ƒé›†çš„å‡å€¼å’Œæ ·æœ¬æ ‡å‡†å·®å­˜å‚¨èµ·æ¥ï¼Œå¯¹åé¢çš„æ•°æ®è¿›è¡Œå¤„ç†**ã€‚
>
> è€Œä¸”**æ³¨æ„è¿™é‡Œæ˜¯æ ·æœ¬æ ‡å‡†å·®è€Œä¸æ˜¯æ€»ä½“æ ‡å‡†å·®**ï¼Œä½¿ç”¨`np.std()`æ—¶ï¼Œå°†**`ddof=1`åˆ™æ˜¯æ ·æœ¬æ ‡å‡†å·®ï¼Œé»˜è®¤`=0`æ˜¯æ€»ä½“æ ‡å‡†å·®**ã€‚è€Œ`pandas`é»˜è®¤è®¡ç®—æ ·æœ¬æ ‡å‡†å·®ã€‚

è·å–æ·»åŠ å¤šé¡¹å¼ç‰¹å¾ä»¥åŠæ ‡å‡†åŒ–ä¹‹åçš„æ•°æ®ï¼š

```python
power = 6  # æ‰©å±•åˆ°xçš„6æ¬¡æ–¹

train_means, train_stds = get_means_std(genPolyFeatures(X,power))

# æ•°æ®é›†æ•°æ®æ ‡å‡†åŒ–
X_norm = featureNormalize(genPolyFeatures(X,power), train_means, train_stds)
# éªŒè¯é›†æ•°æ®æ ‡å‡†åŒ–
Xval_norm = featureNormalize(genPolyFeatures(Xval,power), train_means, train_stds)
# æµ‹è¯•é›†æ•°æ®æ ‡å‡†åŒ–
Xtest_norm = featureNormalize(genPolyFeatures(Xtest,power), train_means, train_stds)
```

```python
def plot_fit(means, stds, l):
    """ç”»å‡ºæ‹Ÿåˆæ›²çº¿"""
    theta = trainLinearReg(X_norm,y, l)
    x = np.linspace(-75,55,50)
    xmat = x.reshape(-1, 1)
    xmat = np.insert(xmat,0,1,axis=1) # æ·»åŠ åç½®é¡¹
    Xmat = genPolyFeatures(xmat, power) # æ·»åŠ å¤šé¡¹å¼ç‰¹å¾
    Xmat_norm = featureNormalize(Xmat, means, stds) # å‡å€¼å½’ä¸€åŒ–
    
    plotData()
    plt.plot(x, Xmat_norm@theta,'b--') # ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿
```

> ğŸ’¡ `np.linspace`å‡½æ•°ï¼š`np.linspace` ä¸»è¦ç”¨æ¥åˆ›å»ºç­‰å·®æ•°åˆ—ã€‚
>
> ```python
> np.linspace(2.0, 3.0, num=5)
> # array([ 2.  ,  2.25,  2.5 ,  2.75,  3.  ])
> ```

```python
plot_fit(train_means, train_stds, 0)
```

![](https://gitee.com/veal98/images/raw/master/img/20200623123415.png)

å­¦ä¹ æ›²çº¿ï¼š

```python
plot_learning_curve(X_norm, y, Xval_norm, yval, 0)
```

![](https://gitee.com/veal98/images/raw/master/img/20200623123524.png)

å¯ä»¥çœ‹åˆ° Î»  = 0 æ—¶ï¼Œè®­ç»ƒè¯¯å·®å¤ªå°äº†ï¼Œæ˜æ˜¾è¿‡æ‹Ÿåˆäº†ã€‚

#### â‘¡ è°ƒæ•´æ­£åˆ™åŒ–ç³»æ•° Î»

ğŸ‘‰ æˆ‘ä»¬ç»§ç»­è°ƒæ•´ `Î» =  1` æ—¶ï¼š

æ‹Ÿåˆå¤šé¡¹å¼çº¿æ€§å›å½’ï¼š

```python
plot_fit(train_means, train_stds, 1)
```

![](https://gitee.com/veal98/images/raw/master/img/20200623123932.png)

å­¦ä¹ æ›²çº¿ï¼š

```python
plot_learning_curve(X_norm, y, Xval_norm, yval, 1)
```

![](https://gitee.com/veal98/images/raw/master/img/20200623123942.png)

è®­ç»ƒä»£ä»·ä¸å†æ˜¯0äº†ï¼Œä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬**è¿‡æ‹Ÿåˆ**ç¨‹åº¦å‡è½»äº†

ğŸ‘‰ å¦‚æœ `Î» = 100` ï¼š

```python
plot_fit(train_means, train_stds, 1)
```

![](https://gitee.com/veal98/images/raw/master/img/20200623124135.png)

```python
plot_learning_curve(X_norm, y, Xval_norm, yval, 1)
```

![](https://gitee.com/veal98/images/raw/master/img/20200623124143.png)

å¤ªå¤šæ­£åˆ™åŒ–ï¼Œå¯¼è‡´è®­ç»ƒé›†å’ŒéªŒè¯é›†è¯¯å·®éƒ½å¾ˆé«˜ï¼Œå³æ¬ æ‹Ÿåˆ

#### â‘¢ é€šè¿‡äº¤å‰éªŒè¯é›†é€‰æ‹©æœ€ä½³çš„ Î»

é€šè¿‡ä¹‹å‰çš„å®éªŒï¼Œæˆ‘ä»¬å¯ä»¥å‘ç° Î» å¯ä»¥æå¤§ç¨‹åº¦åœ°å½±å“æ­£åˆ™åŒ–å¤šé¡¹å¼å›å½’ã€‚ æ‰€ä»¥è¿™éƒ¨åˆ†æˆ‘ä»¬ä¼šä¼šä½¿ç”¨éªŒè¯é›†å»è¯„ä»· Î» çš„è¡¨ç°å¥½åï¼Œç„¶åé€‰æ‹©è¡¨ç°æœ€å¥½çš„ Î» åï¼Œç”¨æµ‹è¯•é›†æµ‹è¯•æ¨¡å‹åœ¨æ²¡æœ‰å‡ºç°è¿‡çš„æ•°æ®ä¸Šä¼šè¡¨ç°å¤šå¥½ã€‚ å°è¯• Î» å€¼[0, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]

```python
lambdas = [0., 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1., 3., 10.]
errors_train, errors_val = [], []
for l in lambdas:
    theta = trainLinearReg(X_norm, y, l)
    errors_train.append(costReg(theta,X_norm,y,0))  # è®­ç»ƒé›†è¯¯å·® è®°å¾—æŠŠlambda = 0
    errors_val.append(costReg(theta,Xval_norm,yval,0)) # éªŒè¯é›†è¯¯å·®
    
plt.figure(figsize=(8,5))
plt.plot(lambdas,errors_train,label='Train')
plt.plot(lambdas,errors_val,label='Cross Validation')
plt.legend()
plt.xlabel('lambda')
plt.ylabel('Error')
plt.grid(True)
```

![](https://gitee.com/veal98/images/raw/master/img/20200623124918.png)

é€‰æ‹©ä½¿å¾—äº¤å‰éªŒè¯é›†è¯¯å·®/ä»£ä»· æœ€å°çš„ Î»

```python
# å¯ä»¥çœ‹åˆ°äº¤å‰éªŒè¯ä»£ä»·æœ€å°çš„æ˜¯ lambda = 3
lambdas[np.argmin(errors_val)]  # 3.0
```

![](https://gitee.com/veal98/images/raw/master/img/20200623125010.png)

#### â‘£ è®¡ç®—æµ‹è¯•é›†ä¸Šçš„è¯¯å·®

å®é™…ä¸Šï¼Œä¸ºäº†è·å¾—ä¸€ä¸ªæ›´å¥½çš„æ¨¡å‹ï¼Œæˆ‘ä»¬éœ€è¦æŠŠæœ€ç»ˆçš„æ¨¡å‹ç”¨åœ¨ä¸€ä¸ªä»æ¥æ²¡æœ‰åœ¨è®¡ç®—ä¸­å‡ºç°è¿‡çš„æµ‹è¯•é›†ä¸Šï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œéœ€è¦æ—¢æ²¡æœ‰è¢«ç”¨ä½œé€‰æ‹© Î¸ï¼Œä¹Ÿæ²¡æœ‰è¢«ç”¨ä½œé€‰æ‹© Î» çš„æ•°æ®

```python
theta = trainLinearReg(X_norm, y, 3) # é€šè¿‡è®­ç»ƒé›†è®­ç»ƒå‡º Î¸
print('test cost(l={}) = {}'.format(3, costReg(theta, Xtest_norm, ytest, 0))) # é€šè¿‡ Î¸ è®¡ç®—æµ‹è¯•é›†è¯¯å·®/ä»£ä»·
```

![](https://gitee.com/veal98/images/raw/master/img/20200623125550.png)

> ğŸ”ˆ å› ä¸ºæˆ‘ä»¬åœ¨ä¸Šé¢è°ƒæ•´äº†`power = 6`æ¥åŒ¹é…ä½œä¸šé‡Œé¢çš„å›¾ï¼Œæ‰€ä»¥å¾—ä¸åˆ° 3.8599ã€‚ä½†æ˜¯è°ƒæ•´ `power=8` æ—¶ï¼ˆåŒä½œä¸šé‡Œä¸€æ ·ï¼‰, å°±å¯ä»¥å¾—åˆ°ä¸Šè¿°æ•°æ® 3.8599ã€‚

## ğŸš€ Ex6ï¼šæ”¯æŒå‘é‡æœº SVM

### 1. æ”¯æŒå‘é‡æœº

```python
%matplotlib inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
from scipy.io import loadmat
from sklearn import svm
```

#### â‘  æ•°æ®é›† 1

```python
mat = loadmat('ex6/ex6data1.mat')
print(mat.keys())
# dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])
X = mat['X']
y = mat['y']
```

å¤§å¤šæ•°SVMçš„åº“ä¼šè‡ªåŠ¨å¸®ä½ æ·»åŠ é¢å¤–çš„ç‰¹å¾ x0 ä»¥åŠ Î¸0 ï¼Œæ‰€ä»¥æ— éœ€æ‰‹åŠ¨æ·»åŠ ã€‚

```python
def plotData(X, y):
    plt.figure(figsize=(8,5))
    plt.scatter(X[:,0], X[:,1], c=y.flatten(), cmap='rainbow')
    plt.xlabel('X1')
    plt.ylabel('X2')
plotData(X, y)
```

![](https://gitee.com/veal98/images/raw/master/img/20200626105512.png)

è®­ç»ƒçº¿æ€§æ”¯æŒå‘é‡æœºæ‰¾å‡ºè¾¹ç•Œï¼š

```python
def plotBoundary(clf, X):
    '''plot decision bondary'''
    x_min, x_max = X[:,0].min()*1.2, X[:,0].max()*1.1
    y_min, y_max = X[:,1].min()*1.1,X[:,1].max()*1.1
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500),
                         np.linspace(y_min, y_max, 500))
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)
    plt.contour(xx, yy, Z)

```

```python
models = [svm.SVC(C, kernel='linear') for C in [1, 100]]
clfs = [model.fit(X, y.ravel()) for model in models]
```

```python
title = ['SVM Decision Boundary with C = {} (Example Dataset 1'.format(C) for C in [1, 100]]
for model,title in zip(clfs,title):
    plt.figure(figsize=(8,5))
    plotData(X, y)
    plotBoundary(model, X)
    plt.title(title)
```

![](https://gitee.com/veal98/images/raw/master/img/20200626110513.png)

å¯ä»¥ä»ä¸Šå›¾çœ‹åˆ°ï¼Œå½“Cæ¯”è¾ƒå°æ—¶æ¨¡å‹å¯¹è¯¯åˆ†ç±»çš„æƒ©ç½šå¢å¤§ï¼Œæ¯”è¾ƒä¸¥æ ¼ï¼Œè¯¯åˆ†ç±»å°‘ï¼Œé—´éš”æ¯”è¾ƒç‹­çª„ã€‚

å½“ C æ¯”è¾ƒå¤§æ—¶æ¨¡å‹å¯¹è¯¯åˆ†ç±»çš„æƒ©ç½šå¢å¤§ï¼Œæ¯”è¾ƒå®½æ¾ï¼Œå…è®¸ä¸€å®šçš„è¯¯åˆ†ç±»å­˜åœ¨ï¼Œé—´éš”è¾ƒå¤§ã€‚

#### â‘¡ é«˜æ–¯å†…æ ¸çš„ SVM

è¿™éƒ¨åˆ†ï¼Œä½¿ç”¨SVMåšéçº¿æ€§åˆ†ç±»ã€‚æˆ‘ä»¬å°†ä½¿ç”¨é«˜æ–¯æ ¸å‡½æ•°ã€‚

![](https://gitee.com/veal98/images/raw/master/img/20200626110929.png)

è¿™é‡Œæˆ‘ä»¬ç”¨ sklearn è‡ªå¸¦çš„ svm ä¸­çš„æ ¸å‡½æ•°å³å¯ã€‚

##### â…  é«˜æ–¯å†…æ ¸

```python
def gaussKernel(x1, x2, sigma):
    return np.exp(- ((x1 - x2) ** 2).sum() / (2 * sigma ** 2))

gaussKernel(np.array([1, 2, 1]),np.array([0, 4, -1]), 2.)  # 0.32465246735834974
```

##### â…¡ æ•°æ®é›† 2

```python
mat = loadmat('ex6/ex6data2.mat')
X2 = mat['X']
y2 = mat['y']

plotData(X2, y2)
```

![](https://gitee.com/veal98/images/raw/master/img/20200626111240.png)

ä½¿ç”¨é«˜æ–¯å†…æ ¸çš„ SVM æ‰¾å‡ºéçº¿æ€§è¾¹ç•Œï¼š

```python
sigma = 0.1
gamma = np.power(sigma,-2.)/2
clf = svm.SVC(C=1, kernel='rbf', gamma=gamma)
modle = clf.fit(X2, y2.flatten())
plotData(X2, y2)
plotBoundary(modle, X2)
```

![](https://gitee.com/veal98/images/raw/master/img/20200626111555.png)

##### â…¢ æ•°æ®é›† 3

å¯¹äºç¬¬ä¸‰ä¸ªæ•°æ®é›†ï¼Œæˆ‘ä»¬ç»™å‡ºäº†è®­ç»ƒå’ŒéªŒè¯é›†ï¼Œå¹¶ä¸”åŸºäºéªŒè¯é›†æ€§èƒ½ä¸ºSVMæ¨¡å‹æ‰¾åˆ°æœ€ä¼˜è¶…å‚æ•°ã€‚ æˆ‘ä»¬ç°åœ¨éœ€è¦å¯»æ‰¾æœ€ä¼˜Cå’ŒÏƒï¼Œå€™é€‰æ•°å€¼ä¸º[0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100]

```python
mat3 = loadmat('ex6/ex6data3.mat')
X3, y3 = mat3['X'], mat3['y']
Xval, yval = mat3['Xval'], mat3['yval']

plotData(X3, y3)
```

![](https://gitee.com/veal98/images/raw/master/img/20200626111729.png)

```python
Cvalues = (0.01, 0.03, 0.1, 0.3, 1., 3., 10., 30.)
sigmavalues = Cvalues
best_pair, best_score = (0, 0), 0

for C in Cvalues:
    for sigma in sigmavalues:
        gamma = np.power(sigma,-2.)/2
        model = svm.SVC(C=C,kernel='rbf',gamma=gamma)
        model.fit(X3, y3.flatten())
        this_score = model.score(Xval, yval)
        if this_score > best_score:
            best_score = this_score
            best_pair = (C, sigma)
print('best_pair={}, best_score={}'.format(best_pair, best_score))
# best_pair=(1.0, 0.1), best_score=0.965
```

ğŸ‘‰ å¯ä»¥çœ‹å‡º C å’Œ Ïƒ çš„æœ€ä½³å€¼åˆ†åˆ«ä¸º 1.0 å’Œ 0.1

ç”»å‡ºåˆ†ç•Œçº¿ï¼š

```python
model = svm.SVC(C=1., kernel='rbf', gamma = np.power(.1, -2.)/2)
model.fit(X3, y3.flatten())

plotData(X3, y3)
plotBoundary(model, X3)
```

![](https://gitee.com/veal98/images/raw/master/img/20200626112113.png)

### 2. åƒåœ¾é‚®ä»¶åˆ†ç±»

åœ¨è¿™ä¸€éƒ¨åˆ†ä¸­ï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç”¨SVMå»ºç«‹ä¸€ä¸ªåƒåœ¾é‚®ä»¶åˆ†ç±»å™¨ã€‚ä½ éœ€è¦å°†æ¯ä¸ªemail å˜æˆä¸€ä¸ªnç»´çš„ç‰¹å¾å‘é‡ï¼Œè¿™ä¸ªåˆ†ç±»å™¨å°†åˆ¤æ–­ç»™å®šä¸€ä¸ªé‚®ä»¶ x æ˜¯åƒåœ¾é‚®ä»¶(y=1)æˆ–ä¸æ˜¯åƒåœ¾é‚®ä»¶(y=0)ã€‚

#### â‘  å¤„ç†é‚®ä»¶

##### â…  é¢„å¤„ç†

é¦–å…ˆæˆ‘ä»¬ä»æ•°æ®é›†ä¸­é€‰å–ä¸€ä¸ªé‚®ä»¶æ¥çœ‹çœ‹å…·ä½“åŒ…å«ä»€ä¹ˆå†…å®¹ï¼š

```python
with open('ex6/emailSample1.txt', 'r') as f:
    email = f.read()
    print(email)
```

![](https://gitee.com/veal98/images/raw/master/img/20200626112620.png)

å¯ä»¥çœ‹åˆ°ï¼Œé‚®ä»¶å†…å®¹åŒ…å« a URL, an email address(at the end), numbers, and dollar amounts. å¾ˆå¤šé‚®ä»¶éƒ½ä¼šåŒ…å«è¿™äº›å…ƒç´ ï¼Œä½†æ˜¯æ¯å°é‚®ä»¶çš„å…·ä½“å†…å®¹å¯èƒ½ä¼šä¸ä¸€æ ·ã€‚å› æ­¤ï¼Œ**å¤„ç†é‚®ä»¶ç»å¸¸é‡‡ç”¨çš„æ–¹æ³•æ˜¯æ ‡å‡†åŒ–è¿™äº›æ•°æ®ï¼ŒæŠŠæ‰€æœ‰URLå½“ä½œä¸€æ ·ï¼Œæ‰€æœ‰æ•°å­—çœ‹ä½œä¸€æ ·ã€‚**

ä¾‹å¦‚ï¼Œæˆ‘ä»¬**ç”¨å”¯ä¸€çš„ä¸€ä¸ªå­—ç¬¦ä¸²`httpaddr`æ¥æ›¿æ¢æ‰€æœ‰çš„URLï¼Œæ¥è¡¨ç¤ºé‚®ä»¶åŒ…å«URL**ï¼Œè€Œä¸è¦æ±‚å…·ä½“çš„URLå†…å®¹ã€‚è¿™é€šå¸¸ä¼šæé«˜åƒåœ¾é‚®ä»¶åˆ†ç±»å™¨çš„æ€§èƒ½ï¼Œå› ä¸ºåƒåœ¾é‚®ä»¶å‘é€è€…é€šå¸¸ä¼šéšæœºåŒ–URLï¼Œå› æ­¤åœ¨æ–°çš„åƒåœ¾é‚®ä»¶ä¸­å†æ¬¡çœ‹åˆ°ä»»ä½•ç‰¹å®šURLçš„å‡ ç‡éå¸¸å°ã€‚

æˆ‘ä»¬å¯ä»¥åšå¦‚ä¸‹å¤„ç†ï¼š

- Lower-casing: æŠŠæ•´å°é‚®ä»¶è½¬åŒ–ä¸ºå°å†™ã€‚

- Stripping HTML: ç§»é™¤æ‰€æœ‰HTMLæ ‡ç­¾ï¼Œåªä¿ç•™å†…å®¹ã€‚

- Normalizing URLs: å°†æ‰€æœ‰çš„URLæ›¿æ¢ä¸ºå­—ç¬¦ä¸² â€œhttpaddrâ€.

- Normalizing Email Addresses: æ‰€æœ‰çš„åœ°å€æ›¿æ¢ä¸º â€œemailaddrâ€

- Normalizing Dollars: æ‰€æœ‰dollarç¬¦å·($)æ›¿æ¢ä¸ºâ€œdollarâ€.

- Normalizing Numbers: æ‰€æœ‰æ•°å­—æ›¿æ¢ä¸ºâ€œnumberâ€

- Word Stemming(è¯å¹²æå–): å°†æ‰€æœ‰å•è¯è¿˜åŸä¸ºè¯æºã€‚ä¾‹å¦‚ï¼Œâ€œdiscountâ€, â€œdiscountsâ€, â€œdiscountedâ€ and â€œdiscountingâ€éƒ½æ›¿æ¢ä¸ºâ€œdiscountâ€ã€‚

- Removal of non-words: ç§»é™¤æ‰€æœ‰éæ–‡å­—ç±»å‹ï¼Œæ‰€æœ‰çš„ç©ºæ ¼(tabs, newlines, spaces)è°ƒæ•´ä¸ºä¸€ä¸ªç©ºæ ¼.

```python
%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from scipy.io import loadmat
from sklearn import svm
import re #regular expression for e-mail processing

# è‹±æ–‡åˆ†è¯ç®—æ³•
import nltk, nltk.stem.porter
```

åˆ©ç”¨æ­£åˆ™è¡¨è¾¾å¼å®Œæˆ é™¤äº† è¯å¹²æå– å’Œ ç§»é™¤æ‰€æœ‰éæ–‡å­—ç±»å‹ çš„æ‰€æœ‰é‚®ä»¶å¤„ç†ï¼š

```python
def processEmail(email):
    """åšé™¤äº† è¯å¹²æå– å’Œ ç§»é™¤æ‰€æœ‰éæ–‡å­—ç±»å‹ çš„æ‰€æœ‰å¤„ç†"""
    email = email.lower()
    email = re.sub('<[^<>]>', ' ', email)  # åŒ¹é…<å¼€å¤´ï¼Œç„¶åæ‰€æœ‰ä¸æ˜¯< ,> çš„å†…å®¹ï¼ŒçŸ¥é“>ç»“å°¾ï¼Œç›¸å½“äºåŒ¹é…<...>
    email = re.sub('(http|https)://[^\s]*', 'httpaddr', email )  # åŒ¹é…//åé¢ä¸æ˜¯ç©ºç™½å­—ç¬¦çš„å†…å®¹ï¼Œé‡åˆ°ç©ºç™½å­—ç¬¦åˆ™åœæ­¢
    email = re.sub('[^\s]+@[^\s]+', 'emailaddr', email)
    email = re.sub('[\$]+', 'dollar', email)
    email = re.sub('[\d]+', 'number', email) 
    return email
```

æ¥ä¸‹æ¥å°±æ˜¯æå–è¯å¹²ï¼Œä»¥åŠå»é™¤éå­—ç¬¦å†…å®¹ï¼š

```python
def email2TokenList(email):
    """é¢„å¤„ç†æ•°æ®ï¼Œè¿”å›ä¸€ä¸ªå¹²å‡€çš„å•è¯åˆ—è¡¨"""
    
    # I'll use the NLTK stemmer because it more accurately duplicates the
    # performance of the OCTAVE implementation in the assignment
    stemmer = nltk.stem.porter.PorterStemmer()
    
    email = processEmail(email)

    # å°†é‚®ä»¶åˆ†å‰²ä¸ºå•ä¸ªå•è¯ï¼Œre.split() å¯ä»¥è®¾ç½®å¤šç§åˆ†éš”ç¬¦
    tokens = re.split('[ \@\$\/\#\.\-\:\&\*\+\=\[\]\?\!\(\)\{\}\,\'\"\>\_\<\;\%]', email)
    
    # éå†æ¯ä¸ªåˆ†å‰²å‡ºæ¥çš„å†…å®¹
    tokenlist = []
    for token in tokens:
        # åˆ é™¤ä»»ä½•éå­—æ¯æ•°å­—çš„å­—ç¬¦
        token = re.sub('[^a-zA-Z0-9]', '', token);
        # Use the Porter stemmer to æå–è¯æ ¹
        stemmed = stemmer.stem(token)
        # å»é™¤ç©ºå­—ç¬¦ä¸²â€˜â€™ï¼Œé‡Œé¢ä¸å«ä»»ä½•å­—ç¬¦
        if not len(token): continue
        tokenlist.append(stemmed)
            
    return tokenlist  
```

##### â…¡ è¯æ±‡è¡¨

åœ¨å¯¹é‚®ä»¶è¿›è¡Œé¢„å¤„ç†ä¹‹åï¼Œæˆ‘ä»¬æœ‰ä¸€ä¸ªå¤„ç†åçš„å•è¯åˆ—è¡¨ã€‚ä¸‹ä¸€æ­¥æ˜¯é€‰æ‹©æˆ‘ä»¬æƒ³åœ¨åˆ†ç±»å™¨ä¸­ä½¿ç”¨å“ªäº›è¯ï¼Œæˆ‘ä»¬éœ€è¦å»é™¤å“ªäº›è¯ã€‚

æˆ‘ä»¬æœ‰ä¸€ä¸ªè¯æ±‡è¡¨ `vocab.txt`ï¼Œé‡Œé¢å­˜å‚¨äº†åœ¨å®é™…ä¸­ç»å¸¸ä½¿ç”¨çš„å•è¯ï¼Œå…±1899ä¸ªã€‚

æˆ‘ä»¬è¦ç®—å‡ºå¤„ç†åçš„emailä¸­å«æœ‰å¤šå°‘vocab.txtä¸­çš„å•è¯ï¼Œå¹¶è¿”å›åœ¨vocab.txtä¸­çš„indexï¼Œè¿™å°±æˆ‘ä»¬æƒ³è¦çš„è®­ç»ƒå•è¯çš„ç´¢å¼•ã€‚

```python
def email2VocabIndices(email, vocab):
    """æå–å­˜åœ¨å•è¯çš„ç´¢å¼•"""
    token = email2TokenList(email)
    index = [i for i in range(len(vocab)) if vocab[i] in token ]
    return index
```

#### â‘¡ æå–ç‰¹å¾

```python
def email2FeatureVector(email):
    """
    å°†emailè½¬åŒ–ä¸ºè¯å‘é‡ï¼Œnæ˜¯vocabçš„é•¿åº¦ã€‚å­˜åœ¨å•è¯çš„ç›¸åº”ä½ç½®çš„å€¼ç½®ä¸º1ï¼Œå…¶ä½™ä¸º0
    """
    df = pd.read_table('ex6/vocab.txt',names=['words'])
    vocab = df.as_matrix()  # return array
    vector = np.zeros(len(vocab))  # init vector
    vocab_indices = email2VocabIndices(email, vocab)  # è¿”å›å«æœ‰å•è¯çš„ç´¢å¼•
    # å°†æœ‰å•è¯çš„ç´¢å¼•ç½®ä¸º1
    for i in vocab_indices:
        vector[i] = 1
    return vector

vector = email2FeatureVector(email)
print('length of vector = {}\nnum of non-zero = {}'.format(len(vector), int(vector.sum())))
```

![](https://gitee.com/veal98/images/raw/master/img/20200626113801.png)

æ¯ä¸ªæ–‡æ¡£å·²ç»è½¬æ¢ä¸ºä¸€ä¸ªå‘é‡ï¼Œå…¶ä¸­1,899ä¸ªç»´å¯¹åº”äºè¯æ±‡è¡¨ä¸­çš„1,899ä¸ªå•è¯ã€‚

#### â‘¢ è®­ç»ƒ SVM ç”¨äºé‚®ä»¶åˆ†ç±»

è¯»å–å·²ç»è®­æå–å¥½çš„ç‰¹å¾å‘é‡ä»¥åŠç›¸åº”çš„æ ‡ç­¾ã€‚åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚

```python
# Training set
mat1 = loadmat('ex6/spamTrain.mat')
X, y = mat1['X'], mat1['y']

# Test set
mat2 = loadmat('ex6/spamTest.mat')
Xtest, ytest = mat2['Xtest'], mat2['ytest']

clf = svm.SVC(C=0.1, kernel='linear')
clf.fit(X, y)
```

![](https://gitee.com/veal98/images/raw/master/img/20200626114207.png)

çœ‹çœ‹è®­ç»ƒçš„å‡†ç¡®åº¦ï¼š

```python
predTrain = clf.score(X, y)
predTest = clf.score(Xtest, ytest)
predTrain, predTest # (0.99825, 0.989)
```

![](https://gitee.com/veal98/images/raw/master/img/20200626114638.png)
# ğŸšš ç¬¬ 6 ç«  æ•°æ®åŠ è½½ã€å­˜å‚¨ä¸æ–‡ä»¶æ ¼å¼

---

è®¿é—®æ•°æ®æ˜¯ä½¿ç”¨æœ¬ä¹¦æ‰€ä»‹ç»çš„è¿™äº›å·¥å…·çš„ç¬¬ä¸€æ­¥ã€‚æˆ‘ä¼šç€é‡ä»‹ç»pandasçš„æ•°æ®è¾“å…¥ä¸è¾“å‡ºï¼Œè™½ç„¶åˆ«çš„åº“ä¸­ä¹Ÿæœ‰ä¸å°‘ä»¥æ­¤ä¸ºç›®çš„çš„å·¥å…·ã€‚

è¾“å…¥è¾“å‡ºé€šå¸¸å¯ä»¥åˆ’åˆ†ä¸ºå‡ ä¸ªå¤§ç±»ï¼šè¯»å–æ–‡æœ¬æ–‡ä»¶å’Œå…¶ä»–æ›´é«˜æ•ˆçš„ç£ç›˜å­˜å‚¨æ ¼å¼ï¼ŒåŠ è½½æ•°æ®åº“ä¸­çš„æ•°æ®ï¼Œåˆ©ç”¨Web APIæ“ä½œç½‘ç»œèµ„æºã€‚

## 6.1 è¯»å†™æ–‡æœ¬æ ¼å¼çš„æ•°æ®

### 1. åŸºæœ¬æ“ä½œ

pandasæä¾›äº†ä¸€äº›ç”¨äºå°†è¡¨æ ¼å‹æ•°æ®è¯»å–ä¸ºDataFrameå¯¹è±¡çš„å‡½æ•°ã€‚ä¸‹è¡¨å¯¹å®ƒä»¬è¿›è¡Œäº†æ€»ç»“ï¼Œå…¶ä¸­ `read_csv` å’Œ `read_table` å¯èƒ½ä¼šæ˜¯ä½ ä»Šåç”¨å¾—æœ€å¤šçš„ã€‚

![](https://gitee.com/veal98/images/raw/master/img/20200612214245.png)

æˆ‘å°†å¤§è‡´ä»‹ç»ä¸€ä¸‹è¿™äº›å‡½æ•°åœ¨å°†æ–‡æœ¬æ•°æ®è½¬æ¢ä¸º DataFrame æ—¶æ‰€ç”¨åˆ°çš„ä¸€äº›æŠ€æœ¯ã€‚è¿™äº›å‡½æ•°çš„é€‰é¡¹å¯ä»¥åˆ’åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªå¤§ç±»ï¼š

- ç´¢å¼•ï¼šå°†ä¸€ä¸ªæˆ–å¤šä¸ªåˆ—å½“åšè¿”å›çš„DataFrameå¤„ç†ï¼Œä»¥åŠæ˜¯å¦ä»æ–‡ä»¶ã€ç”¨æˆ·è·å–åˆ—åã€‚
- ç±»å‹æ¨æ–­å’Œæ•°æ®è½¬æ¢ï¼šåŒ…æ‹¬ç”¨æˆ·å®šä¹‰å€¼çš„è½¬æ¢ã€å’Œè‡ªå®šä¹‰çš„ç¼ºå¤±å€¼æ ‡è®°åˆ—è¡¨ç­‰ã€‚
- æ—¥æœŸè§£æï¼šåŒ…æ‹¬ç»„åˆåŠŸèƒ½ï¼Œæ¯”å¦‚å°†åˆ†æ•£åœ¨å¤šä¸ªåˆ—ä¸­çš„æ—¥æœŸæ—¶é—´ä¿¡æ¯ç»„åˆæˆç»“æœä¸­çš„å•ä¸ªåˆ—ã€‚
- è¿­ä»£ï¼šæ”¯æŒå¯¹å¤§æ–‡ä»¶è¿›è¡Œé€å—è¿­ä»£ã€‚
- ä¸è§„æ•´æ•°æ®é—®é¢˜ï¼šè·³è¿‡ä¸€äº›è¡Œã€é¡µè„šã€æ³¨é‡Šæˆ–å…¶ä»–ä¸€äº›ä¸é‡è¦çš„ä¸œè¥¿ï¼ˆæ¯”å¦‚ç”±æˆåƒä¸Šä¸‡ä¸ªé€—å·éš”å¼€çš„æ•°å€¼æ•°æ®ï¼‰ã€‚

å› ä¸ºå·¥ä½œä¸­å®é™…ç¢°åˆ°çš„æ•°æ®å¯èƒ½ååˆ†æ··ä¹±ï¼Œä¸€äº›æ•°æ®åŠ è½½å‡½æ•°ï¼ˆå°¤å…¶æ˜¯read_csvï¼‰çš„é€‰é¡¹é€æ¸å˜å¾—å¤æ‚èµ·æ¥ã€‚é¢å¯¹ä¸åŒçš„å‚æ•°ï¼Œæ„Ÿåˆ°å¤´ç—›å¾ˆæ­£å¸¸ï¼ˆread_csvæœ‰è¶…è¿‡50ä¸ªå‚æ•°ï¼‰ã€‚pandasæ–‡æ¡£æœ‰è¿™äº›å‚æ•°çš„ä¾‹å­ï¼Œå¦‚æœä½ æ„Ÿåˆ°é˜…è¯»æŸä¸ªæ–‡ä»¶å¾ˆéš¾ï¼Œå¯ä»¥é€šè¿‡ç›¸ä¼¼çš„è¶³å¤Ÿå¤šçš„ä¾‹å­æ‰¾åˆ°æ­£ç¡®çš„å‚æ•°ã€‚

å…¶ä¸­ä¸€äº›å‡½æ•°ï¼Œæ¯”å¦‚pandas.read_csvï¼Œæœ‰ç±»å‹æ¨æ–­åŠŸèƒ½ï¼Œå› ä¸ºåˆ—æ•°æ®çš„ç±»å‹ä¸å±äºæ•°æ®ç±»å‹ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ ä¸éœ€è¦æŒ‡å®šåˆ—çš„ç±»å‹åˆ°åº•æ˜¯æ•°å€¼ã€æ•´æ•°ã€å¸ƒå°”å€¼ï¼Œè¿˜æ˜¯å­—ç¬¦ä¸²ã€‚å…¶å®ƒçš„æ•°æ®æ ¼å¼ï¼Œå¦‚HDF5ã€Featherå’Œmsgpackï¼Œä¼šåœ¨æ ¼å¼ä¸­å­˜å‚¨æ•°æ®ç±»å‹ã€‚æ—¥æœŸå’Œå…¶ä»–è‡ªå®šä¹‰ç±»å‹çš„å¤„ç†éœ€è¦å¤šèŠ±ç‚¹å·¥å¤«æ‰è¡Œã€‚

é¦–å…ˆæˆ‘ä»¬æ¥çœ‹ä¸€ä¸ªä»¥é€—å·åˆ†éš”çš„ï¼ˆCSVï¼‰æ–‡æœ¬æ–‡ä»¶ï¼š

```python
In [8]: !type examples/ex1.csv # example.csv ä¸ jupyter notebook æ–‡ä»¶æ”¾åœ¨åŒä¸€ç›®å½•ä¸‹
a,b,c,d,message
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
```

>ğŸ’¡ è¿™é‡Œï¼Œæˆ‘ç”¨çš„æ˜¯Windowsçš„ `type` shellå‘½ä»¤å°†æ–‡ä»¶çš„åŸå§‹å†…å®¹æ‰“å°åˆ°å±å¹•ä¸Šã€‚å¦‚æœä½ ç”¨çš„æ˜¯Unixï¼Œä½ å¯ä»¥ä½¿ç”¨ `cat` è¾¾åˆ°åŒæ ·çš„æ•ˆæœã€‚

> ğŸ’¡ csv æ–‡ä»¶å…¶å®å°±æ˜¯ Excel æ–‡ä»¶ ğŸ‘‰ [åˆ›å»ºCSVæ–‡ä»¶çš„ä¸¤ç§æ–¹æ³•](https://jingyan.baidu.com/article/c843ea0b9a641477931e4a89.html)

ç”±äºè¯¥æ–‡ä»¶ä»¥é€—å·åˆ†éš”ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `read_csv` å°†å…¶è¯»å…¥ä¸€ä¸ªDataFrameï¼š

```python
In [9]: df = pd.read_csv('examples/ex1.csv')

In [10]: df
Out[10]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

æˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ `read_table`ï¼Œå¹¶æŒ‡å®šåˆ†éš”ç¬¦ï¼š
```python
In [11]: pd.read_table('examples/ex1.csv', sep=',')
Out[11]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

å¹¶ä¸æ˜¯æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰æ ‡é¢˜è¡Œã€‚çœ‹çœ‹ä¸‹é¢è¿™ä¸ªæ–‡ä»¶ï¼š
```python
In [12]: !type examples/ex2.csv
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
```

è¯»å…¥è¯¥æ–‡ä»¶çš„åŠæ³•æœ‰ä¸¤ä¸ªã€‚ä½ å¯ä»¥è®©pandasä¸ºå…¶åˆ†é…é»˜è®¤çš„åˆ—åï¼ˆ0ï¼Œ1ï¼Œ2ï¼Œ3......ï¼‰ï¼Œä¹Ÿå¯ä»¥é€šè¿‡å‚æ•° `names` è‡ªå·±å®šä¹‰åˆ—åï¼š
```python
In [13]: pd.read_csv('examples/ex2.csv', header=None)
Out[13]: 
   0   1   2   3      4
0  1   2   3   4  hello
1  5   6   7   8  world
2  9  10  11  12    foo

In [14]: pd.read_csv('examples/ex2.csv', names=['a', 'b', 'c', 'd', 'message'])
Out[14]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

å‡è®¾ä½ å¸Œæœ›å°†messageåˆ—åšæˆDataFrameçš„ç´¢å¼•ã€‚ä½ å¯ä»¥æ˜ç¡®è¡¨ç¤ºè¦å°†è¯¥åˆ—æ”¾åˆ°ç´¢å¼•4çš„ä½ç½®ä¸Šï¼Œä¹Ÿå¯ä»¥é€šè¿‡ `index_col` å‚æ•°æŒ‡å®š"message"ï¼š
```python
In [15]: names = ['a', 'b', 'c', 'd', 'message']

In [16]: pd.read_csv('examples/ex2.csv', names=names, index_col='message')
Out[16]: 
         a   b   c   d
message               
hello    1   2   3   4
world    5   6   7   8
foo      9  10  11  12
```

å¦‚æœå¸Œæœ›å°†å¤šä¸ªåˆ—åšæˆä¸€ä¸ªå±‚æ¬¡åŒ–ç´¢å¼•ï¼Œåªéœ€ä¼ å…¥ç”±åˆ—ç¼–å·æˆ–åˆ—åç»„æˆçš„åˆ—è¡¨å³å¯ï¼š
```python
In [17]: !type examples/csv_mindex.csv
key1,key2,value1,value2
one,a,1,2
one,b,3,4
one,c,5,6
one,d,7,8
two,a,9,10
two,b,11,12
two,c,13,14
two,d,15,16

In [18]: parsed = pd.read_csv('examples/csv_mindex.csv',
   ....:                      index_col=['key1', 'key2'])

In [19]: parsed
Out[19]: 
           value1  value2
key1 key2                
one  a          1       2
     b          3       4
     c          5       6
     d          7       8
two  a          9      10
     b         11      12
     c         13      14
     d         15      16
```

æœ‰äº›æƒ…å†µä¸‹ï¼Œæœ‰äº›è¡¨æ ¼å¯èƒ½ä¸æ˜¯ç”¨å›ºå®šçš„åˆ†éš”ç¬¦å»åˆ†éš”å­—æ®µçš„ï¼ˆæ¯”å¦‚ç©ºç™½ç¬¦æˆ–å…¶å®ƒæ¨¡å¼ï¼‰ã€‚çœ‹çœ‹ä¸‹é¢è¿™ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼š
```python
In [20]: list(open('examples/ex3.txt'))
Out[20]: 
['            A         B         C\n',
 'aaa -0.264438 -1.026059 -0.619500\n',
 'bbb  0.927272  0.302904 -0.032399\n',
 'ccc -0.264273 -0.386314 -0.217601\n',
 'ddd -0.871858 -0.348382  1.100491\n']
```

è™½ç„¶å¯ä»¥æ‰‹åŠ¨å¯¹æ•°æ®è¿›è¡Œè§„æ•´ï¼Œè¿™é‡Œçš„å­—æ®µæ˜¯è¢«æ•°é‡ä¸åŒçš„ç©ºç™½å­—ç¬¦é—´éš”å¼€çš„ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œ**ä½ å¯ä»¥ä¼ é€’ä¸€ä¸ªæ­£åˆ™è¡¨è¾¾å¼ä½œä¸ºread_tableçš„åˆ†éš”ç¬¦**ã€‚å¯ä»¥ç”¨æ­£åˆ™è¡¨è¾¾å¼è¡¨è¾¾ä¸º\s+ï¼Œäºæ˜¯æœ‰ï¼š
```python
In [21]: result = pd.read_table('examples/ex3.txt', sep='\s+')

In [22]: result
Out[22]: 
            A         B         C
aaa -0.264438 -1.026059 -0.619500
bbb  0.927272  0.302904 -0.032399
ccc -0.264273 -0.386314 -0.217601
ddd -0.871858 -0.348382  1.100491
```

è¿™é‡Œï¼Œç”±äºåˆ—åæ¯”æ•°æ®è¡Œçš„æ•°é‡å°‘ï¼Œæ‰€ä»¥read_tableæ¨æ–­ç¬¬ä¸€åˆ—åº”è¯¥æ˜¯DataFrameçš„ç´¢å¼•ã€‚

è¿™äº›è§£æå™¨å‡½æ•°è¿˜æœ‰è®¸å¤šå‚æ•°å¯ä»¥å¸®åŠ©ä½ å¤„ç†å„ç§å„æ ·çš„å¼‚å½¢æ–‡ä»¶æ ¼å¼ï¼ˆè¡¨6-2åˆ—å‡ºäº†ä¸€äº›ï¼‰ã€‚æ¯”å¦‚è¯´ï¼Œä½ å¯ä»¥ç”¨ `skiprows` è·³è¿‡æ–‡ä»¶çš„ç¬¬ä¸€è¡Œã€ç¬¬ä¸‰è¡Œå’Œç¬¬å››è¡Œï¼š
```python
In [23]: !type examples/ex4.csv
# hey!
a,b,c,d,message
# just wanted to make things more difficult for you
# who reads CSV files with computers, anyway?
1,2,3,4,hello
5,6,7,8,world
9,10,11,12,foo
In [24]: pd.read_csv('examples/ex4.csv', skiprows=[0, 2, 3])
Out[24]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

ç¼ºå¤±å€¼å¤„ç†æ˜¯æ–‡ä»¶è§£æä»»åŠ¡ä¸­çš„ä¸€ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ã€‚**ç¼ºå¤±æ•°æ®ç»å¸¸æ˜¯è¦ä¹ˆæ²¡æœ‰ï¼ˆç©ºå­—ç¬¦ä¸²ï¼‰ï¼Œè¦ä¹ˆç”¨æŸä¸ªæ ‡è®°å€¼è¡¨ç¤ºã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œpandasä¼šç”¨ä¸€ç»„ç»å¸¸å‡ºç°çš„æ ‡è®°å€¼è¿›è¡Œè¯†åˆ«ï¼Œæ¯”å¦‚NAåŠNULL**ï¼š
```python
In [25]: !type examples/ex5.csv
something,a,b,c,d,message
one,1,2,3,4,NA
two,5,6,,8,world
three,9,10,11,12,foo
In [26]: result = pd.read_csv('examples/ex5.csv')

In [27]: result
Out[27]: 
    something  a   b     c   d message
0         one  1   2   3.0   4     NaN
1         two  5   6   NaN   8   world
2       three  9  10  11.0  12     foo

In [28]: pd.isnull(result)
Out[28]: 
   something      a      b      c      d  message
0      False  False  False  False  False     True
1      False  False  False   True  False    False
2      False  False  False  False  False    False
```

`na_values` å¯ä»¥ç”¨ä¸€ä¸ªåˆ—è¡¨æˆ–é›†åˆçš„å­—ç¬¦ä¸²è¡¨ç¤ºç¼ºå¤±å€¼ï¼š

```python
In [29]: result = pd.read_csv('examples/ex5.csv', na_values=['NULL'])

In [30]: result
Out[30]: 
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo
```

å­—å…¸çš„å„åˆ—å¯ä»¥ä½¿ç”¨ä¸åŒçš„NAæ ‡è®°å€¼ï¼š
```python
In [31]: sentinels = {'message': ['foo', 'NA'], 'something': ['two']}

In [32]: pd.read_csv('examples/ex5.csv', na_values=sentinels)
Out[32]:
  something  a   b     c   d   message
0       one  1   2   3.0   4       NaN
1       NaN  5   6   NaN   8     world
2     three  9  10  11.0  12       NaN
```

è¡¨6-2åˆ—å‡ºäº†pandas.read_csvå’Œpandas.read_tableå¸¸ç”¨çš„é€‰é¡¹ï¼š

![](https://gitee.com/veal98/images/raw/master/img/20200612221122.png)

### 2. é€å—è¯»å–æ–‡æœ¬æ–‡ä»¶
åœ¨å¤„ç†å¾ˆå¤§çš„æ–‡ä»¶æ—¶ï¼Œæˆ–æ‰¾å‡ºå¤§æ–‡ä»¶ä¸­çš„å‚æ•°é›†ä»¥ä¾¿äºåç»­å¤„ç†æ—¶ï¼Œä½ å¯èƒ½åªæƒ³è¯»å–æ–‡ä»¶çš„ä¸€å°éƒ¨åˆ†æˆ–é€å—å¯¹æ–‡ä»¶è¿›è¡Œè¿­ä»£ã€‚

åœ¨çœ‹å¤§æ–‡ä»¶ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆè®¾ç½®pandasæ˜¾ç¤ºçš„æ›´ç´§äº›ï¼š
```python
In [33]: pd.options.display.max_rows = 10
```

ç„¶åæœ‰ï¼š
```python
In [34]: result = pd.read_csv('examples/ex6.csv')

In [35]: result
Out[35]: 
           one       two     three      four key
0     0.467976 -0.038649 -0.295344 -1.824726   L
1    -0.358893  1.404453  0.704965 -0.200638   B
2    -0.501840  0.659254 -0.421691 -0.057688   G
3     0.204886  1.074134  1.388361 -0.982404   R
4     0.354628 -0.133116  0.283763 -0.837063   Q
...        ...       ...       ...       ...  ..
9995  2.311896 -0.417070 -1.409599 -0.515821   L
9996 -0.479893 -0.650419  0.745152 -0.646038   E
9997  0.523331  0.787112  0.486066  1.093156   K
9998 -0.362559  0.598894 -1.843201  0.887292   G
9999 -0.096376 -1.012999 -0.657431 -0.573315   0
[10000 rows x 5 columns]
If you want to only read a small
```

**å¦‚æœåªæƒ³è¯»å–å‡ è¡Œï¼ˆé¿å…è¯»å–æ•´ä¸ªæ–‡ä»¶ï¼‰ï¼Œé€šè¿‡ `nrows` è¿›è¡ŒæŒ‡å®šå³å¯**ï¼š

```python
In [36]: pd.read_csv('examples/ex6.csv', nrows=5)
Out[36]: 
        one       two     three      four key
0  0.467976 -0.038649 -0.295344 -1.824726   L
1 -0.358893  1.404453  0.704965 -0.200638   B
2 -0.501840  0.659254 -0.421691 -0.057688   G
3  0.204886  1.074134  1.388361 -0.982404   R
4  0.354628 -0.133116  0.283763 -0.837063   Q
```

**è¦é€å—è¯»å–æ–‡ä»¶ï¼Œå¯ä»¥æŒ‡å®š `chunksizeï¼ˆè¡Œæ•°ï¼‰`**ï¼š

```python
InÂ [874]:Â chunkerÂ =Â pd.read_csv('ch06/ex6.csv',Â chunksize=1000)

InÂ [875]:Â chunker
Out[875]:Â <pandas.io.parsers.TextParserÂ atÂ 0x8398150>
```

read_csv æ‰€è¿”å›çš„è¿™ä¸ª `TextParser` å¯¹è±¡ä½¿ä½ å¯ä»¥æ ¹æ® chunksize å¯¹æ–‡ä»¶è¿›è¡Œé€å—è¿­ä»£ã€‚æ¯”å¦‚è¯´ï¼Œæˆ‘ä»¬å¯ä»¥è¿­ä»£å¤„ç† ex6.csvï¼Œå°†å€¼è®¡æ•°èšåˆåˆ°"key"åˆ—ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
```python
chunker = pd.read_csv('examples/ex6.csv', chunksize=1000)

tot = pd.Series([])
for piece in chunker:
    tot = tot.add(piece['key'].value_counts(), fill_value=0)

tot = tot.sort_values(ascending=False)
```

ç„¶åæœ‰ï¼š
```python
In [40]: tot[:10]
Out[40]: 
E    368.0
X    364.0
L    346.0
O    343.0
Q    340.0
M    338.0
J    337.0
F    335.0
K    334.0
H    330.0
dtype: float64
```

TextParserè¿˜æœ‰ä¸€ä¸ªget_chunkæ–¹æ³•ï¼Œå®ƒä½¿ä½ å¯ä»¥è¯»å–ä»»æ„å¤§å°çš„å—ã€‚

### 3. å°†æ•°æ®å†™å‡ºåˆ°æ–‡æœ¬æ ¼å¼
æ•°æ®ä¹Ÿå¯ä»¥è¢«è¾“å‡ºä¸ºåˆ†éš”ç¬¦æ ¼å¼çš„æ–‡æœ¬ã€‚æˆ‘ä»¬å†æ¥çœ‹çœ‹ä¹‹å‰è¯»è¿‡çš„ä¸€ä¸ªCSVæ–‡ä»¶ï¼š
```python
In [41]: data = pd.read_csv('examples/ex5.csv')

In [42]: data
Out[42]: 
  something  a   b     c   d message
0       one  1   2   3.0   4     NaN
1       two  5   6   NaN   8   world
2     three  9  10  11.0  12     foo
```

åˆ©ç”¨DataFrameçš„ `to_csv` æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ•°æ®å†™åˆ°ä¸€ä¸ªä»¥é€—å·åˆ†éš”çš„æ–‡ä»¶ä¸­ï¼š
```python
In [43]: data.to_csv('examples/out.csv')

In [44]: !type examples/out.csv
,something,a,b,c,d,message
0,one,1,2,3.0,4,
1,two,5,6,,8,world
2,three,9,10,11.0,12,foo
```

å½“ç„¶ï¼Œè¿˜å¯ä»¥ä½¿ç”¨å…¶ä»–åˆ†éš”ç¬¦ï¼ˆç”±äºè¿™é‡Œç›´æ¥å†™å‡ºåˆ°sys.stdoutï¼Œæ‰€ä»¥ä»…ä»…æ˜¯æ‰“å°å‡ºæ–‡æœ¬ç»“æœè€Œå·²ï¼‰ï¼š
```python
In [45]: import sys

In [46]: data.to_csv(sys.stdout, sep='|')
|something|a|b|c|d|message
0|one|1|2|3.0|4|
1|two|5|6||8|world
2|three|9|10|11.0|12|foo
```

ç¼ºå¤±å€¼åœ¨è¾“å‡ºç»“æœä¸­ä¼šè¢«è¡¨ç¤ºä¸ºç©ºå­—ç¬¦ä¸²ã€‚ä½ å¯èƒ½å¸Œæœ›å°†å…¶è¡¨ç¤ºä¸ºåˆ«çš„æ ‡è®°å€¼ï¼š
```python
In [47]: data.to_csv(sys.stdout, na_rep='NULL')
,something,a,b,c,d,message
0,one,1,2,3.0,4,NULL
1,two,5,6,NULL,8,world
2,three,9,10,11.0,12,foo
```

å¦‚æœæ²¡æœ‰è®¾ç½®å…¶ä»–é€‰é¡¹ï¼Œåˆ™ä¼šå†™å‡ºè¡Œå’Œåˆ—çš„æ ‡ç­¾ã€‚å½“ç„¶ï¼Œå®ƒä»¬ä¹Ÿéƒ½å¯ä»¥è¢«ç¦ç”¨ï¼š
```python
In [48]: data.to_csv(sys.stdout, index=False, header=False)
one,1,2,3.0,4,
two,5,6,,8,world
three,9,10,11.0,12,foo
```

æ­¤å¤–ï¼Œä½ è¿˜å¯ä»¥åªå†™å‡ºä¸€éƒ¨åˆ†çš„åˆ—ï¼Œå¹¶ä»¥ä½ æŒ‡å®šçš„é¡ºåºæ’åˆ—ï¼š
```python
In [49]: data.to_csv(sys.stdout, index=False, columns=['a', 'b', 'c'])
a,b,c
1,2,3.0
5,6,
9,10,11.0
```

Series ä¹Ÿæœ‰ä¸€ä¸ª to_csv æ–¹æ³•ï¼š
```python
In [50]: dates = pd.date_range('1/1/2000', periods=7)

In [51]: ts = pd.Series(np.arange(7), index=dates)

In [52]: ts.to_csv('examples/tseries.csv')

In [53]: !type examples/tseries.csv
2000-01-01,0
2000-01-02,1
2000-01-03,2
2000-01-04,3
2000-01-05,4
2000-01-06,5
2000-01-07,6
```

### 4. å¤„ç†åˆ†éš”ç¬¦æ ¼å¼
å¤§éƒ¨åˆ†å­˜å‚¨åœ¨ç£ç›˜ä¸Šçš„è¡¨æ ¼å‹æ•°æ®éƒ½èƒ½ç”¨pandas.read_tableè¿›è¡ŒåŠ è½½ã€‚ç„¶è€Œï¼Œæœ‰æ—¶è¿˜æ˜¯éœ€è¦åšä¸€äº›æ‰‹å·¥å¤„ç†ã€‚ç”±äºæ¥æ”¶åˆ°å«æœ‰ç•¸å½¢è¡Œçš„æ–‡ä»¶è€Œä½¿read_tableå‡ºæ¯›ç—…çš„æƒ…å†µå¹¶ä¸å°‘è§ã€‚ä¸ºäº†è¯´æ˜è¿™äº›åŸºæœ¬å·¥å…·ï¼Œçœ‹çœ‹ä¸‹é¢è¿™ä¸ªç®€å•çš„CSVæ–‡ä»¶ï¼š
```python
In [54]: !type examples/ex7.csv
"a","b","c"
"1","2","3"
"1","2","3"
```

å¯¹äºä»»ä½•å•å­—ç¬¦åˆ†éš”ç¬¦æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨Pythonå†…ç½®çš„ csv æ¨¡å—ã€‚å°†ä»»æ„å·²æ‰“å¼€çš„æ–‡ä»¶æˆ–æ–‡ä»¶å‹çš„å¯¹è±¡ä¼ ç»™ csv.readerï¼š
```python
import csv
f = open('examples/ex7.csv')

reader = csv.reader(f)
```

å¯¹è¿™ä¸ªreaderè¿›è¡Œè¿­ä»£å°†ä¼šä¸ºæ¯è¡Œäº§ç”Ÿä¸€ä¸ªå…ƒç»„ï¼ˆå¹¶ç§»é™¤äº†æ‰€æœ‰çš„å¼•å·ï¼‰ï¼šå¯¹è¿™ä¸ªreaderè¿›è¡Œè¿­ä»£å°†ä¼šä¸ºæ¯è¡Œäº§ç”Ÿä¸€ä¸ªå…ƒç»„ï¼ˆå¹¶ç§»é™¤äº†æ‰€æœ‰çš„å¼•å·ï¼‰ï¼š
```python
In [56]: for line in reader:
   ....:     print(line)
['a', 'b', 'c']
['1', '2', '3']
['1', '2', '3']
```

ç°åœ¨ï¼Œä¸ºäº†ä½¿æ•°æ®æ ¼å¼åˆä¹è¦æ±‚ï¼Œä½ éœ€è¦å¯¹å…¶åšä¸€äº›æ•´ç†å·¥ä½œã€‚æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥æ¥åšã€‚é¦–å…ˆï¼Œè¯»å–æ–‡ä»¶åˆ°ä¸€ä¸ªå¤šè¡Œçš„åˆ—è¡¨ä¸­ï¼š
```python
In [57]: with open('examples/ex7.csv') as f:
   ....:     lines = list(csv.reader(f))
```

ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›è¡Œåˆ†ä¸ºæ ‡é¢˜è¡Œå’Œæ•°æ®è¡Œï¼š
```python
In [58]: header, values = lines[0], lines[1:]
```

ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ç”¨å­—å…¸æ„é€ å¼å’Œ `zip(*values)`ï¼Œåè€…**å°†è¡Œè½¬ç½®ä¸ºåˆ—**ï¼Œåˆ›å»ºæ•°æ®åˆ—çš„å­—å…¸ï¼š
```python
In [59]: data_dict = {h: v for h, v in zip(header, zip(*values))}

In [60]: data_dict
Out[60]: {'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}
```

**CSVæ–‡ä»¶çš„å½¢å¼æœ‰å¾ˆå¤šã€‚åªéœ€å®šä¹‰csv.Dialectçš„ä¸€ä¸ªå­ç±»å³å¯å®šä¹‰å‡ºæ–°æ ¼å¼ï¼ˆå¦‚ä¸“é—¨çš„åˆ†éš”ç¬¦ã€å­—ç¬¦ä¸²å¼•ç”¨çº¦å®šã€è¡Œç»“æŸç¬¦ç­‰ï¼‰**ï¼š

```python
class my_dialect(csv.Dialect):
    lineterminator = '\n'
    delimiter = ';'
    quotechar = '"'
    quoting = csv.QUOTE_MINIMAL
reader = csv.reader(f, dialect=my_dialect)
```

å„ä¸ªCSVè¯­æ”¯çš„å‚æ•°ä¹Ÿå¯ä»¥ç”¨å…³é”®å­—çš„å½¢å¼æä¾›ç»™csv.readerï¼Œè€Œæ— éœ€å®šä¹‰å­ç±»ï¼š
```python
reader = csv.reader(f, delimiter='|')
```

å¯ç”¨çš„é€‰é¡¹ï¼ˆcsv.Dialectçš„å±æ€§ï¼‰åŠå…¶åŠŸèƒ½å¦‚è¡¨6-3æ‰€ç¤ºã€‚

![](https://gitee.com/veal98/images/raw/master/img/20200612223509.png)

>ğŸš© **å¯¹äºé‚£äº›ä½¿ç”¨å¤æ‚åˆ†éš”ç¬¦æˆ–å¤šå­—ç¬¦åˆ†éš”ç¬¦çš„æ–‡ä»¶ï¼Œcsvæ¨¡å—å°±æ— èƒ½ä¸ºåŠ›äº†ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œä½ å°±åªèƒ½ä½¿ç”¨å­—ç¬¦ä¸²çš„splitæ–¹æ³•æˆ–æ­£åˆ™è¡¨è¾¾å¼æ–¹æ³•re.splitè¿›è¡Œè¡Œæ‹†åˆ†å’Œå…¶ä»–æ•´ç†å·¥ä½œäº†**ã€‚

è¦æ‰‹å·¥è¾“å‡ºåˆ†éš”ç¬¦æ–‡ä»¶ï¼Œä½ å¯ä»¥ä½¿ç”¨ csv.writerã€‚å®ƒæ¥å—ä¸€ä¸ªå·²æ‰“å¼€ä¸”å¯å†™çš„æ–‡ä»¶å¯¹è±¡ä»¥åŠè·Ÿcsv.readerç›¸åŒçš„é‚£äº›è¯­æ”¯å’Œæ ¼å¼åŒ–é€‰é¡¹ï¼š
```python
with open('mydata.csv', 'w') as f:
    writer = csv.writer(f, dialect=my_dialect)
    writer.writerow(('one', 'two', 'three'))
    writer.writerow(('1', '2', '3'))
    writer.writerow(('4', '5', '6'))
    writer.writerow(('7', '8', '9'))
```

### 5. JSONæ•°æ®

#### â‘  JSON å¯¹è±¡ä¸ Python å¯¹è±¡è½¬æ¢ 

JSONï¼ˆJavaScript Object Notationçš„ç®€ç§°ï¼‰å·²ç»æˆä¸ºé€šè¿‡HTTPè¯·æ±‚åœ¨Webæµè§ˆå™¨å’Œå…¶ä»–åº”ç”¨ç¨‹åºä¹‹é—´å‘é€æ•°æ®çš„æ ‡å‡†æ ¼å¼ä¹‹ä¸€ã€‚å®ƒæ˜¯ä¸€ç§æ¯”è¡¨æ ¼å‹æ–‡æœ¬æ ¼å¼ï¼ˆå¦‚CSVï¼‰çµæ´»å¾—å¤šçš„æ•°æ®æ ¼å¼ã€‚ä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ï¼š
```python
obj = """
{"name": "Wes",
 "places_lived": ["United States", "Spain", "Germany"],
 "pet": null,
 "siblings": [{"name": "Scott", "age": 30, "pets": ["Zeus", "Zuko"]},
              {"name": "Katie", "age": 38,
               "pets": ["Sixes", "Stache", "Cisco"]}]
}
"""
```
é™¤å…¶ç©ºå€¼nullå’Œä¸€äº›å…¶ä»–çš„ç»†å¾®å·®åˆ«ï¼ˆå¦‚åˆ—è¡¨æœ«å°¾ä¸å…è®¸å­˜åœ¨å¤šä½™çš„é€—å·ï¼‰ä¹‹å¤–ï¼ŒJSONéå¸¸æ¥è¿‘äºæœ‰æ•ˆçš„Pythonä»£ç ã€‚åŸºæœ¬ç±»å‹æœ‰å¯¹è±¡ï¼ˆå­—å…¸ï¼‰ã€æ•°ç»„ï¼ˆåˆ—è¡¨ï¼‰ã€å­—ç¬¦ä¸²ã€æ•°å€¼ã€å¸ƒå°”å€¼ä»¥åŠnullã€‚å¯¹è±¡ä¸­æ‰€æœ‰çš„é”®éƒ½å¿…é¡»æ˜¯å­—ç¬¦ä¸²ã€‚è®¸å¤šPythonåº“éƒ½å¯ä»¥è¯»å†™JSONæ•°æ®ã€‚æˆ‘å°†ä½¿ç”¨ jsonï¼Œå› ä¸ºå®ƒæ˜¯æ„å»ºäºPythonæ ‡å‡†åº“ä¸­çš„ã€‚**é€šè¿‡` json.loads` å³å¯å°†JSONå­—ç¬¦ä¸²è½¬æ¢æˆPythonå½¢å¼**ï¼š
```python
In [62]: import json

In [63]: result = json.loads(obj)

In [64]: result
Out[64]: 
{'name': 'Wes',
 'pet': None,
 'places_lived': ['United States', 'Spain', 'Germany'],
 'siblings': [{'age': 30, 'name': 'Scott', 'pets': ['Zeus', 'Zuko']},
  {'age': 38, 'name': 'Katie', 'pets': ['Sixes', 'Stache', 'Cisco']}]}
```

`json.dumps` åˆ™å°†Pythonå¯¹è±¡è½¬æ¢æˆJSONæ ¼å¼ï¼š

```python
In [65]: asjson = json.dumps(result)
```

#### â‘¡ JSON å¯¹è±¡ä¸ DataFrame/Series è½¬æ¢

â­ **å¦‚ä½•å°†ï¼ˆä¸€ä¸ªæˆ–ä¸€ç»„ï¼‰JSONå¯¹è±¡è½¬æ¢ä¸ºDataFrame**æˆ–å…¶ä»–ä¾¿äºåˆ†æçš„æ•°æ®ç»“æ„å°±ç”±ä½ å†³å®šäº†ã€‚**æœ€ç®€å•æ–¹ä¾¿çš„æ–¹å¼æ˜¯ï¼šå‘DataFrameæ„é€ å™¨ä¼ å…¥ä¸€ä¸ªå­—å…¸çš„åˆ—è¡¨ï¼ˆå°±æ˜¯åŸå…ˆçš„JSONå¯¹è±¡ï¼‰ï¼Œå¹¶é€‰å–æ•°æ®å­—æ®µçš„å­é›†**ï¼š

```python
In [66]: siblings = pd.DataFrame(result['siblings'], columns=['name', 'age'])

In [67]: siblings
Out[67]: 
    name  age
0  Scott   30
1  Katie   38
```

**`pandas.read_json` å¯ä»¥è‡ªåŠ¨å°†ç‰¹åˆ«æ ¼å¼çš„JSONæ•°æ®é›†è½¬æ¢ä¸ºSeriesæˆ–DataFrame**ã€‚ä¾‹å¦‚ï¼š

```python
In [68]: !type examples/example.json
[{"a": 1, "b": 2, "c": 3},
 {"a": 4, "b": 5, "c": 6},
 {"a": 7, "b": 8, "c": 9}]
```

pandas.read_json çš„é»˜è®¤é€‰é¡¹å‡è®¾JSONæ•°ç»„ä¸­çš„æ¯ä¸ªå¯¹è±¡æ˜¯è¡¨æ ¼ä¸­çš„ä¸€è¡Œï¼š
```python
In [69]: data = pd.read_json('examples/example.json')

In [70]: data
Out[70]: 
   a  b  c
0  1  2  3
1  4  5  6
2  7  8  9
```

> ğŸ”Š ç¬¬7ç« ä¸­å…³äºUSDA Food Databaseçš„é‚£ä¸ªä¾‹å­è¿›ä¸€æ­¥è®²è§£äº†JSONæ•°æ®çš„è¯»å–å’Œå¤„ç†ï¼ˆåŒ…æ‹¬åµŒå¥—è®°å½•ï¼‰ã€‚

â­ å¦‚æœä½ éœ€è¦**å°†æ•°æ®ä»pandasè¾“å‡ºåˆ°JSONï¼Œå¯ä»¥ä½¿ç”¨ `to_json` æ–¹æ³•**ï¼š
```python
In [71]: print(data.to_json())
{"a":{"0":1,"1":4,"2":7},"b":{"0":2,"1":5,"2":8},"c":{"0":3,"1":6,"2":9}}

In [72]: print(data.to_json(orient='records'))
[{"a":1,"b":2,"c":3},{"a":4,"b":5,"c":6},{"a":7,"b":8,"c":9}]
```

### 6. XML å’Œ HTMLï¼šWeb ä¿¡æ¯æ”¶é›†

Pythonæœ‰è®¸å¤šå¯ä»¥è¯»å†™å¸¸è§çš„HTMLå’ŒXMLæ ¼å¼æ•°æ®çš„åº“ï¼ŒåŒ…æ‹¬lxmlã€Beautiful Soupå’Œhtml5libã€‚lxmlçš„é€Ÿåº¦æ¯”è¾ƒå¿«ï¼Œä½†å…¶å®ƒçš„åº“å¤„ç†æœ‰è¯¯çš„HTMLæˆ–XMLæ–‡ä»¶æ›´å¥½ã€‚

**pandasæœ‰ä¸€ä¸ªå†…ç½®çš„åŠŸèƒ½ï¼Œ`read_html`ï¼Œå®ƒå¯ä»¥ä½¿ç”¨lxmlå’ŒBeautiful Soupè‡ªåŠ¨å°†HTMLæ–‡ä»¶ä¸­çš„è¡¨æ ¼è§£æä¸ºDataFrameå¯¹è±¡ã€‚**ä¸ºäº†è¿›è¡Œå±•ç¤ºï¼Œæˆ‘ä»ç¾å›½è”é‚¦å­˜æ¬¾ä¿é™©å…¬å¸ä¸‹è½½äº†ä¸€ä¸ªHTMLæ–‡ä»¶ï¼ˆpandasæ–‡æ¡£ä¸­ä¹Ÿä½¿ç”¨è¿‡ï¼‰ï¼Œå®ƒè®°å½•äº†é“¶è¡Œå€’é—­çš„æƒ…å†µã€‚é¦–å…ˆï¼Œä½ éœ€è¦å®‰è£…read_htmlç”¨åˆ°çš„åº“ï¼š

```powershell
conda install lxml
pip install beautifulsoup4 html5lib
```

å¦‚æœä½ ç”¨çš„ä¸æ˜¯ condaï¼Œå¯ä»¥ä½¿ç”¨``pip install lxml``ã€‚

pandas.read_html æœ‰ä¸€äº›é€‰é¡¹ï¼Œé»˜è®¤æ¡ä»¶ä¸‹ï¼Œå®ƒä¼šæœç´¢ã€å°è¯•è§£æ `<table>` æ ‡ç­¾å†…çš„çš„è¡¨æ ¼æ•°æ®ã€‚ç»“æœæ˜¯ä¸€ä¸ªåˆ—è¡¨çš„DataFrameå¯¹è±¡ï¼š
```python
In [73]: tables = pd.read_html('examples/fdic_failed_bank_list.html')

In [74]: len(tables)
Out[74]: 1

In [75]: failures = tables[0]

In [76]: failures.head()
Out[76]: 
                      Bank Name             City  ST   CERT  \
0                   Allied Bank         Mulberry  AR     91   
1  The Woodbury Banking Company         Woodbury  GA  11297   
2        First CornerStone Bank  King of Prussia  PA  35312   
3            Trust Company Bank          Memphis  TN   9956   
4    North Milwaukee State Bank        Milwaukee  WI  20364   
                 Acquiring Institution        Closing Date       Updated Date  
0                         Today's Bank  September 23, 2016  November 17, 2016  
1                          United Bank     August 19, 2016  November 17, 2016  
2  First-Citizens Bank & Trust Company         May 6, 2016  September 6, 2016  
3           The Bank of Fayette County      April 29, 2016  September 6, 2016  
4  First-Citizens Bank & Trust Company      March 11, 2016      June 16, 2016
```

å› ä¸º failures æœ‰è®¸å¤šåˆ—ï¼Œpandasæ’å…¥äº†ä¸€ä¸ªæ¢è¡Œç¬¦ `\`ã€‚

è¿™é‡Œï¼Œæˆ‘ä»¬å¯ä»¥åšä¸€äº›æ•°æ®æ¸…æ´—å’Œåˆ†æï¼ˆåé¢ç« èŠ‚ä¼šè¿›ä¸€æ­¥è®²è§£ï¼‰ï¼Œæ¯”å¦‚è®¡ç®—æŒ‰å¹´ä»½è®¡ç®—å€’é—­çš„é“¶è¡Œæ•°ï¼š
```python
In [77]: close_timestamps = pd.to_datetime(failures['Closing Date'])

In [78]: close_timestamps.dt.year.value_counts()
Out[78]: 
2010    157
2009    140
2011     92
2012     51
2008     25
       ... 
2004      4
2001      4
2007      3
2003      3
2000      2
Name: Closing Date, Length: 15, dtype: int64
```

### 7. åˆ©ç”¨ lxml.objectify è§£æ XML
XMLï¼ˆExtensible Markup Languageï¼‰æ˜¯å¦ä¸€ç§å¸¸è§çš„æ”¯æŒåˆ†å±‚ã€åµŒå¥—æ•°æ®ä»¥åŠå…ƒæ•°æ®çš„ç»“æ„åŒ–æ•°æ®æ ¼å¼ã€‚æœ¬ä¹¦æ‰€ä½¿ç”¨çš„è¿™äº›æ–‡ä»¶å®é™…ä¸Šæ¥è‡ªäºä¸€ä¸ªå¾ˆå¤§çš„XMLæ–‡æ¡£ã€‚

å‰é¢ï¼Œæˆ‘ä»‹ç»äº†pandas.read_html å‡½æ•°ï¼Œå®ƒå¯ä»¥ä½¿ç”¨ lxml æˆ– Beautiful Soup ä» HTML è§£ææ•°æ®ã€‚XML å’Œ HTML çš„ç»“æ„å¾ˆç›¸ä¼¼ï¼Œä½†XMLæ›´ä¸ºé€šç”¨ã€‚è¿™é‡Œï¼Œ**æˆ‘ä¼šç”¨ä¸€ä¸ªä¾‹å­æ¼”ç¤ºå¦‚ä½•åˆ©ç”¨ lxml ä» XML æ ¼å¼è§£ææ•°æ®**ã€‚

çº½çº¦å¤§éƒ½ä¼šè¿è¾“ç½²å‘å¸ƒäº†ä¸€äº›æœ‰å…³å…¶å…¬äº¤å’Œåˆ—è½¦æœåŠ¡çš„æ•°æ®èµ„æ–™ï¼ˆhttp://www.mta.info/developers/download.htmlï¼‰ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å°†çœ‹çœ‹åŒ…å«åœ¨ä¸€ç»„XMLæ–‡ä»¶ä¸­çš„è¿è¡Œæƒ…å†µæ•°æ®ã€‚æ¯é¡¹åˆ—è½¦æˆ–å…¬äº¤æœåŠ¡éƒ½æœ‰å„è‡ªçš„æ–‡ä»¶ï¼ˆå¦‚Metro-North Railroadçš„æ–‡ä»¶æ˜¯Performance_MNR.xmlï¼‰ï¼Œå…¶ä¸­æ¯æ¡XMLè®°å½•å°±æ˜¯ä¸€æ¡æœˆåº¦æ•°æ®ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š
```xml
<INDICATOR>
  <INDICATOR_SEQ>373889</INDICATOR_SEQ>
  <PARENT_SEQ></PARENT_SEQ>
  <AGENCY_NAME>Metro-North Railroad</AGENCY_NAME>
  <INDICATOR_NAME>Escalator Availability</INDICATOR_NAME>
  <DESCRIPTION>Percent of the time that escalators are operational
  systemwide. The availability rate is based on physical observations performed
  the morning of regular business days only. This is a new indicator the agency
  began reporting in 2009.</DESCRIPTION>
  <PERIOD_YEAR>2011</PERIOD_YEAR>
  <PERIOD_MONTH>12</PERIOD_MONTH>
  <CATEGORY>Service Indicators</CATEGORY>
  <FREQUENCY>M</FREQUENCY>
  <DESIRED_CHANGE>U</DESIRED_CHANGE>
  <INDICATOR_UNIT>%</INDICATOR_UNIT>
  <DECIMAL_PLACES>1</DECIMAL_PLACES>
  <YTD_TARGET>97.00</YTD_TARGET>
  <YTD_ACTUAL></YTD_ACTUAL>
  <MONTHLY_TARGET>97.00</MONTHLY_TARGET>
  <MONTHLY_ACTUAL></MONTHLY_ACTUAL>
</INDICATOR>
```

æˆ‘ä»¬**å…ˆç”¨ `lxml.objectify` è§£æè¯¥æ–‡ä»¶ï¼Œç„¶åé€šè¿‡ `getroot` å¾—åˆ°è¯¥XMLæ–‡ä»¶çš„æ ¹èŠ‚ç‚¹çš„å¼•ç”¨**ï¼š
```python
from lxml import objectify

path = 'datasets/mta_perf/Performance_MNR.xml'
parsed = objectify.parse(open(path))
root = parsed.getroot()
```

`root.INDICATOR` è¿”å›ä¸€ä¸ªç”¨äºäº§ç”Ÿå„ä¸ª `<INDICATOR>` XMLå…ƒç´ çš„ç”Ÿæˆå™¨ã€‚å¯¹äºæ¯æ¡è®°å½•ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æ ‡è®°åï¼ˆå¦‚YTD_ACTUALï¼‰å’Œæ•°æ®å€¼å¡«å……ä¸€ä¸ªå­—å…¸ï¼ˆæ’é™¤å‡ ä¸ªæ ‡è®°ï¼‰ï¼š

```python
data = []

skip_fields = ['PARENT_SEQ', 'INDICATOR_SEQ',
               'DESIRED_CHANGE', 'DECIMAL_PLACES']

for elt in root.INDICATOR:
    el_data = {}
    for child in elt.getchildren():
        if child.tag in skip_fields:
            continue
        el_data[child.tag] = child.pyval
    data.append(el_data)
```

æœ€åï¼Œå°†è¿™ç»„å­—å…¸è½¬æ¢ä¸ºä¸€ä¸ªDataFrameï¼š
```python
In [81]: perf = pd.DataFrame(data)

In [82]: perf.head()
Out[82]:
Empty DataFrame
Columns: []
Index: []
```

XMLæ•°æ®å¯ä»¥æ¯”æœ¬ä¾‹å¤æ‚å¾—å¤šã€‚æ¯ä¸ªæ ‡è®°éƒ½å¯ä»¥æœ‰å…ƒæ•°æ®ã€‚çœ‹çœ‹ä¸‹é¢è¿™ä¸ªHTMLçš„é“¾æ¥æ ‡ç­¾ï¼ˆå®ƒä¹Ÿç®—æ˜¯ä¸€æ®µæœ‰æ•ˆçš„XMLï¼‰ï¼š
```python
from io import StringIO
tag = '<a href="http://www.google.com">Google</a>'
root = objectify.parse(StringIO(tag)).getroot()
```

ç°åœ¨å°±å¯ä»¥è®¿é—®æ ‡ç­¾æˆ–é“¾æ¥æ–‡æœ¬ä¸­çš„ä»»ä½•å­—æ®µäº†ï¼ˆå¦‚hrefï¼‰ï¼š
```python
In [84]: root
Out[84]: <Element a at 0x7f6b15817748>

In [85]: root.get('href')
Out[85]: 'http://www.google.com'

In [86]: root.text
Out[86]: 'Google'
```

## 6.2 äºŒè¿›åˆ¶æ•°æ®æ ¼å¼

### 1. pandas çš„åºåˆ—åŒ–

**å®ç°æ•°æ®çš„é«˜æ•ˆäºŒè¿›åˆ¶æ ¼å¼å­˜å‚¨æœ€ç®€å•çš„åŠæ³•ä¹‹ä¸€æ˜¯ä½¿ç”¨Pythonå†…ç½®çš„pickleåºåˆ—åŒ–ã€‚pandaså¯¹è±¡éƒ½æœ‰ä¸€ä¸ªç”¨äºå°†æ•°æ®ä»¥ pickle æ ¼å¼ä¿å­˜åˆ°ç£ç›˜ä¸Šçš„ `to_pickle` æ–¹æ³•**ï¼š

```python
In [87]: frame = pd.read_csv('examples/ex1.csv')

In [88]: frame
Out[88]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo

In [89]: frame.to_pickle('examples/frame_pickle')
```

ä½ å¯ä»¥é€šè¿‡pickleç›´æ¥è¯»å–è¢«pickleåŒ–çš„æ•°æ®ï¼Œæˆ–æ˜¯ä½¿ç”¨æ›´ä¸ºæ–¹ä¾¿çš„ `pandas.read_pickle`ï¼š
```python
In [90]: pd.read_pickle('examples/frame_pickle')
Out[90]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

>ğŸš¨ **pickle ä»…å»ºè®®ç”¨äºçŸ­æœŸå­˜å‚¨æ ¼å¼ã€‚**å…¶åŸå› æ˜¯å¾ˆéš¾ä¿è¯è¯¥æ ¼å¼æ°¸è¿œæ˜¯ç¨³å®šçš„ï¼›ä»Šå¤©pickleçš„å¯¹è±¡å¯èƒ½æ— æ³•è¢«åç»­ç‰ˆæœ¬çš„åº“unpickleå‡ºæ¥ã€‚

pandaså†…ç½®æ”¯æŒä¸¤ä¸ªäºŒè¿›åˆ¶æ•°æ®æ ¼å¼ï¼š`HDF5` å’Œ `MessagePack`ã€‚ä¸‹ä¸€èŠ‚ï¼Œæˆ‘ä¼šç»™å‡ºå‡ ä¸ªHDF5çš„ä¾‹å­ï¼Œä½†æˆ‘å»ºè®®ä½ å°è¯•ä¸‹ä¸åŒçš„æ–‡ä»¶æ ¼å¼ï¼Œçœ‹çœ‹å®ƒä»¬çš„é€Ÿåº¦ä»¥åŠæ˜¯å¦é€‚åˆä½ çš„åˆ†æå·¥ä½œã€‚pandasæˆ–NumPyæ•°æ®çš„å…¶å®ƒå­˜å‚¨æ ¼å¼æœ‰ï¼š

- bcolzï¼šä¸€ç§å¯å‹ç¼©çš„åˆ—å­˜å‚¨äºŒè¿›åˆ¶æ ¼å¼ï¼ŒåŸºäºBloscå‹ç¼©åº“ã€‚
- Featherï¼šæˆ‘ä¸Rè¯­è¨€ç¤¾åŒºçš„Hadley Wickhamè®¾è®¡çš„ä¸€ç§è·¨è¯­è¨€çš„åˆ—å­˜å‚¨æ–‡ä»¶æ ¼å¼ã€‚Featherä½¿ç”¨äº†Apache Arrowçš„åˆ—å¼å†…å­˜æ ¼å¼ã€‚

### 2. ä½¿ç”¨HDF5æ ¼å¼

**HDF5æ˜¯ä¸€ç§å­˜å‚¨å¤§è§„æ¨¡ç§‘å­¦æ•°ç»„æ•°æ®çš„éå¸¸å¥½çš„æ–‡ä»¶æ ¼å¼ã€‚**å®ƒå¯ä»¥è¢«ä½œä¸ºCæ ‡å‡†åº“ï¼Œå¸¦æœ‰è®¸å¤šè¯­è¨€çš„æ¥å£ï¼Œå¦‚Javaã€Pythonå’ŒMATLABç­‰ã€‚**HDF5ä¸­çš„HDFæŒ‡çš„æ˜¯å±‚æ¬¡å‹æ•°æ®æ ¼å¼ï¼ˆhierarchical data formatï¼‰**ã€‚æ¯ä¸ªHDF5æ–‡ä»¶éƒ½å«æœ‰ä¸€ä¸ªæ–‡ä»¶ç³»ç»Ÿå¼çš„èŠ‚ç‚¹ç»“æ„ï¼Œå®ƒä½¿ä½ èƒ½å¤Ÿå­˜å‚¨å¤šä¸ªæ•°æ®é›†å¹¶æ”¯æŒå…ƒæ•°æ®ã€‚ä¸å…¶ä»–ç®€å•æ ¼å¼ç›¸æ¯”ï¼ŒHDF5æ”¯æŒå¤šç§å‹ç¼©å™¨çš„å³æ—¶å‹ç¼©ï¼Œè¿˜èƒ½æ›´é«˜æ•ˆåœ°å­˜å‚¨é‡å¤æ¨¡å¼æ•°æ®ã€‚<u>å¯¹äºé‚£äº›éå¸¸å¤§çš„æ— æ³•ç›´æ¥æ”¾å…¥å†…å­˜çš„æ•°æ®é›†ï¼ŒHDF5å°±æ˜¯ä¸é”™çš„é€‰æ‹©ï¼Œå› ä¸ºå®ƒå¯ä»¥é«˜æ•ˆåœ°åˆ†å—è¯»å†™ã€‚</u>

è™½ç„¶å¯ä»¥ç”¨PyTablesæˆ–h5pyåº“ç›´æ¥è®¿é—®HDF5æ–‡ä»¶ï¼Œpandasæä¾›äº†æ›´ä¸ºé«˜çº§çš„æ¥å£ï¼Œå¯ä»¥ç®€åŒ–å­˜å‚¨Serieså’ŒDataFrameå¯¹è±¡ã€‚`HDFStore` ç±»å¯ä»¥åƒå­—å…¸ä¸€æ ·ï¼Œå¤„ç†ä½çº§çš„ç»†èŠ‚ï¼š
```python
In [92]: frame = pd.DataFrame({'a': np.random.randn(100)})

In [93]: store = pd.HDFStore('mydata.h5')

In [94]: store['obj1'] = frame

In [95]: store['obj1_col'] = frame['a']

In [96]: store
Out[96]: 
<class 'pandas.io.pytables.HDFStore'>
File path: mydata.h5
/obj1                frame        (shape->[100,1])                               
        
/obj1_col            series       (shape->[100])                                 
        
/obj2                frame_table  (typ->appendable,nrows->100,ncols->1,indexers->
[index])
/obj3                frame_table  (typ->appendable,nrows->100,ncols->1,indexers->
[index])
```

HDF5æ–‡ä»¶ä¸­çš„å¯¹è±¡å¯ä»¥é€šè¿‡ä¸å­—å…¸ä¸€æ ·çš„APIè¿›è¡Œè·å–ï¼š
```python
In [97]: store['obj1']
Out[97]: 
           a
0  -0.204708
1   0.478943
2  -0.519439
3  -0.555730
4   1.965781
..       ...
95  0.795253
96  0.118110
97 -0.748532
98  0.584970
99  0.152677
[100 rows x 1 columns]
```

HDFStoreæ”¯æŒä¸¤ç§å­˜å‚¨æ¨¡å¼ï¼Œ`fixed` å’Œ `table` ã€‚åè€…é€šå¸¸ä¼šæ›´æ…¢ï¼Œä½†æ˜¯æ”¯æŒä½¿ç”¨ç‰¹æ®Šè¯­æ³•è¿›è¡ŒæŸ¥è¯¢æ“ä½œï¼š
```python
In [98]: store.put('obj2', frame, format='table')

In [99]: store.select('obj2', where=['index >= 10 and index <= 15'])
Out[99]: 
           a
10  1.007189
11 -1.296221
12  0.274992
13  0.228913
14  1.352917
15  0.886429

In [100]: store.close()
```

putæ˜¯ `store['obj2'] = frame`æ–¹æ³•çš„æ˜¾ç¤ºç‰ˆæœ¬ï¼Œå…è®¸æˆ‘ä»¬è®¾ç½®å…¶å®ƒçš„é€‰é¡¹ï¼Œæ¯”å¦‚æ ¼å¼ã€‚

**`pandas.read_hdf` å‡½æ•°å¯ä»¥å¿«æ·ä½¿ç”¨è¿™äº›å·¥å…·**ï¼š

```python
In [101]: frame.to_hdf('mydata.h5', 'obj3', format='table')

In [102]: pd.read_hdf('mydata.h5', 'obj3', where=['index < 5'])
Out[102]: 
          a
0 -0.204708
1  0.478943
2 -0.519439
3 -0.555730
4  1.965781
```

>ğŸš© å¦‚æœä½ è¦å¤„ç†çš„æ•°æ®ä½äºè¿œç¨‹æœåŠ¡å™¨ï¼Œæ¯”å¦‚Amazon S3æˆ–HDFSï¼Œä½¿ç”¨ä¸“é—¨ä¸ºåˆ†å¸ƒå¼å­˜å‚¨ï¼ˆæ¯”å¦‚Apache Parquetï¼‰çš„äºŒè¿›åˆ¶æ ¼å¼ä¹Ÿè®¸æ›´åŠ åˆé€‚ã€‚Pythonçš„Parquetå’Œå…¶å®ƒå­˜å‚¨æ ¼å¼è¿˜åœ¨ä¸æ–­çš„å‘å±•ä¹‹ä¸­ï¼Œæ‰€ä»¥è¿™æœ¬ä¹¦ä¸­æ²¡æœ‰æ¶‰åŠã€‚

å¦‚æœéœ€è¦æœ¬åœ°å¤„ç†æµ·é‡æ•°æ®ï¼Œæˆ‘å»ºè®®ä½ å¥½å¥½ç ”ç©¶ä¸€ä¸‹PyTableså’Œh5pyï¼Œçœ‹çœ‹å®ƒä»¬èƒ½æ»¡è¶³ä½ çš„å“ªäº›éœ€æ±‚ã€‚ã€‚ç”±äºè®¸å¤šæ•°æ®åˆ†æé—®é¢˜éƒ½æ˜¯IOå¯†é›†å‹ï¼ˆè€Œä¸æ˜¯CPUå¯†é›†å‹ï¼‰ï¼Œåˆ©ç”¨HDF5è¿™æ ·çš„å·¥å…·èƒ½æ˜¾è‘—æå‡åº”ç”¨ç¨‹åºçš„æ•ˆç‡ã€‚

>ğŸš¨ **HDF5ä¸æ˜¯æ•°æ®åº“ã€‚å®ƒæœ€é€‚åˆç”¨ä½œâ€œä¸€æ¬¡å†™å¤šæ¬¡è¯»â€çš„æ•°æ®é›†ã€‚è™½ç„¶æ•°æ®å¯ä»¥åœ¨ä»»ä½•æ—¶å€™è¢«æ·»åŠ åˆ°æ–‡ä»¶ä¸­ï¼Œä½†å¦‚æœåŒæ—¶å‘ç”Ÿå¤šä¸ªå†™æ“ä½œï¼Œæ–‡ä»¶å°±å¯èƒ½ä¼šè¢«ç ´åã€‚**

### 3. è¯»å–Microsoft Excelæ–‡ä»¶

pandasçš„ `ExcelFile `ç±»æˆ– `pandas.read_excel` å‡½æ•°æ”¯æŒè¯»å–å­˜å‚¨åœ¨Excel 2003ï¼ˆæˆ–æ›´é«˜ç‰ˆæœ¬ï¼‰ä¸­çš„è¡¨æ ¼å‹æ•°æ®ã€‚è¿™ä¸¤ä¸ªå·¥å…·åˆ†åˆ«ä½¿ç”¨æ‰©å±•åŒ… `xlrd` å’Œ `openpyxl` è¯»å–XLSå’ŒXLSXæ–‡ä»¶ã€‚ä½ å¯ä»¥ç”¨pipæˆ–condaå®‰è£…å®ƒä»¬ã€‚

è¦ä½¿ç”¨ ExcelFileï¼Œé€šè¿‡ä¼ é€’xlsæˆ–xlsxè·¯å¾„åˆ›å»ºä¸€ä¸ªå®ä¾‹ï¼š
```python
In [104]: xlsx = pd.ExcelFile('examples/ex1.xlsx')
```

å­˜å‚¨åœ¨è¡¨å•ä¸­çš„æ•°æ®å¯ä»¥ read_excel è¯»å–åˆ° DataFrameï¼š
```python
In [105]: pd.read_excel(xlsx, 'Sheet1')
Out[105]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

å¦‚æœè¦è¯»å–ä¸€ä¸ªæ–‡ä»¶ä¸­çš„å¤šä¸ªè¡¨å•ï¼Œåˆ›å»ºExcelFileä¼šæ›´å¿«ï¼Œä½†ä½ ä¹Ÿå¯ä»¥å°†æ–‡ä»¶åä¼ é€’åˆ°pandas.read_excelï¼š
```python
In [106]: frame = pd.read_excel('examples/ex1.xlsx', 'Sheet1')

In [107]: frame
Out[107]: 
   a   b   c   d message
0  1   2   3   4   hello
1  5   6   7   8   world
2  9  10  11  12     foo
```

å¦‚æœè¦å°†pandasæ•°æ®å†™å…¥ä¸ºExcelæ ¼å¼ï¼Œä½ å¿…é¡»é¦–å…ˆåˆ›å»ºä¸€ä¸ª`ExcelWriter`ï¼Œç„¶åä½¿ç”¨pandaså¯¹è±¡çš„ `to_excel` æ–¹æ³•å°†æ•°æ®å†™å…¥åˆ°å…¶ä¸­ï¼š
```python
In [108]: writer = pd.ExcelWriter('examples/ex2.xlsx')

In [109]: frame.to_excel(writer, 'Sheet1')

In [110]: writer.save()
```

ä½ è¿˜å¯ä»¥ä¸ä½¿ç”¨ExcelWriterï¼Œè€Œæ˜¯ä¼ é€’æ–‡ä»¶çš„è·¯å¾„åˆ°to_excelï¼š
```python
In [111]: frame.to_excel('examples/ex2.xlsx')
```

## 6.3 Web APIs äº¤äº’
è®¸å¤šç½‘ç«™éƒ½æœ‰ä¸€äº›é€šè¿‡JSONæˆ–å…¶ä»–æ ¼å¼æä¾›æ•°æ®çš„å…¬å…±APIã€‚é€šè¿‡Pythonè®¿é—®è¿™äº›APIçš„åŠæ³•æœ‰ä¸å°‘ã€‚ä¸€ä¸ªç®€å•æ˜“ç”¨çš„åŠæ³•ï¼ˆæ¨èï¼‰æ˜¯ `requests` åŒ…ï¼ˆhttp://docs.python-requests.orgï¼‰ã€‚

ä¸ºäº†æœç´¢æœ€æ–°çš„30ä¸ªGitHubä¸Šçš„pandasä¸»é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥å‘ä¸€ä¸ªHTTP GETè¯·æ±‚ï¼Œä½¿ç”¨requestsæ‰©å±•åº“ï¼š
```python
In [113]: import requests

In [114]: url = 'https://api.github.com/repos/pandas-dev/pandas/issues'

In [115]: resp = requests.get(url)

In [116]: resp
Out[116]: <Response [200]>
```

å“åº”å¯¹è±¡çš„jsonæ–¹æ³•ä¼šè¿”å›ä¸€ä¸ªåŒ…å«è¢«è§£æè¿‡çš„JSONå­—å…¸ï¼ŒåŠ è½½åˆ°ä¸€ä¸ªPythonå¯¹è±¡ä¸­ï¼š
```python
In [117]: data = resp.json()

In [118]: data[0]['title']
Out[118]: 'Period does not round down for frequencies less that 1 hour'
```

dataä¸­çš„æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªåŒ…å«æ‰€æœ‰GitHubä¸»é¢˜é¡µæ•°æ®ï¼ˆä¸åŒ…å«è¯„è®ºï¼‰çš„å­—å…¸ã€‚æˆ‘ä»¬å¯ä»¥ç›´æ¥ä¼ é€’æ•°æ®åˆ°DataFrameï¼Œå¹¶æå–æ„Ÿå…´è¶£çš„å­—æ®µï¼š
```python
In [119]: issues = pd.DataFrame(data, columns=['number', 'title',
   .....:                                      'labels', 'state'])

In [120]: issues
Out[120]:
    number                                              title  \
0    17666  Period does not round down for frequencies les...   
1    17665           DOC: improve docstring of function where   
2    17664               COMPAT: skip 32-bit test on int repr   
3    17662                          implement Delegator class
4    17654  BUG: Fix series rename called with str alterin...   
..     ...                                                ...   
25   17603  BUG: Correctly localize naive datetime strings...   
26   17599                     core.dtypes.generic --> cython   
27   17596   Merge cdate_range functionality into bdate_range   
28   17587  Time Grouper bug fix when applied for list gro...   
29   17583  BUG: fix tz-aware DatetimeIndex + TimedeltaInd...   
                                               labels state  
0                                                  []  open  
1   [{'id': 134699, 'url': 'https://api.github.com...  open  
2   [{'id': 563047854, 'url': 'https://api.github....  open  
3                                                  []  open  
4   [{'id': 76811, 'url': 'https://api.github.com/...  open  
..                                                ...   ...  
25  [{'id': 76811, 'url': 'https://api.github.com/...  open  
26  [{'id': 49094459, 'url': 'https://api.github.c...  open  
27  [{'id': 35818298, 'url': 'https://api.github.c...  open  
28  [{'id': 233160, 'url': 'https://api.github.com...  open  
29  [{'id': 76811, 'url': 'https://api.github.com/...  open  
[30 rows x 4 columns]
```

èŠ±è´¹ä¸€äº›ç²¾åŠ›ï¼Œä½ å°±å¯ä»¥åˆ›å»ºä¸€äº›æ›´é«˜çº§çš„å¸¸è§çš„Web APIçš„æ¥å£ï¼Œè¿”å›DataFrameå¯¹è±¡ï¼Œæ–¹ä¾¿è¿›è¡Œåˆ†æã€‚

## 6.4 æ•°æ®åº“äº¤äº’

åœ¨å•†ä¸šåœºæ™¯ä¸‹ï¼Œå¤§å¤šæ•°æ•°æ®å¯èƒ½ä¸æ˜¯å­˜å‚¨åœ¨æ–‡æœ¬æˆ–Excelæ–‡ä»¶ä¸­ã€‚åŸºäºSQLçš„å…³ç³»å‹æ•°æ®åº“ï¼ˆå¦‚SQL Serverã€PostgreSQLå’ŒMySQLç­‰ï¼‰ä½¿ç”¨éå¸¸å¹¿æ³›ï¼Œå…¶å®ƒä¸€äº›æ•°æ®åº“ä¹Ÿå¾ˆæµè¡Œã€‚æ•°æ®åº“çš„é€‰æ‹©é€šå¸¸å–å†³äºæ€§èƒ½ã€æ•°æ®å®Œæ•´æ€§ä»¥åŠåº”ç”¨ç¨‹åºçš„ä¼¸ç¼©æ€§éœ€æ±‚ã€‚

å°†æ•°æ®ä»SQLåŠ è½½åˆ°DataFrameçš„è¿‡ç¨‹å¾ˆç®€å•ï¼Œæ­¤å¤–pandasè¿˜æœ‰ä¸€äº›èƒ½å¤Ÿç®€åŒ–è¯¥è¿‡ç¨‹çš„å‡½æ•°ã€‚ä¾‹å¦‚ï¼Œæˆ‘å°†ä½¿ç”¨SQLiteæ•°æ®åº“ï¼ˆé€šè¿‡Pythonå†…ç½®çš„sqlite3é©±åŠ¨å™¨ï¼‰ï¼š
```python
In [121]: import sqlite3

In [122]: query = """
   .....: CREATE TABLE test
   .....: (a VARCHAR(20), b VARCHAR(20),
   .....:  c REAL,        d INTEGER
   .....: );"""

In [123]: con = sqlite3.connect('mydata.sqlite')

In [124]: con.execute(query)
Out[124]: <sqlite3.Cursor at 0x7f6b12a50f10>

In [125]: con.commit()
```

ç„¶åæ’å…¥å‡ è¡Œæ•°æ®ï¼š
```python
In [126]: data = [('Atlanta', 'Georgia', 1.25, 6),
   .....:         ('Tallahassee', 'Florida', 2.6, 3),
   .....:         ('Sacramento', 'California', 1.7, 5)]

In [127]: stmt = "INSERT INTO test VALUES(?, ?, ?, ?)"

In [128]: con.executemany(stmt, data)
Out[128]: <sqlite3.Cursor at 0x7f6b15c66ce0>
```

**ä»è¡¨ä¸­é€‰å–æ•°æ®æ—¶ï¼Œå¤§éƒ¨åˆ†Python SQLé©±åŠ¨å™¨ï¼ˆPyODBCã€psycopg2ã€MySQLdbã€pymssqlç­‰ï¼‰éƒ½ä¼šè¿”å›ä¸€ä¸ªå…ƒç»„åˆ—è¡¨**ï¼š

```python
In [130]: cursor = con.execute('select * from test')

In [131]: rows = cursor.fetchall()

In [132]: rows
Out[132]: 
[('Atlanta', 'Georgia', 1.25, 6),
 ('Tallahassee', 'Florida', 2.6, 3),
 ('Sacramento', 'California', 1.7, 5)]
```

ä½ å¯ä»¥å°†è¿™ä¸ªå…ƒç»„åˆ—è¡¨ä¼ ç»™DataFrameæ„é€ å™¨ï¼Œä½†è¿˜éœ€è¦åˆ—åï¼ˆä½äºå…‰æ ‡çš„descriptionå±æ€§ä¸­ï¼‰ï¼š
```python
In [133]: cursor.description
Out[133]: 
(('a', None, None, None, None, None, None),
 ('b', None, None, None, None, None, None),
 ('c', None, None, None, None, None, None),
 ('d', None, None, None, None, None, None))

In [134]: pd.DataFrame(rows, columns=[x[0] for x in cursor.description])
Out[134]: 
             a           b     c  d
0      Atlanta     Georgia  1.25  6
1  Tallahassee     Florida  2.60  3
2   Sacramento  California  1.70  5
```

è¿™ç§æ•°æ®è§„æ•´æ“ä½œç›¸å½“å¤šï¼Œä½ è‚¯å®šä¸æƒ³æ¯æŸ¥ä¸€æ¬¡æ•°æ®åº“å°±é‡å†™ä¸€æ¬¡ã€‚[SQLAlchemyé¡¹ç›®](http://www.sqlalchemy.org/)æ˜¯ä¸€ä¸ªæµè¡Œçš„Python SQLå·¥å…·ï¼Œå®ƒæŠ½è±¡å‡ºäº†SQLæ•°æ®åº“ä¸­çš„è®¸å¤šå¸¸è§å·®å¼‚ã€‚pandasæœ‰ä¸€ä¸ª `read_sql` å‡½æ•°ï¼Œå¯ä»¥è®©ä½ è½»æ¾çš„ä»SQLAlchemy è¿æ¥è¯»å–æ•°æ®ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬**ç”¨SQLAlchemyè¿æ¥SQLiteæ•°æ®åº“**ï¼Œå¹¶ä»ä¹‹å‰åˆ›å»ºçš„è¡¨è¯»å–æ•°æ®ï¼š
```python
In [135]: import sqlalchemy as sqla

In [136]: db = sqla.create_engine('sqlite:///mydata.sqlite')

In [137]: pd.read_sql('select * from test', db)
Out[137]: 
             a           b     c  d
0      Atlanta     Georgia  1.25  6
1  Tallahassee     Florida  2.60  3
2   Sacramento  California  1.70  5
```

## âœ… End

è®¿é—®æ•°æ®é€šå¸¸æ˜¯æ•°æ®åˆ†æçš„ç¬¬ä¸€æ­¥ã€‚åœ¨æœ¬ç« ä¸­ï¼Œæˆ‘ä»¬å·²ç»å­¦äº†ä¸€äº›æœ‰ç”¨çš„å·¥å…·ã€‚åœ¨æ¥ä¸‹æ¥çš„ç« èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥ç ”ç©¶æ•°æ®è§„æ•´ã€æ•°æ®å¯è§†åŒ–ã€æ—¶é—´åºåˆ—åˆ†æå’Œå…¶å®ƒä¸»é¢˜ã€‚ 

---

# ğŸ“š References

- ğŸ“•  [ã€Šåˆ©ç”¨Pythonè¿›è¡Œæ•°æ®åˆ†æ-ç¬¬2ç‰ˆ-ä¸­æ–‡è¯‘ç‰ˆã€‹](https://www.jianshu.com/p/04d180d90a3f)

  <img src="https://gitee.com/veal98/images/raw/master/img/20200607091609.png" style="zoom:50%;" />

- ğŸš [Gihubã€ŠPythonæ•°æ®åˆ†æã€‹é…å¥—æºç ](https://github.com/wesm/pydata-book)
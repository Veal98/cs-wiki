# ğŸ† Keras å‡½æ•°å¼ API

---

```python
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
```

## 1. ç®€ä»‹

Keras *å‡½æ•°å¼ API* æ˜¯ä¸€ç§æ¯” [`tf.keras.Sequential`](https://tensorflow.google.cn/api_docs/python/tf/keras/Sequential?hl=zh_cn) API æ›´åŠ çµæ´»çš„æ¨¡å‹åˆ›å»ºæ–¹å¼ã€‚å‡½æ•°å¼ API å¯ä»¥å¤„ç†å…·æœ‰éçº¿æ€§æ‹“æ‰‘çš„æ¨¡å‹ã€å…·æœ‰å…±äº«å±‚çš„æ¨¡å‹ï¼Œä»¥åŠå…·æœ‰å¤šä¸ªè¾“å…¥æˆ–è¾“å‡ºçš„æ¨¡å‹ã€‚

æ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸æ˜¯å±‚çš„æœ‰å‘æ— ç¯å›¾ (DAG)ã€‚å› æ­¤ï¼Œå‡½æ•°å¼ API æ˜¯æ„å»º*å±‚è®¡ç®—å›¾*çš„ä¸€ç§æ–¹å¼ã€‚

è¯·è€ƒè™‘ä»¥ä¸‹æ¨¡å‹ï¼š

```
(input: 784-dimensional vectors)
[Dense (64 units, relu activation)] 
[Dense (64 units, relu activation)]
[Dense (10 units, softmax activation)] 
(output: logits of a probability distribution over 10 classes)
```

è¿™æ˜¯ä¸€ä¸ªå…·æœ‰ä¸‰å±‚çš„åŸºæœ¬è®¡ç®—å›¾ã€‚è¦ä½¿ç”¨å‡½æ•°å¼ API æ„å»ºæ­¤æ¨¡å‹ï¼Œè¯·å…ˆåˆ›å»ºä¸€ä¸ªè¾“å…¥èŠ‚ç‚¹ï¼š

```python
inputs = keras.Input(shape=(784,))
```

æ•°æ®çš„å½¢çŠ¶è®¾ç½®ä¸º 784 ç»´å‘é‡ã€‚<u>ç”±äºä»…æŒ‡å®šäº†æ¯ä¸ªæ ·æœ¬çš„å½¢çŠ¶ï¼Œå› æ­¤å§‹ç»ˆå¿½ç•¥æ‰¹æ¬¡å¤§å°</u>ã€‚

ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æœ‰ä¸€ä¸ªå½¢çŠ¶ä¸º `(32, 32, 3)` çš„å›¾åƒè¾“å…¥ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ï¼š

```python
# Just for demonstration purposes.
img_inputs = keras.Input(shape=(32, 32, 3))
```

> ğŸ’¡ è¿”å›çš„ `inputs` åŒ…å«é¦ˆé€ç»™æ¨¡å‹çš„è¾“å…¥æ•°æ®çš„å½¢çŠ¶å’Œ `dtype`ã€‚å½¢çŠ¶å¦‚ä¸‹ï¼š
>
> ```python
> inputs.shape
> TensorShape([None, 784])
> ```
>
> dtype å¦‚ä¸‹ï¼š
>
> ```python
> inputs.dtype
> tf.float32
> ```

**å¯ä»¥é€šè¿‡åœ¨æ­¤ `inputs` å¯¹è±¡ä¸Šè°ƒç”¨å±‚ï¼Œåœ¨å±‚è®¡ç®—å›¾ä¸­åˆ›å»ºæ–°çš„èŠ‚ç‚¹**ï¼š

```python
dense = layers.Dense(64, activation="relu")
x = dense(inputs)
```

â€œå±‚è°ƒç”¨â€æ“ä½œå°±åƒä»â€œè¾“å…¥â€å‘æ‚¨åˆ›å»ºçš„è¯¥å±‚ç»˜åˆ¶ä¸€ä¸ªç®­å¤´ã€‚æ‚¨**å°†è¾“å…¥â€œä¼ é€’â€åˆ° `dense` å±‚ï¼Œç„¶åå¾—åˆ° `x`**ã€‚

è®©æˆ‘ä»¬ä¸ºå±‚è®¡ç®—å›¾å¤šæ·»åŠ å‡ ä¸ªå±‚ï¼š

```python
x = layers.Dense(64, activation="relu")(x)
outputs = layers.Dense(10)(x)
```

æ­¤æ—¶ï¼Œæ‚¨å¯ä»¥é€šè¿‡åœ¨å±‚è®¡ç®—å›¾ä¸­æŒ‡å®šæ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºæ¥åˆ›å»º `Model`ï¼š

```python
model = keras.Model(inputs=inputs, outputs=outputs, name="mnist_model")
```

è®©æˆ‘ä»¬çœ‹çœ‹æ¨¡å‹æ‘˜è¦æ˜¯ä»€ä¹ˆæ ·å­ï¼š

```python
model.summary()
Model: "mnist_model" _________________________________________________________________ Layer (type)                 Output Shape              Param #    ================================================================= input_1 (InputLayer)         [(None, 784)]             0          _________________________________________________________________ dense (Dense)                (None, 64)                50240      _________________________________________________________________ dense_1 (Dense)              (None, 64)                4160       _________________________________________________________________ dense_2 (Dense)              (None, 10)                650        ================================================================= Total params: 55,050 Trainable params: 55,050
```

æ‚¨è¿˜å¯ä»¥å°†æ¨¡å‹ç»˜åˆ¶ä¸ºè®¡ç®—å›¾ï¼š

```python
keras.utils.plot_model(model, "my_first_model.png")
```

![](https://gitee.com/veal98/images/raw/master/img/20201117112612.png)

å¹¶ä¸”ï¼Œæ‚¨è¿˜å¯ä»¥é€‰æ‹©åœ¨ç»˜åˆ¶çš„è®¡ç®—å›¾ä¸­æ˜¾ç¤ºæ¯å±‚çš„è¾“å…¥å’Œè¾“å‡ºå½¢çŠ¶ï¼š

```python
keras.utils.plot_model(model, "my_first_model_with_shape_info.png", show_shapes=True)
```

![](https://gitee.com/veal98/images/raw/master/img/20201117112648.png)

æ­¤å›¾å’Œä»£ç å‡ ä¹å®Œå…¨ç›¸åŒã€‚åœ¨ä»£ç ç‰ˆæœ¬ä¸­ï¼Œè¿æ¥ç®­å¤´ç”±è°ƒç”¨æ“ä½œä»£æ›¿ã€‚

â€œå±‚è®¡ç®—å›¾â€æ˜¯æ·±åº¦å­¦ä¹ æ¨¡å‹çš„ç›´è§‚å¿ƒç†å›¾åƒï¼Œè€Œå‡½æ•°å¼ API æ˜¯åˆ›å»ºå¯†åˆ‡åæ˜ æ­¤å›¾åƒçš„æ¨¡å‹çš„æ–¹æ³•ã€‚

## 2. è®­ç»ƒã€è¯„ä¼°å’Œæ¨æ–­

å¯¹äºä½¿ç”¨å‡½æ•°å¼ API æ„å»ºçš„æ¨¡å‹æ¥è¯´ï¼Œå…¶è®­ç»ƒã€è¯„ä¼°å’Œæ¨æ–­çš„å·¥ä½œæ–¹å¼ä¸ `Sequential` æ¨¡å‹å®Œå…¨ç›¸åŒã€‚

å¦‚ä¸‹æ‰€ç¤ºï¼ŒåŠ è½½ MNIST å›¾åƒæ•°æ®ï¼Œå°†å…¶æ”¹é€ ä¸ºå‘é‡ï¼Œå°†æ¨¡å‹ä¸æ•°æ®æ‹Ÿåˆï¼ˆåŒæ—¶ç›‘è§†éªŒè¯æ‹†åˆ†çš„æ€§èƒ½ï¼‰ï¼Œç„¶ååœ¨æµ‹è¯•æ•°æ®ä¸Šè¯„ä¼°æ¨¡å‹ï¼š

```python
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

x_train = x_train.reshape(60000, 784).astype("float32") / 255
x_test = x_test.reshape(10000, 784).astype("float32") / 255

model.compile(
    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=keras.optimizers.RMSprop(),
    metrics=["accuracy"],
)

history = model.fit(x_train, y_train, batch_size=64, epochs=2, validation_split=0.2)

test_scores = model.evaluate(x_test, y_test, verbose=2)
print("Test loss:", test_scores[0])
print("Test accuracy:", test_scores[1])
Epoch 1/2 750/750 [==============================] - 2s 2ms/step - loss: 0.3455 - accuracy: 0.9027 - val_loss: 0.1908 - val_accuracy: 0.9445 Epoch 2/2 750/750 [==============================] - 2s 2ms/step - loss: 0.1664 - accuracy: 0.9506 - val_loss: 0.1390 - val_accuracy: 0.9622 313/313 - 0s - loss: 0.1350 - accuracy: 0.9600 Test loss: 0.13501940667629242 Test accuracy: 0.9599999785423279 
```

## 3. ä¿å­˜å’Œåºåˆ—åŒ–

å¯¹äºä½¿ç”¨å‡½æ•°å¼ API æ„å»ºçš„æ¨¡å‹ï¼Œå…¶ä¿å­˜æ¨¡å‹å’Œåºåˆ—åŒ–çš„å·¥ä½œæ–¹å¼ä¸ `Sequential` æ¨¡å‹ç›¸åŒã€‚ä¿å­˜å‡½æ•°å¼æ¨¡å‹çš„æ ‡å‡†æ–¹å¼æ˜¯è°ƒç”¨ `model.save()` å°†æ•´ä¸ªæ¨¡å‹ä¿å­˜ä¸ºå•ä¸ªæ–‡ä»¶ã€‚æ‚¨å¯ä»¥ç¨åä»è¯¥æ–‡ä»¶é‡æ–°åˆ›å»ºç›¸åŒçš„æ¨¡å‹ï¼Œå³ä½¿æ„å»ºè¯¥æ¨¡å‹çš„ä»£ç å·²ä¸å†å¯ç”¨ã€‚

ä¿å­˜çš„æ–‡ä»¶åŒ…æ‹¬ï¼š

- æ¨¡å‹æ¶æ„
- æ¨¡å‹æƒé‡å€¼ï¼ˆåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¾—çŸ¥ï¼‰
- æ¨¡å‹è®­ç»ƒé…ç½®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œå¦‚ä¼ é€’ç»™ `compile`ï¼‰
- ä¼˜åŒ–å™¨åŠå…¶çŠ¶æ€ï¼ˆå¦‚æœæœ‰çš„è¯ï¼Œç”¨æ¥ä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹é‡æ–°å¼€å§‹è®­ç»ƒï¼‰

```python
model.save("path_to_my_model")
del model # Recreate the exact same model purely from the file:
model = keras.models.load_model("path_to_my_model")
```

## 4. ä½¿ç”¨ç›¸åŒçš„å±‚è®¡ç®—å›¾å®šä¹‰å¤šä¸ªæ¨¡å‹

åœ¨å‡½æ•°å¼ API ä¸­ï¼Œæ¨¡å‹æ˜¯é€šè¿‡åœ¨å±‚è®¡ç®—å›¾ä¸­æŒ‡å®šå…¶è¾“å…¥å’Œè¾“å‡ºæ¥åˆ›å»ºçš„ã€‚è¿™æ„å‘³ç€å¯ä»¥ä½¿ç”¨å•ä¸ªå±‚è®¡ç®—å›¾æ¥ç”Ÿæˆå¤šä¸ªæ¨¡å‹ã€‚

åœ¨ä¸‹é¢çš„ç¤ºä¾‹ä¸­ï¼Œæ‚¨å°†ä½¿ç”¨ç›¸åŒçš„å±‚å †æ ˆæ¥å®ä¾‹åŒ–ä¸¤ä¸ªæ¨¡å‹ï¼šèƒ½å¤Ÿå°†å›¾åƒè¾“å…¥è½¬æ¢ä¸º 16 ç»´å‘é‡çš„ `encoder` æ¨¡å‹ï¼Œä»¥åŠç”¨äºè®­ç»ƒçš„ç«¯åˆ°ç«¯ `autoencoder` æ¨¡å‹ã€‚

```python
encoder_input = keras.Input(shape=(28, 28, 1), name="img")
x = layers.Conv2D(16, 3, activation="relu")(encoder_input)
x = layers.Conv2D(32, 3, activation="relu")(x)
x = layers.MaxPooling2D(3)(x)
x = layers.Conv2D(32, 3, activation="relu")(x)
x = layers.Conv2D(16, 3, activation="relu")(x)
encoder_output = layers.GlobalMaxPooling2D()(x)

encoder = keras.Model(encoder_input, encoder_output, name="encoder")
encoder.summary()

Model: "encoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
img (InputLayer)             [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 26, 26, 16)        160       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      
_________________________________________________________________
global_max_pooling2d (Global (None, 16)                0         
=================================================================
Total params: 18,672
Trainable params: 18,672
Non-trainable params: 0
_________________________________________________________________
```

```python
x = layers.Reshape((4, 4, 1))(encoder_output)
x = layers.Conv2DTranspose(16, 3, activation="relu")(x)
x = layers.Conv2DTranspose(32, 3, activation="relu")(x)
x = layers.UpSampling2D(3)(x)
x = layers.Conv2DTranspose(16, 3, activation="relu")(x)
decoder_output = layers.Conv2DTranspose(1, 3, activation="relu")(x)

autoencoder = keras.Model(encoder_input, decoder_output, name="autoencoder")
autoencoder.summary()

Model: "autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
img (InputLayer)             [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d (Conv2D)              (None, 26, 26, 16)        160       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      
_________________________________________________________________
global_max_pooling2d (Global (None, 16)                0         
_________________________________________________________________
reshape (Reshape)            (None, 4, 4, 1)           0         
_________________________________________________________________
conv2d_transpose (Conv2DTran (None, 6, 6, 16)          160       
_________________________________________________________________
conv2d_transpose_1 (Conv2DTr (None, 8, 8, 32)          4640      
_________________________________________________________________
up_sampling2d (UpSampling2D) (None, 24, 24, 32)        0         
_________________________________________________________________
conv2d_transpose_2 (Conv2DTr (None, 26, 26, 16)        4624      
_________________________________________________________________
conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         145       
=================================================================
Total params: 28,241
Trainable params: 28,241
Non-trainable params: 0
_________________________________________________________________
```

åœ¨ä¸Šä¾‹ä¸­ï¼Œè§£ç æ¶æ„ä¸ç¼–ç æ¶æ„ä¸¥æ ¼å¯¹ç§°ï¼Œå› æ­¤è¾“å‡ºå½¢çŠ¶ä¸è¾“å…¥å½¢çŠ¶ `(28, 28, 1)` ç›¸åŒã€‚

`Conv2D` å±‚çš„åé¢æ˜¯ `Conv2DTranspose` å±‚ï¼Œ`MaxPooling2D` å±‚çš„åé¢æ˜¯ `UpSampling2D` å±‚ã€‚

## 5. æ‰€æœ‰æ¨¡å‹å‡å¯åƒå±‚ä¸€æ ·è°ƒç”¨

**æ‚¨å¯ä»¥é€šè¿‡åœ¨ `Input` ä¸Šæˆ–åœ¨å¦ä¸€ä¸ªå±‚çš„è¾“å‡ºä¸Šè°ƒç”¨ä»»ä½•æ¨¡å‹æ¥å°†å…¶å½“ä½œå±‚æ¥å¤„ç†ã€‚é€šè¿‡è°ƒç”¨æ¨¡å‹ï¼Œæ‚¨ä¸ä»…å¯ä»¥é‡ç”¨æ¨¡å‹çš„æ¶æ„ï¼Œè¿˜å¯ä»¥é‡ç”¨å®ƒçš„æƒé‡**ã€‚

ä¸ºäº†æŸ¥çœ‹å®é™…è¿è¡Œæƒ…å†µï¼Œä¸‹é¢æ˜¯å¯¹è‡ªåŠ¨ç¼–ç å™¨ç¤ºä¾‹çš„å¦ä¸€ç§å¤„ç†æ–¹å¼ï¼Œè¯¥ç¤ºä¾‹åˆ›å»ºäº†ä¸€ä¸ªç¼–ç å™¨æ¨¡å‹ã€ä¸€ä¸ªè§£ç å™¨æ¨¡å‹ï¼Œå¹¶åœ¨ä¸¤ä¸ªè°ƒç”¨ä¸­å°†å®ƒä»¬é“¾æ¥ï¼Œä»¥è·å¾—è‡ªåŠ¨ç¼–ç å™¨æ¨¡å‹ï¼š

```python
encoder_input = keras.Input(shape=(28, 28, 1), name="original_img")
x = layers.Conv2D(16, 3, activation="relu")(encoder_input)
x = layers.Conv2D(32, 3, activation="relu")(x)
x = layers.MaxPooling2D(3)(x)
x = layers.Conv2D(32, 3, activation="relu")(x)
x = layers.Conv2D(16, 3, activation="relu")(x)
encoder_output = layers.GlobalMaxPooling2D()(x)

encoder = keras.Model(encoder_input, encoder_output, name="encoder")
encoder.summary()

decoder_input = keras.Input(shape=(16,), name="encoded_img")
x = layers.Reshape((4, 4, 1))(decoder_input)
x = layers.Conv2DTranspose(16, 3, activation="relu")(x)
x = layers.Conv2DTranspose(32, 3, activation="relu")(x)
x = layers.UpSampling2D(3)(x)
x = layers.Conv2DTranspose(16, 3, activation="relu")(x)
decoder_output = layers.Conv2DTranspose(1, 3, activation="relu")(x)

decoder = keras.Model(decoder_input, decoder_output, name="decoder")
decoder.summary()

autoencoder_input = keras.Input(shape=(28, 28, 1), name="img")
encoded_img = encoder(autoencoder_input)
decoded_img = decoder(encoded_img)
autoencoder = keras.Model(autoencoder_input, decoded_img, name="autoencoder")
autoencoder.summary()
Model: "encoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
original_img (InputLayer)    [(None, 28, 28, 1)]       0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 24, 24, 32)        4640      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 6, 6, 32)          9248      
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 4, 4, 16)          4624      
_________________________________________________________________
global_max_pooling2d_1 (Glob (None, 16)                0         
=================================================================
Total params: 18,672
Trainable params: 18,672
Non-trainable params: 0
_________________________________________________________________
Model: "decoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
encoded_img (InputLayer)     [(None, 16)]              0         
_________________________________________________________________
reshape_1 (Reshape)          (None, 4, 4, 1)           0         
_________________________________________________________________
conv2d_transpose_4 (Conv2DTr (None, 6, 6, 16)          160       
_________________________________________________________________
conv2d_transpose_5 (Conv2DTr (None, 8, 8, 32)          4640      
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 24, 24, 32)        0         
_________________________________________________________________
conv2d_transpose_6 (Conv2DTr (None, 26, 26, 16)        4624      
_________________________________________________________________
conv2d_transpose_7 (Conv2DTr (None, 28, 28, 1)         145       
=================================================================
Total params: 9,569
Trainable params: 9,569
Non-trainable params: 0
_________________________________________________________________
Model: "autoencoder"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
img (InputLayer)             [(None, 28, 28, 1)]       0         
_________________________________________________________________
encoder (Functional)         (None, 16)                18672     
_________________________________________________________________
decoder (Functional)         (None, 28, 28, 1)         9569      
=================================================================
Total params: 28,241
Trainable params: 28,241
Non-trainable params: 0
_________________________________________________________________
```

å¦‚æ‚¨æ‰€è§ï¼Œæ¨¡å‹å¯ä»¥åµŒå¥—ï¼šæ¨¡å‹å¯ä»¥åŒ…å«å­æ¨¡å‹ï¼ˆå› ä¸ºæ¨¡å‹å°±åƒå±‚ä¸€æ ·ï¼‰ã€‚æ¨¡å‹åµŒå¥—çš„ä¸€ä¸ªå¸¸è§ç”¨ä¾‹æ˜¯*è£…é…*ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹å±•ç¤ºäº†å¦‚ä½•å°†ä¸€ç»„æ¨¡å‹è£…é…æˆä¸€ä¸ªå¹³å‡å…¶é¢„æµ‹çš„æ¨¡å‹ï¼š

```python
def get_model():
    inputs = keras.Input(shape=(128,))
    outputs = layers.Dense(1)(inputs)
    return keras.Model(inputs, outputs)


model1 = get_model()
model2 = get_model()
model3 = get_model()

inputs = keras.Input(shape=(128,))
y1 = model1(inputs)
y2 = model2(inputs)
y3 = model3(inputs)
outputs = layers.average([y1, y2, y3])
ensemble_model = keras.Model(inputs=inputs, outputs=outputs)
```

## 6. å¤„ç†å¤šä¸ªè¾“å…¥å’Œè¾“å‡º

**å‡½æ•°å¼ API ä½¿å¤„ç†å¤šä¸ªè¾“å…¥å’Œè¾“å‡ºå˜å¾—å®¹æ˜“ã€‚è€Œè¿™æ— æ³•ä½¿ç”¨ `Sequential` API å¤„ç†ã€‚**

ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨è¦æ„å»ºä¸€ä¸ªç³»ç»Ÿï¼Œè¯¥ç³»ç»ŸæŒ‰ç…§ä¼˜å…ˆçº§å¯¹è‡ªå®šä¹‰é—®é¢˜å·¥å•è¿›è¡Œæ’åºï¼Œç„¶åå°†å·¥å•ä¼ é€åˆ°æ­£ç¡®çš„éƒ¨é—¨ï¼Œåˆ™æ­¤æ¨¡å‹å°†å…·æœ‰ä¸‰ä¸ªè¾“å…¥ï¼š

- å·¥å•æ ‡é¢˜ï¼ˆæ–‡æœ¬è¾“å…¥ï¼‰ï¼Œ
- å·¥å•çš„æ–‡æœ¬æ­£æ–‡ï¼ˆæ–‡æœ¬è¾“å…¥ï¼‰ï¼Œä»¥åŠ
- ç”¨æˆ·æ·»åŠ çš„ä»»ä½•æ ‡ç­¾ï¼ˆåˆ†ç±»è¾“å…¥ï¼‰

æ­¤æ¨¡å‹å°†å…·æœ‰ä¸¤ä¸ªè¾“å‡ºï¼š

- ä»‹äº 0 å’Œ 1 ä¹‹é—´çš„ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆæ ‡é‡ Sigmoid è¾“å‡ºï¼‰ï¼Œä»¥åŠ
- åº”è¯¥å¤„ç†å·¥å•çš„éƒ¨é—¨ï¼ˆéƒ¨é—¨èŒƒå›´å†…çš„ Softmax è¾“å‡ºï¼‰ã€‚

æ‚¨å¯ä»¥ä½¿ç”¨å‡½æ•°å¼ API é€šè¿‡å‡ è¡Œä»£ç æ„å»ºæ­¤æ¨¡å‹ï¼š

```python
num_tags = 12  # Number of unique issue tags
num_words = 10000  # Size of vocabulary obtained when preprocessing text data
num_departments = 4  # Number of departments for predictions

title_input = keras.Input(
    shape=(None,), name="title"
)  # Variable-length sequence of ints
body_input = keras.Input(shape=(None,), name="body")  # Variable-length sequence of ints
tags_input = keras.Input(
    shape=(num_tags,), name="tags"
)  # Binary vectors of size `num_tags`

# Embed each word in the title into a 64-dimensional vector
title_features = layers.Embedding(num_words, 64)(title_input)
# Embed each word in the text into a 64-dimensional vector
body_features = layers.Embedding(num_words, 64)(body_input)

# Reduce sequence of embedded words in the title into a single 128-dimensional vector
title_features = layers.LSTM(128)(title_features)
# Reduce sequence of embedded words in the body into a single 32-dimensional vector
body_features = layers.LSTM(32)(body_features)

# Merge all available features into a single large vector via concatenation
x = layers.concatenate([title_features, body_features, tags_input])

# Stick a logistic regression for priority prediction on top of the features
priority_pred = layers.Dense(1, name="priority")(x)
# Stick a department classifier on top of the features
department_pred = layers.Dense(num_departments, name="department")(x)

# Instantiate an end-to-end model predicting both priority and department
model = keras.Model(
    inputs=[title_input, body_input, tags_input],
    outputs=[priority_pred, department_pred],
)
```

ç°åœ¨ç»˜åˆ¶æ¨¡å‹ï¼š

```python
keras.utils.plot_model(model, "multi_input_and_output_model.png", show_shapes=True)
```

![](https://gitee.com/veal98/images/raw/master/img/20201117115129.png)

ç¼–è¯‘æ­¤æ¨¡å‹æ—¶ï¼Œå¯ä»¥ä¸ºæ¯ä¸ªè¾“å‡ºåˆ†é…ä¸åŒçš„æŸå¤±ã€‚ç”šè‡³å¯ä»¥ä¸ºæ¯ä¸ªæŸå¤±åˆ†é…ä¸åŒçš„æƒé‡ï¼Œä»¥è°ƒæ•´å…¶å¯¹æ€»è®­ç»ƒæŸå¤±çš„è´¡çŒ®ã€‚

```python
model.compile(
    optimizer=keras.optimizers.RMSprop(1e-3),
    loss=[
        keras.losses.BinaryCrossentropy(from_logits=True),
        keras.losses.CategoricalCrossentropy(from_logits=True),
    ],
    loss_weights=[1.0, 0.2],
)
```

ç”±äºè¾“å‡ºå±‚å…·æœ‰ä¸åŒçš„åç§°ï¼Œæ‚¨è¿˜å¯ä»¥åƒä¸‹é¢è¿™æ ·æŒ‡å®šæŸå¤±ï¼š

```python
model.compile(
    optimizer=keras.optimizers.RMSprop(1e-3),
    loss={
        "priority": keras.losses.BinaryCrossentropy(from_logits=True),
        "department": keras.losses.CategoricalCrossentropy(from_logits=True),
    },
    loss_weights=[1.0, 0.2],
)
```

é€šè¿‡ä¼ é€’è¾“å…¥å’Œç›®æ ‡çš„ NumPy æ•°ç»„åˆ—è¡¨æ¥è®­ç»ƒæ¨¡å‹ï¼š

```python
# Dummy input data
title_data = np.random.randint(num_words, size=(1280, 10))
body_data = np.random.randint(num_words, size=(1280, 100))
tags_data = np.random.randint(2, size=(1280, num_tags)).astype("float32")

# Dummy target data
priority_targets = np.random.random(size=(1280, 1))
dept_targets = np.random.randint(2, size=(1280, num_departments))

model.fit(
    {"title": title_data, "body": body_data, "tags": tags_data},
    {"priority": priority_targets, "department": dept_targets},
    epochs=2,
    batch_size=32,
)
```

## ğŸ“š References

- [TensorFlow 2 å®˜æ–¹æ–‡æ¡£](https://tensorflow.google.cn/tutorials/keras/classification?hl=zh_cn)
- [TensorFlow 2 å®˜æ–¹æŒ‡å—](https://tensorflow.google.cn/guide/tensor?hl=zh_cn#%E6%93%8D%E4%BD%9C%E5%BD%A2%E7%8A%B6)